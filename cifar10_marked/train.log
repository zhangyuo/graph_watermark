INFO - 12/18/25 13:53:08 - 0:00:00 - ============ Initialized logger ============
INFO - 12/18/25 13:53:08 - 0:00:00 - angle: None
                                     carrier_id: 0
                                     carrier_path: carriers.pth
                                     command: python make_data_radioactive.py --carrier_id 0 --carrier_path 'carriers.pth' --data_augmentation random --epochs 10 --img_paths 'cifar10_images/0/0.png,cifar10_images/0/17.png' --lambda_ft_l2 '0.01' --lambda_l2_img '0.0005' --marking_network 'pretrained_resnet18.pth' --dump_path './cifar10_marked' --optimizer 'sgd,lr=1.0' --exp_id "cifar10_marked"
                                     crop_size: 224
                                     data_augmentation: random
                                     debug: False
                                     debug_slurm: False
                                     debug_train: False
                                     dump_path: ./cifar10_marked
                                     epochs: 10
                                     exp_id: cifar10_marked
                                     exp_name: bypass
                                     half_cone: True
                                     img_list: None
                                     img_paths: cifar10_images/0/0.png,cifar10_images/0/17.png
                                     img_size: 256
                                     lambda_ft_l2: 0.01
                                     lambda_l2_img: 0.0005
                                     marking_network: pretrained_resnet18.pth
                                     optimizer: sgd,lr=1.0
                                     radius: 10
INFO - 12/18/25 13:53:08 - 0:00:00 - The experiment will be stored in ./cifar10_marked
                                     
INFO - 12/18/25 13:53:08 - 0:00:00 - Running command: python make_data_radioactive.py --carrier_id 0 --carrier_path 'carriers.pth' --data_augmentation random --epochs 10 --img_paths 'cifar10_images/0/0.png,cifar10_images/0/17.png' --lambda_ft_l2 '0.01' --lambda_l2_img '0.0005' --marking_network 'pretrained_resnet18.pth' --dump_path './cifar10_marked' --optimizer 'sgd,lr=1.0'

INFO - 12/18/25 13:58:26 - 0:00:00 - ============ Initialized logger ============
INFO - 12/18/25 13:58:26 - 0:00:00 - angle: None
                                     carrier_id: 0
                                     carrier_path: carriers.pth
                                     command: python make_data_radioactive.py --carrier_id 0 --carrier_path 'carriers.pth' --data_augmentation random --epochs 10 --img_paths 'cifar10_images/0/0.png,cifar10_images/0/17.png' --lambda_ft_l2 '0.01' --lambda_l2_img '0.0005' --marking_network 'pretrained_resnet18.pth' --dump_path './cifar10_marked' --optimizer 'sgd,lr=1.0' --exp_id "cifar10_marked"
                                     crop_size: 224
                                     data_augmentation: random
                                     debug: False
                                     debug_slurm: False
                                     debug_train: False
                                     dump_path: ./cifar10_marked
                                     epochs: 10
                                     exp_id: cifar10_marked
                                     exp_name: bypass
                                     half_cone: True
                                     img_list: None
                                     img_paths: cifar10_images/0/0.png,cifar10_images/0/17.png
                                     img_size: 256
                                     lambda_ft_l2: 0.01
                                     lambda_l2_img: 0.0005
                                     marking_network: pretrained_resnet18.pth
                                     optimizer: sgd,lr=1.0
                                     radius: 10
INFO - 12/18/25 13:58:26 - 0:00:00 - The experiment will be stored in ./cifar10_marked
                                     
INFO - 12/18/25 13:58:26 - 0:00:00 - Running command: python make_data_radioactive.py --carrier_id 0 --carrier_path 'carriers.pth' --data_augmentation random --epochs 10 --img_paths 'cifar10_images/0/0.png,cifar10_images/0/17.png' --lambda_ft_l2 '0.01' --lambda_l2_img '0.0005' --marking_network 'pretrained_resnet18.pth' --dump_path './cifar10_marked' --optimizer 'sgd,lr=1.0'

INFO - 12/18/25 13:58:26 - 0:00:00 - Model: ResNet(
                                       (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
                                       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                       (relu): ReLU(inplace=True)
                                       (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
                                       (layer1): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer2): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer3): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer4): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
                                       (fc): Linear(in_features=512, out_features=1000, bias=True)
                                     )
INFO - 12/18/25 13:59:05 - 0:00:00 - ============ Initialized logger ============
INFO - 12/18/25 13:59:05 - 0:00:00 - angle: None
                                     carrier_id: 0
                                     carrier_path: carriers.pth
                                     command: python make_data_radioactive.py --carrier_id 0 --carrier_path 'carriers.pth' --data_augmentation random --epochs 10 --img_paths 'cifar10_images/0/0.png,cifar10_images/0/17.png' --lambda_ft_l2 '0.01' --lambda_l2_img '0.0005' --marking_network 'pretrained_resnet18.pth' --dump_path './cifar10_marked' --optimizer 'sgd,lr=1.0' --exp_id "cifar10_marked"
                                     crop_size: 224
                                     data_augmentation: random
                                     debug: False
                                     debug_slurm: False
                                     debug_train: False
                                     dump_path: ./cifar10_marked
                                     epochs: 10
                                     exp_id: cifar10_marked
                                     exp_name: bypass
                                     half_cone: True
                                     img_list: None
                                     img_paths: cifar10_images/0/0.png,cifar10_images/0/17.png
                                     img_size: 256
                                     lambda_ft_l2: 0.01
                                     lambda_l2_img: 0.0005
                                     marking_network: pretrained_resnet18.pth
                                     optimizer: sgd,lr=1.0
                                     radius: 10
INFO - 12/18/25 13:59:05 - 0:00:00 - The experiment will be stored in ./cifar10_marked
                                     
INFO - 12/18/25 13:59:05 - 0:00:00 - Running command: python make_data_radioactive.py --carrier_id 0 --carrier_path 'carriers.pth' --data_augmentation random --epochs 10 --img_paths 'cifar10_images/0/0.png,cifar10_images/0/17.png' --lambda_ft_l2 '0.01' --lambda_l2_img '0.0005' --marking_network 'pretrained_resnet18.pth' --dump_path './cifar10_marked' --optimizer 'sgd,lr=1.0'

INFO - 12/18/25 13:59:05 - 0:00:00 - Model: ResNet(
                                       (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
                                       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                       (relu): ReLU(inplace=True)
                                       (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
                                       (layer1): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer2): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer3): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer4): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
                                       (fc): Linear(in_features=512, out_features=10, bias=True)
                                     )
INFO - 12/18/25 14:04:55 - 0:00:00 - ============ Initialized logger ============
INFO - 12/18/25 14:04:55 - 0:00:00 - angle: None
                                     carrier_id: 0
                                     carrier_path: carriers.pth
                                     command: python make_data_radioactive.py --carrier_id 0 --carrier_path 'carriers.pth' --data_augmentation random --epochs 10 --img_paths 'cifar10_images/0/0.png,cifar10_images/0/17.png' --lambda_ft_l2 '0.01' --lambda_l2_img '0.0005' --marking_network 'pretrained_resnet18.pth' --dump_path './cifar10_marked' --optimizer 'sgd,lr=1.0' --exp_id "cifar10_marked"
                                     crop_size: 224
                                     data_augmentation: random
                                     debug: False
                                     debug_slurm: False
                                     debug_train: False
                                     dump_path: ./cifar10_marked
                                     epochs: 10
                                     exp_id: cifar10_marked
                                     exp_name: bypass
                                     half_cone: True
                                     img_list: None
                                     img_paths: cifar10_images/0/0.png,cifar10_images/0/17.png
                                     img_size: 256
                                     lambda_ft_l2: 0.01
                                     lambda_l2_img: 0.0005
                                     marking_network: pretrained_resnet18.pth
                                     optimizer: sgd,lr=1.0
                                     radius: 10
INFO - 12/18/25 14:04:55 - 0:00:00 - The experiment will be stored in ./cifar10_marked
                                     
INFO - 12/18/25 14:04:55 - 0:00:00 - Running command: python make_data_radioactive.py --carrier_id 0 --carrier_path 'carriers.pth' --data_augmentation random --epochs 10 --img_paths 'cifar10_images/0/0.png,cifar10_images/0/17.png' --lambda_ft_l2 '0.01' --lambda_l2_img '0.0005' --marking_network 'pretrained_resnet18.pth' --dump_path './cifar10_marked' --optimizer 'sgd,lr=1.0'

INFO - 12/18/25 14:04:55 - 0:00:00 - Model: ResNet(
                                       (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
                                       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                       (relu): ReLU(inplace=True)
                                       (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
                                       (layer1): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer2): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer3): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer4): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
                                       (fc): Linear(in_features=512, out_features=10, bias=True)
                                     )
INFO - 12/18/25 14:11:31 - 0:00:00 - ============ Initialized logger ============
INFO - 12/18/25 14:11:31 - 0:00:00 - angle: None
                                     carrier_id: 0
                                     carrier_path: carriers.pth
                                     command: python make_data_radioactive.py --carrier_id 0 --carrier_path 'carriers.pth' --data_augmentation random --epochs 10 --img_paths 'cifar10_images/0/0.png,cifar10_images/0/17.png' --lambda_ft_l2 '0.01' --lambda_l2_img '0.0005' --marking_network 'pretrained_resnet18.pth' --dump_path './cifar10_marked' --optimizer 'sgd,lr=1.0' --exp_id "cifar10_marked"
                                     crop_size: 224
                                     data_augmentation: random
                                     debug: False
                                     debug_slurm: False
                                     debug_train: False
                                     dump_path: ./cifar10_marked
                                     epochs: 10
                                     exp_id: cifar10_marked
                                     exp_name: bypass
                                     half_cone: True
                                     img_list: None
                                     img_paths: cifar10_images/0/0.png,cifar10_images/0/17.png
                                     img_size: 256
                                     lambda_ft_l2: 0.01
                                     lambda_l2_img: 0.0005
                                     marking_network: pretrained_resnet18.pth
                                     optimizer: sgd,lr=1.0
                                     radius: 10
INFO - 12/18/25 14:11:31 - 0:00:00 - The experiment will be stored in ./cifar10_marked
                                     
INFO - 12/18/25 14:11:31 - 0:00:00 - Running command: python make_data_radioactive.py --carrier_id 0 --carrier_path 'carriers.pth' --data_augmentation random --epochs 10 --img_paths 'cifar10_images/0/0.png,cifar10_images/0/17.png' --lambda_ft_l2 '0.01' --lambda_l2_img '0.0005' --marking_network 'pretrained_resnet18.pth' --dump_path './cifar10_marked' --optimizer 'sgd,lr=1.0'

INFO - 12/18/25 14:11:32 - 0:00:00 - Model: ResNet(
                                       (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
                                       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                       (relu): ReLU(inplace=True)
                                       (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
                                       (layer1): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer2): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer3): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer4): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
                                       (fc): Linear(in_features=512, out_features=10, bias=True)
                                     )
INFO - 12/18/25 14:14:06 - 0:00:00 - ============ Initialized logger ============
INFO - 12/18/25 14:14:06 - 0:00:00 - angle: None
                                     carrier_id: 0
                                     carrier_path: carriers.pth
                                     command: python make_data_radioactive.py --carrier_id 0 --carrier_path 'carriers.pth' --data_augmentation random --epochs 10 --img_paths 'cifar10_images/0/29.png,cifar10_images/0/77.png' --lambda_ft_l2 '0.01' --lambda_l2_img '0.0005' --marking_network 'pretrained_resnet18.pth' --dump_path './cifar10_marked' --optimizer 'sgd,lr=1.0' --exp_id "cifar10_marked"
                                     crop_size: 224
                                     data_augmentation: random
                                     debug: False
                                     debug_slurm: False
                                     debug_train: False
                                     dump_path: ./cifar10_marked
                                     epochs: 10
                                     exp_id: cifar10_marked
                                     exp_name: bypass
                                     half_cone: True
                                     img_list: None
                                     img_paths: cifar10_images/0/29.png,cifar10_images/0/77.png
                                     img_size: 256
                                     lambda_ft_l2: 0.01
                                     lambda_l2_img: 0.0005
                                     marking_network: pretrained_resnet18.pth
                                     optimizer: sgd,lr=1.0
                                     radius: 10
INFO - 12/18/25 14:14:06 - 0:00:00 - The experiment will be stored in ./cifar10_marked
                                     
INFO - 12/18/25 14:14:06 - 0:00:00 - Running command: python make_data_radioactive.py --carrier_id 0 --carrier_path 'carriers.pth' --data_augmentation random --epochs 10 --img_paths 'cifar10_images/0/29.png,cifar10_images/0/77.png' --lambda_ft_l2 '0.01' --lambda_l2_img '0.0005' --marking_network 'pretrained_resnet18.pth' --dump_path './cifar10_marked' --optimizer 'sgd,lr=1.0'

INFO - 12/18/25 14:14:06 - 0:00:00 - Model: ResNet(
                                       (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
                                       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                       (relu): ReLU(inplace=True)
                                       (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
                                       (layer1): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer2): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer3): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer4): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
                                       (fc): Linear(in_features=512, out_features=10, bias=True)
                                     )
DEBUG - 12/18/25 14:14:06 - 0:00:00 - STREAM b'IHDR' 16 13
DEBUG - 12/18/25 14:14:06 - 0:00:00 - STREAM b'IDAT' 41 2006
DEBUG - 12/18/25 14:14:06 - 0:00:00 - STREAM b'IHDR' 16 13
DEBUG - 12/18/25 14:14:06 - 0:00:00 - STREAM b'IDAT' 41 2124
INFO - 12/18/25 14:16:26 - 0:00:00 - ============ Initialized logger ============
INFO - 12/18/25 14:16:26 - 0:00:00 - angle: None
                                     carrier_id: 0
                                     carrier_path: carriers.pth
                                     command: python make_data_radioactive.py --carrier_id 0 --carrier_path 'carriers.pth' --data_augmentation random --epochs 10 --img_paths 'cifar10_images/0/29.png,cifar10_images/0/77.png' --lambda_ft_l2 '0.01' --lambda_l2_img '0.0005' --marking_network 'pretrained_resnet18.pth' --dump_path './cifar10_marked' --optimizer 'sgd,lr=1.0' --exp_id "cifar10_marked"
                                     crop_size: 224
                                     data_augmentation: random
                                     debug: False
                                     debug_slurm: False
                                     debug_train: False
                                     dump_path: ./cifar10_marked
                                     epochs: 10
                                     exp_id: cifar10_marked
                                     exp_name: bypass
                                     half_cone: True
                                     img_list: None
                                     img_paths: cifar10_images/0/29.png,cifar10_images/0/77.png
                                     img_size: 256
                                     lambda_ft_l2: 0.01
                                     lambda_l2_img: 0.0005
                                     marking_network: pretrained_resnet18.pth
                                     optimizer: sgd,lr=1.0
                                     radius: 10
INFO - 12/18/25 14:16:26 - 0:00:00 - The experiment will be stored in ./cifar10_marked
                                     
INFO - 12/18/25 14:16:26 - 0:00:00 - Running command: python make_data_radioactive.py --carrier_id 0 --carrier_path 'carriers.pth' --data_augmentation random --epochs 10 --img_paths 'cifar10_images/0/29.png,cifar10_images/0/77.png' --lambda_ft_l2 '0.01' --lambda_l2_img '0.0005' --marking_network 'pretrained_resnet18.pth' --dump_path './cifar10_marked' --optimizer 'sgd,lr=1.0'

INFO - 12/18/25 14:16:26 - 0:00:00 - Model: ResNet(
                                       (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
                                       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                       (relu): ReLU(inplace=True)
                                       (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
                                       (layer1): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer2): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer3): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer4): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
                                       (fc): Linear(in_features=512, out_features=10, bias=True)
                                     )
DEBUG - 12/18/25 14:16:27 - 0:00:00 - STREAM b'IHDR' 16 13
DEBUG - 12/18/25 14:16:27 - 0:00:00 - STREAM b'IDAT' 41 2006
DEBUG - 12/18/25 14:16:27 - 0:00:00 - STREAM b'IHDR' 16 13
DEBUG - 12/18/25 14:16:27 - 0:00:00 - STREAM b'IDAT' 41 2124
INFO - 12/18/25 14:16:27 - 0:00:00 - Schedule of sgd,lr=1.0: None
INFO - 12/18/25 14:16:27 - 0:00:01 - __log__:{"keyword": "iteration", "loss": 1.0708261728286743, "loss_ft": 0.8909723162651062, "loss_norm": 0.0, "loss_ft_l2": 0.17985385656356812}
INFO - 12/18/25 14:16:27 - 0:00:01 - __log__:{"keyword": "iteration", "loss": 0.349763959646225, "loss_ft": -0.008003875613212585, "loss_norm": 0.013490734621882439, "loss_ft_l2": 0.34427711367607117}
INFO - 12/18/25 14:16:27 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.2027149200439453, "loss_ft": -0.4903455674648285, "loss_norm": 0.017816860228776932, "loss_ft_l2": 0.26981377601623535}
INFO - 12/18/25 14:16:27 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.0161176919937134, "loss_ft": -1.344266414642334, "loss_norm": 0.022534115239977837, "loss_ft_l2": 0.30561456084251404}
INFO - 12/18/25 14:16:27 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.12795332074165344, "loss_ft": -0.4835464358329773, "loss_norm": 0.025978300720453262, "loss_ft_l2": 0.3296148180961609}
INFO - 12/18/25 14:16:27 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.1274352073669434, "loss_ft": -2.426752805709839, "loss_norm": 0.02738136053085327, "loss_ft_l2": 0.2719362676143646}
INFO - 12/18/25 14:16:27 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.2892414331436157, "loss_ft": -1.641770362854004, "loss_norm": 0.030305445194244385, "loss_ft_l2": 0.32222357392311096}
INFO - 12/18/25 14:16:27 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.636521339416504, "loss_ft": -2.001208782196045, "loss_norm": 0.031154455617070198, "loss_ft_l2": 0.3335328698158264}
INFO - 12/18/25 14:16:27 - 0:00:01 - __log__:{"keyword": "iteration", "loss": 0.06897121667861938, "loss_ft": -0.290345698595047, "loss_norm": 0.03323041647672653, "loss_ft_l2": 0.32608649134635925}
INFO - 12/18/25 14:16:27 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.5442147254943848, "loss_ft": -2.9006733894348145, "loss_norm": 0.03425029665231705, "loss_ft_l2": 0.322208434343338}
INFO - 12/18/25 14:16:27 - 0:00:01 - __log__:{"keyword": "final", "psnr": 32.526318931364344, "ft_direction": 2.6553640365600586, "ft_norm": 15.25709342956543, "rho": -1, "R": -477.8992614746094}
INFO - 01/06/26 15:19:50 - 0:00:00 - ============ Initialized logger ============
INFO - 01/06/26 15:19:50 - 0:00:00 - angle: None
                                     carrier_id: 0
                                     carrier_path: carriers.pth
                                     command: python make_data_radioactive.py --carrier_id 0 --carrier_path 'carriers.pth' --data_augmentation random --epochs 10 --img_paths 'cifar10_images/0/29.png,cifar10_images/0/77.png' --lambda_ft_l2 '0.01' --lambda_l2_img '0.0005' --marking_network 'pretrained_resnet18.pth' --dump_path './cifar10_marked' --optimizer 'sgd,lr=1.0' --exp_id "cifar10_marked"
                                     crop_size: 224
                                     data_augmentation: random
                                     debug: False
                                     debug_slurm: False
                                     debug_train: False
                                     dump_path: ./cifar10_marked
                                     epochs: 10
                                     exp_id: cifar10_marked
                                     exp_name: bypass
                                     half_cone: True
                                     img_list: None
                                     img_paths: cifar10_images/0/29.png,cifar10_images/0/77.png
                                     img_size: 256
                                     lambda_ft_l2: 0.01
                                     lambda_l2_img: 0.0005
                                     marking_network: pretrained_resnet18.pth
                                     optimizer: sgd,lr=1.0
                                     radius: 10
INFO - 01/06/26 15:19:50 - 0:00:00 - The experiment will be stored in ./cifar10_marked
                                     
INFO - 01/06/26 15:19:50 - 0:00:00 - Running command: python make_data_radioactive.py --carrier_id 0 --carrier_path 'carriers.pth' --data_augmentation random --epochs 10 --img_paths 'cifar10_images/0/29.png,cifar10_images/0/77.png' --lambda_ft_l2 '0.01' --lambda_l2_img '0.0005' --marking_network 'pretrained_resnet18.pth' --dump_path './cifar10_marked' --optimizer 'sgd,lr=1.0'

INFO - 01/06/26 15:19:51 - 0:00:01 - Model: ResNet(
                                       (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
                                       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                       (relu): ReLU(inplace=True)
                                       (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
                                       (layer1): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer2): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer3): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer4): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
                                       (fc): Linear(in_features=512, out_features=10, bias=True)
                                     )
DEBUG - 01/06/26 15:19:52 - 0:00:02 - STREAM b'IHDR' 16 13
DEBUG - 01/06/26 15:19:52 - 0:00:02 - STREAM b'IDAT' 41 2006
DEBUG - 01/06/26 15:19:52 - 0:00:02 - STREAM b'IHDR' 16 13
DEBUG - 01/06/26 15:19:52 - 0:00:02 - STREAM b'IDAT' 41 2124
INFO - 01/06/26 15:19:52 - 0:00:02 - Schedule of sgd,lr=1.0: None
INFO - 01/06/26 15:20:00 - 0:00:10 - __log__:{"keyword": "iteration", "loss": 0.4530578851699829, "loss_ft": 0.23361465334892273, "loss_norm": 0.0, "loss_ft_l2": 0.21944324672222137}
INFO - 01/06/26 15:20:00 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -0.7939077615737915, "loss_ft": -1.0956783294677734, "loss_norm": 0.00979302916675806, "loss_ft_l2": 0.29197749495506287}
INFO - 01/06/26 15:20:00 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -0.717896044254303, "loss_ft": -1.1115671396255493, "loss_norm": 0.017037533223628998, "loss_ft_l2": 0.37663358449935913}
INFO - 01/06/26 15:20:00 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -1.316481113433838, "loss_ft": -1.687345266342163, "loss_norm": 0.018730074167251587, "loss_ft_l2": 0.35213416814804077}
INFO - 01/06/26 15:20:00 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -0.4152863025665283, "loss_ft": -0.8012969493865967, "loss_norm": 0.02189401537179947, "loss_ft_l2": 0.3641166090965271}
INFO - 01/06/26 15:20:00 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -1.5703328847885132, "loss_ft": -1.9134867191314697, "loss_norm": 0.02204512059688568, "loss_ft_l2": 0.32110869884490967}
INFO - 01/06/26 15:20:00 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -1.3969385623931885, "loss_ft": -1.7640373706817627, "loss_norm": 0.025677554309368134, "loss_ft_l2": 0.3414212763309479}
INFO - 01/06/26 15:20:00 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -0.18329116702079773, "loss_ft": -0.5916493535041809, "loss_norm": 0.027581222355365753, "loss_ft_l2": 0.380776971578598}
INFO - 01/06/26 15:20:00 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -3.791944980621338, "loss_ft": -4.130084037780762, "loss_norm": 0.0274981539696455, "loss_ft_l2": 0.31064075231552124}
INFO - 01/06/26 15:20:00 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -3.115649461746216, "loss_ft": -3.4533746242523193, "loss_norm": 0.029506729915738106, "loss_ft_l2": 0.3082185387611389}
INFO - 01/06/26 15:20:01 - 0:00:10 - __log__:{"keyword": "final", "psnr": 33.01646461465292, "ft_direction": 2.2966108322143555, "ft_norm": 15.220193862915039, "rho": -1, "R": -468.9132995605469}
INFO - 01/06/26 15:21:35 - 0:00:00 - ============ Initialized logger ============
INFO - 01/06/26 15:21:35 - 0:00:00 - angle: None
                                     carrier_id: 0
                                     carrier_path: carriers.pth
                                     command: python mark_embed.py --carrier_id 0 --carrier_path 'carriers.pth' --data_augmentation random --epochs 10 --img_paths 'cifar10_images/0/29.png,cifar10_images/0/77.png' --lambda_ft_l2 '0.01' --lambda_l2_img '0.0005' --marking_network 'pretrained_resnet18.pth' --dump_path './cifar10_marked' --optimizer 'sgd,lr=1.0' --exp_id "cifar10_marked"
                                     crop_size: 224
                                     data_augmentation: random
                                     debug: False
                                     debug_slurm: False
                                     debug_train: False
                                     dump_path: ./cifar10_marked
                                     epochs: 10
                                     exp_id: cifar10_marked
                                     exp_name: bypass
                                     half_cone: True
                                     img_list: None
                                     img_paths: cifar10_images/0/29.png,cifar10_images/0/77.png
                                     img_size: 256
                                     lambda_ft_l2: 0.01
                                     lambda_l2_img: 0.0005
                                     marking_network: pretrained_resnet18.pth
                                     optimizer: sgd,lr=1.0
                                     radius: 10
INFO - 01/06/26 15:21:35 - 0:00:00 - The experiment will be stored in ./cifar10_marked
                                     
INFO - 01/06/26 15:21:35 - 0:00:00 - Running command: python mark_embed.py --carrier_id 0 --carrier_path 'carriers.pth' --data_augmentation random --epochs 10 --img_paths 'cifar10_images/0/29.png,cifar10_images/0/77.png' --lambda_ft_l2 '0.01' --lambda_l2_img '0.0005' --marking_network 'pretrained_resnet18.pth' --dump_path './cifar10_marked' --optimizer 'sgd,lr=1.0'

INFO - 01/06/26 15:21:35 - 0:00:00 - Model: ResNet(
                                       (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
                                       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                       (relu): ReLU(inplace=True)
                                       (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
                                       (layer1): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer2): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer3): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer4): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
                                       (fc): Linear(in_features=512, out_features=10, bias=True)
                                     )
DEBUG - 01/06/26 15:21:35 - 0:00:00 - STREAM b'IHDR' 16 13
DEBUG - 01/06/26 15:21:35 - 0:00:00 - STREAM b'IDAT' 41 2006
DEBUG - 01/06/26 15:21:35 - 0:00:00 - STREAM b'IHDR' 16 13
DEBUG - 01/06/26 15:21:35 - 0:00:00 - STREAM b'IDAT' 41 2124
INFO - 01/06/26 15:21:35 - 0:00:00 - Schedule of sgd,lr=1.0: None
INFO - 01/06/26 15:21:35 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.12376213073730469, "loss_ft": -0.4031696319580078, "loss_norm": 0.0, "loss_ft_l2": 0.2794075012207031}
INFO - 01/06/26 15:21:35 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.16886472702026367, "loss_ft": -0.48155665397644043, "loss_norm": 0.009324515238404274, "loss_ft_l2": 0.30336740612983704}
INFO - 01/06/26 15:21:35 - 0:00:01 - __log__:{"keyword": "iteration", "loss": 1.0960841178894043, "loss_ft": 0.6562060117721558, "loss_norm": 0.01440492644906044, "loss_ft_l2": 0.42547309398651123}
INFO - 01/06/26 15:21:35 - 0:00:01 - __log__:{"keyword": "iteration", "loss": 0.0354481041431427, "loss_ft": -0.267419695854187, "loss_norm": 0.01620788685977459, "loss_ft_l2": 0.28665992617607117}
INFO - 01/06/26 15:21:35 - 0:00:01 - __log__:{"keyword": "iteration", "loss": 0.2372300773859024, "loss_ft": -0.18226313591003418, "loss_norm": 0.02253330871462822, "loss_ft_l2": 0.39695990085601807}
INFO - 01/06/26 15:21:35 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.23426005244255066, "loss_ft": -0.618388295173645, "loss_norm": 0.024524720385670662, "loss_ft_l2": 0.35960349440574646}
INFO - 01/06/26 15:21:35 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.1850292682647705, "loss_ft": -2.4986584186553955, "loss_norm": 0.026320602744817734, "loss_ft_l2": 0.28730839490890503}
INFO - 01/06/26 15:21:35 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.88429856300354, "loss_ft": -2.199085235595703, "loss_norm": 0.027962330728769302, "loss_ft_l2": 0.2868242859840393}
INFO - 01/06/26 15:21:35 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.628713846206665, "loss_ft": -1.998145580291748, "loss_norm": 0.030026648193597794, "loss_ft_l2": 0.3394050598144531}
INFO - 01/06/26 15:21:35 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.7863336801528931, "loss_ft": -1.175673484802246, "loss_norm": 0.030850211158394814, "loss_ft_l2": 0.35848966240882874}
INFO - 01/06/26 15:21:35 - 0:00:01 - __log__:{"keyword": "final", "psnr": 32.99380590894155, "ft_direction": 1.988230586051941, "ft_norm": 14.433481216430664, "rho": -1, "R": -418.216064453125}
INFO - 01/07/26 10:48:45 - 0:00:00 - ============ Initialized logger ============
INFO - 01/07/26 10:48:45 - 0:00:00 - angle: None
                                     carrier_id: 0
                                     carrier_path: carriers.pth
                                     command: python mark_embed.py --carrier_id 0 --carrier_path 'carriers.pth' --data_augmentation random --epochs 10 --img_paths 'cifar10_images/0/29.png,cifar10_images/0/77.png' --lambda_ft_l2 '0.01' --lambda_l2_img '0.0005' --marking_network 'pretrained_resnet18.pth' --dump_path './cifar10_marked' --optimizer 'sgd,lr=1.0' --exp_id "cifar10_marked"
                                     crop_size: 224
                                     data_augmentation: random
                                     debug: False
                                     debug_slurm: False
                                     debug_train: False
                                     dump_path: ./cifar10_marked
                                     epochs: 10
                                     exp_id: cifar10_marked
                                     exp_name: bypass
                                     half_cone: True
                                     img_list: None
                                     img_paths: cifar10_images/0/29.png,cifar10_images/0/77.png
                                     img_size: 256
                                     lambda_ft_l2: 0.01
                                     lambda_l2_img: 0.0005
                                     marking_network: pretrained_resnet18.pth
                                     optimizer: sgd,lr=1.0
                                     radius: 10
INFO - 01/07/26 10:48:45 - 0:00:00 - The experiment will be stored in ./cifar10_marked
                                     
INFO - 01/07/26 10:48:45 - 0:00:00 - Running command: python mark_embed.py --carrier_id 0 --carrier_path 'carriers.pth' --data_augmentation random --epochs 10 --img_paths 'cifar10_images/0/29.png,cifar10_images/0/77.png' --lambda_ft_l2 '0.01' --lambda_l2_img '0.0005' --marking_network 'pretrained_resnet18.pth' --dump_path './cifar10_marked' --optimizer 'sgd,lr=1.0'

INFO - 01/07/26 11:32:34 - 0:43:44 - Model: ResNet(
                                       (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
                                       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                       (relu): ReLU(inplace=True)
                                       (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
                                       (layer1): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer2): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer3): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer4): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
                                       (fc): Linear(in_features=512, out_features=10, bias=True)
                                     )
DEBUG - 01/07/26 11:48:15 - 0:59:30 - STREAM b'IHDR' 16 13
DEBUG - 01/07/26 11:48:15 - 0:59:30 - STREAM b'IDAT' 41 2006
DEBUG - 01/07/26 11:48:57 - 1:00:12 - STREAM b'IHDR' 16 13
DEBUG - 01/07/26 11:48:57 - 1:00:12 - STREAM b'IDAT' 41 2124
INFO - 01/07/26 12:07:26 - 1:18:41 - Schedule of sgd,lr=1.0: None
INFO - 01/07/26 12:07:37 - 1:18:52 - __log__:{"keyword": "iteration", "loss": 0.3168649673461914, "loss_ft": -0.018631935119628906, "loss_norm": 0.0, "loss_ft_l2": 0.3354969024658203}
INFO - 01/07/26 12:07:37 - 1:18:52 - __log__:{"keyword": "iteration", "loss": 0.027766942977905273, "loss_ft": -0.39021098613739014, "loss_norm": 0.007155475206673145, "loss_ft_l2": 0.41082245111465454}
INFO - 01/07/26 12:07:37 - 1:18:52 - __log__:{"keyword": "iteration", "loss": 0.30127090215682983, "loss_ft": -0.022168517112731934, "loss_norm": 0.010232336819171906, "loss_ft_l2": 0.31320708990097046}
INFO - 01/07/26 12:07:37 - 1:18:52 - __log__:{"keyword": "iteration", "loss": -0.4136403501033783, "loss_ft": -0.8154846429824829, "loss_norm": 0.014870631508529186, "loss_ft_l2": 0.38697364926338196}
INFO - 01/07/26 12:07:37 - 1:18:52 - __log__:{"keyword": "iteration", "loss": -1.458147406578064, "loss_ft": -1.8624464273452759, "loss_norm": 0.01717563346028328, "loss_ft_l2": 0.38712331652641296}
INFO - 01/07/26 12:07:37 - 1:18:52 - __log__:{"keyword": "iteration", "loss": -0.7085698843002319, "loss_ft": -0.9389683604240417, "loss_norm": 0.01931161805987358, "loss_ft_l2": 0.21108688414096832}
INFO - 01/07/26 12:07:37 - 1:18:52 - __log__:{"keyword": "iteration", "loss": -2.892582893371582, "loss_ft": -3.194977045059204, "loss_norm": 0.024168793112039566, "loss_ft_l2": 0.27822554111480713}
INFO - 01/07/26 12:07:37 - 1:18:52 - __log__:{"keyword": "iteration", "loss": -0.991359531879425, "loss_ft": -1.3837167024612427, "loss_norm": 0.027859006077051163, "loss_ft_l2": 0.36449819803237915}
INFO - 01/07/26 12:07:37 - 1:18:52 - __log__:{"keyword": "iteration", "loss": -2.5722012519836426, "loss_ft": -2.8942484855651855, "loss_norm": 0.029209643602371216, "loss_ft_l2": 0.29283758997917175}
INFO - 01/07/26 12:07:37 - 1:18:52 - __log__:{"keyword": "iteration", "loss": -1.6933932304382324, "loss_ft": -2.1050760746002197, "loss_norm": 0.030429385602474213, "loss_ft_l2": 0.3812534213066101}
INFO - 01/07/26 12:07:37 - 1:18:52 - __log__:{"keyword": "final", "psnr": 33.05389156320028, "ft_direction": 2.300325393676758, "ft_norm": 14.466468811035156, "rho": -1, "R": -420.5584716796875}
INFO - 01/07/26 12:09:53 - 0:00:00 - ============ Initialized logger ============
INFO - 01/07/26 12:09:53 - 0:00:00 - angle: None
                                     carrier_id: 0
                                     carrier_path: carriers.pth
                                     command: python mark_embed.py --carrier_id 0 --carrier_path 'carriers.pth' --data_augmentation random --epochs 10 --img_paths 'cifar10_images/0/29.png,cifar10_images/0/77.png' --lambda_ft_l2 '0.01' --lambda_l2_img '0.0005' --marking_network 'pretrained_resnet18.pth' --dump_path './cifar10_marked' --optimizer 'sgd,lr=1.0' --exp_id "cifar10_marked"
                                     crop_size: 224
                                     data_augmentation: random
                                     debug: False
                                     debug_slurm: False
                                     debug_train: False
                                     dump_path: ./cifar10_marked
                                     epochs: 10
                                     exp_id: cifar10_marked
                                     exp_name: bypass
                                     half_cone: True
                                     img_list: None
                                     img_paths: cifar10_images/0/29.png,cifar10_images/0/77.png
                                     img_size: 256
                                     lambda_ft_l2: 0.01
                                     lambda_l2_img: 0.0005
                                     marking_network: pretrained_resnet18.pth
                                     optimizer: sgd,lr=1.0
                                     radius: 10
INFO - 01/07/26 12:09:53 - 0:00:00 - The experiment will be stored in ./cifar10_marked
                                     
INFO - 01/07/26 12:09:53 - 0:00:00 - Running command: python mark_embed.py --carrier_id 0 --carrier_path 'carriers.pth' --data_augmentation random --epochs 10 --img_paths 'cifar10_images/0/29.png,cifar10_images/0/77.png' --lambda_ft_l2 '0.01' --lambda_l2_img '0.0005' --marking_network 'pretrained_resnet18.pth' --dump_path './cifar10_marked' --optimizer 'sgd,lr=1.0'

INFO - 01/07/26 12:10:00 - 0:00:07 - Model: ResNet(
                                       (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
                                       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                       (relu): ReLU(inplace=True)
                                       (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
                                       (layer1): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer2): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer3): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer4): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
                                       (fc): Linear(in_features=512, out_features=10, bias=True)
                                     )
DEBUG - 01/07/26 12:10:00 - 0:00:07 - STREAM b'IHDR' 16 13
DEBUG - 01/07/26 12:10:00 - 0:00:07 - STREAM b'IDAT' 41 2006
DEBUG - 01/07/26 12:10:00 - 0:00:07 - STREAM b'IHDR' 16 13
DEBUG - 01/07/26 12:10:00 - 0:00:07 - STREAM b'IDAT' 41 2124
INFO - 01/07/26 12:16:56 - 0:07:01 - Schedule of sgd,lr=1.0: None
INFO - 01/07/26 12:42:55 - 0:33:00 - __log__:{"keyword": "iteration", "loss": -0.7459368705749512, "loss_ft": -0.9499750733375549, "loss_norm": 0.0, "loss_ft_l2": 0.20403820276260376}
INFO - 01/07/26 12:49:38 - 0:39:45 - __log__:{"keyword": "iteration", "loss": -0.3540421426296234, "loss_ft": -0.6782321929931641, "loss_norm": 0.012810735031962395, "loss_ft_l2": 0.3113793432712555}
INFO - 01/07/26 12:49:38 - 0:39:45 - __log__:{"keyword": "iteration", "loss": -1.540642261505127, "loss_ft": -1.8736023902893066, "loss_norm": 0.015929190441966057, "loss_ft_l2": 0.3170308470726013}
INFO - 01/07/26 12:49:38 - 0:39:45 - __log__:{"keyword": "iteration", "loss": -0.37048986554145813, "loss_ft": -0.6645864248275757, "loss_norm": 0.019131693989038467, "loss_ft_l2": 0.274964839220047}
INFO - 01/07/26 12:49:38 - 0:39:45 - __log__:{"keyword": "iteration", "loss": -0.5430179834365845, "loss_ft": -0.9290995001792908, "loss_norm": 0.02226368337869644, "loss_ft_l2": 0.36381784081459045}
INFO - 01/07/26 12:49:38 - 0:39:45 - __log__:{"keyword": "iteration", "loss": -2.201988458633423, "loss_ft": -2.4863686561584473, "loss_norm": 0.02488679252564907, "loss_ft_l2": 0.25949329137802124}
INFO - 01/07/26 12:49:38 - 0:39:45 - __log__:{"keyword": "iteration", "loss": -3.6760811805725098, "loss_ft": -4.010416507720947, "loss_norm": 0.027109406888484955, "loss_ft_l2": 0.30722588300704956}
INFO - 01/07/26 12:49:38 - 0:39:45 - __log__:{"keyword": "iteration", "loss": -4.298068523406982, "loss_ft": -4.649529457092285, "loss_norm": 0.02809717319905758, "loss_ft_l2": 0.3233637809753418}
INFO - 01/07/26 12:49:38 - 0:39:45 - __log__:{"keyword": "iteration", "loss": -0.26605144143104553, "loss_ft": -0.628282904624939, "loss_norm": 0.03033285215497017, "loss_ft_l2": 0.33189859986305237}
INFO - 01/07/26 12:49:38 - 0:39:45 - __log__:{"keyword": "iteration", "loss": -3.0644378662109375, "loss_ft": -3.4050257205963135, "loss_norm": 0.032008592039346695, "loss_ft_l2": 0.30857914686203003}
INFO - 01/07/26 12:53:32 - 0:43:37 - __log__:{"keyword": "final", "psnr": 32.77513613679342, "ft_direction": 2.3268566131591797, "ft_norm": 13.51157283782959, "rho": -1, "R": -369.73455810546875}
INFO - 01/13/26 20:12:58 - 0:00:00 - ============ Initialized logger ============
INFO - 01/13/26 20:12:58 - 0:00:00 - angle: None
                                     carrier_id: 0
                                     carrier_path: carriers.pth
                                     command: python make_data_radioactive.py --carrier_id 0 --carrier_path 'carriers.pth' --data_augmentation random --epochs 200 --img_paths 'cifar10_images/0/29.png,cifar10_images/0/77.png' --lambda_ft_l2 '0.01' --lambda_l2_img '0.0005' --marking_network 'pretrained_resnet18.pth' --dump_path './cifar10_marked' --optimizer 'sgd,lr=1.0' --exp_id "cifar10_marked"
                                     crop_size: 224
                                     data_augmentation: random
                                     debug: False
                                     debug_slurm: False
                                     debug_train: False
                                     dump_path: ./cifar10_marked
                                     epochs: 200
                                     exp_id: cifar10_marked
                                     exp_name: bypass
                                     half_cone: True
                                     img_list: None
                                     img_paths: cifar10_images/0/29.png,cifar10_images/0/77.png
                                     img_size: 256
                                     lambda_ft_l2: 0.01
                                     lambda_l2_img: 0.0005
                                     marking_network: pretrained_resnet18.pth
                                     optimizer: sgd,lr=1.0
                                     radius: 10
INFO - 01/13/26 20:12:58 - 0:00:00 - The experiment will be stored in ./cifar10_marked
                                     
INFO - 01/13/26 20:12:58 - 0:00:00 - Running command: python make_data_radioactive.py --carrier_id 0 --carrier_path 'carriers.pth' --data_augmentation random --epochs 200 --img_paths 'cifar10_images/0/29.png,cifar10_images/0/77.png' --lambda_ft_l2 '0.01' --lambda_l2_img '0.0005' --marking_network 'pretrained_resnet18.pth' --dump_path './cifar10_marked' --optimizer 'sgd,lr=1.0'

INFO - 01/13/26 20:12:59 - 0:00:01 - Model: ResNet(
                                       (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
                                       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                       (relu): ReLU(inplace=True)
                                       (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
                                       (layer1): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer2): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer3): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer4): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
                                       (fc): Linear(in_features=512, out_features=10, bias=True)
                                     )
DEBUG - 01/13/26 20:13:00 - 0:00:02 - STREAM b'IHDR' 16 13
DEBUG - 01/13/26 20:13:00 - 0:00:02 - STREAM b'IDAT' 41 2006
DEBUG - 01/13/26 20:13:00 - 0:00:02 - STREAM b'IHDR' 16 13
DEBUG - 01/13/26 20:13:00 - 0:00:02 - STREAM b'IDAT' 41 2124
INFO - 01/13/26 20:13:00 - 0:00:02 - Schedule of sgd,lr=1.0: None
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": 0.9947700500488281, "loss_ft": 0.7146996259689331, "loss_norm": 0.0, "loss_ft_l2": 0.280070424079895}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -0.44182223081588745, "loss_ft": -0.7584845423698425, "loss_norm": 0.008365263231098652, "loss_ft_l2": 0.3082970380783081}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": 0.503883957862854, "loss_ft": 0.1993260383605957, "loss_norm": 0.014818880707025528, "loss_ft_l2": 0.28973904252052307}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -0.652583122253418, "loss_ft": -0.909479022026062, "loss_norm": 0.018580880016088486, "loss_ft_l2": 0.23831504583358765}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -1.3940669298171997, "loss_ft": -1.741302490234375, "loss_norm": 0.021982133388519287, "loss_ft_l2": 0.32525333762168884}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": 0.07414403557777405, "loss_ft": -0.3676791191101074, "loss_norm": 0.023923136293888092, "loss_ft_l2": 0.417900025844574}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -1.6836200952529907, "loss_ft": -2.045365333557129, "loss_norm": 0.02512708120048046, "loss_ft_l2": 0.3366180658340454}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -2.6052799224853516, "loss_ft": -2.9386539459228516, "loss_norm": 0.026296593248844147, "loss_ft_l2": 0.3070773184299469}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -0.5630636215209961, "loss_ft": -0.9541763663291931, "loss_norm": 0.02874268963932991, "loss_ft_l2": 0.362370103597641}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -2.232574701309204, "loss_ft": -2.563096284866333, "loss_norm": 0.02968609146773815, "loss_ft_l2": 0.300835520029068}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -4.8470282554626465, "loss_ft": -5.1714301109313965, "loss_norm": 0.031044375151395798, "loss_ft_l2": 0.2933572232723236}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -1.4302403926849365, "loss_ft": -1.848787546157837, "loss_norm": 0.032372936606407166, "loss_ft_l2": 0.3861742317676544}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -0.4213119447231293, "loss_ft": -0.8329205513000488, "loss_norm": 0.032536499202251434, "loss_ft_l2": 0.3790720999240875}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -3.6663715839385986, "loss_ft": -4.030710220336914, "loss_norm": 0.032940588891506195, "loss_ft_l2": 0.33139801025390625}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -3.8588244915008545, "loss_ft": -4.244610786437988, "loss_norm": 0.034170523285865784, "loss_ft_l2": 0.3516155779361725}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -2.2229044437408447, "loss_ft": -2.6107897758483887, "loss_norm": 0.03589276969432831, "loss_ft_l2": 0.3519926071166992}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -1.571143388748169, "loss_ft": -1.9729993343353271, "loss_norm": 0.03608794882893562, "loss_ft_l2": 0.3657680153846741}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -2.4266676902770996, "loss_ft": -2.7741236686706543, "loss_norm": 0.03666308894753456, "loss_ft_l2": 0.3107929825782776}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -3.0647072792053223, "loss_ft": -3.494570016860962, "loss_norm": 0.036714404821395874, "loss_ft_l2": 0.3931483030319214}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -2.326416254043579, "loss_ft": -2.6860127449035645, "loss_norm": 0.03638066351413727, "loss_ft_l2": 0.3232157826423645}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -2.120239734649658, "loss_ft": -2.5148699283599854, "loss_norm": 0.03673294186592102, "loss_ft_l2": 0.35789719223976135}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -4.645823955535889, "loss_ft": -5.031992435455322, "loss_norm": 0.03671746701002121, "loss_ft_l2": 0.34945106506347656}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -4.937434196472168, "loss_ft": -5.369912624359131, "loss_norm": 0.03871701657772064, "loss_ft_l2": 0.39376139640808105}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -1.844238519668579, "loss_ft": -2.21797251701355, "loss_norm": 0.039518751204013824, "loss_ft_l2": 0.3342152237892151}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -2.385050058364868, "loss_ft": -2.778427839279175, "loss_norm": 0.039864346385002136, "loss_ft_l2": 0.3535133898258209}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -2.7926998138427734, "loss_ft": -3.18973708152771, "loss_norm": 0.04015194624662399, "loss_ft_l2": 0.35688555240631104}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -3.124847888946533, "loss_ft": -3.5133156776428223, "loss_norm": 0.03985244408249855, "loss_ft_l2": 0.3486153781414032}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -4.027181148529053, "loss_ft": -4.377525329589844, "loss_norm": 0.040546756237745285, "loss_ft_l2": 0.3097974359989166}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -6.6680450439453125, "loss_ft": -7.054961681365967, "loss_norm": 0.041655782610177994, "loss_ft_l2": 0.34526047110557556}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -0.880056619644165, "loss_ft": -1.3097507953643799, "loss_norm": 0.04236188530921936, "loss_ft_l2": 0.3873322904109955}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -7.284547805786133, "loss_ft": -7.695374488830566, "loss_norm": 0.042602892965078354, "loss_ft_l2": 0.36822381615638733}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -4.241154670715332, "loss_ft": -4.673466682434082, "loss_norm": 0.042432960122823715, "loss_ft_l2": 0.389879435300827}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -5.005745887756348, "loss_ft": -5.3807268142700195, "loss_norm": 0.04263882339000702, "loss_ft_l2": 0.3323422968387604}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -4.835394859313965, "loss_ft": -5.244758605957031, "loss_norm": 0.04316899925470352, "loss_ft_l2": 0.36619484424591064}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": 0.12127593159675598, "loss_ft": -0.323641300201416, "loss_norm": 0.04369240626692772, "loss_ft_l2": 0.401224821805954}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -4.9832763671875, "loss_ft": -5.374176025390625, "loss_norm": 0.043455056846141815, "loss_ft_l2": 0.34744447469711304}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -4.4610514640808105, "loss_ft": -4.885505199432373, "loss_norm": 0.04419999569654465, "loss_ft_l2": 0.3802536725997925}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -0.6782437562942505, "loss_ft": -1.1075258255004883, "loss_norm": 0.04431701451539993, "loss_ft_l2": 0.38496506214141846}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -1.8146871328353882, "loss_ft": -2.208373785018921, "loss_norm": 0.04394087940454483, "loss_ft_l2": 0.34974589943885803}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -2.166008472442627, "loss_ft": -2.561506748199463, "loss_norm": 0.044426046311855316, "loss_ft_l2": 0.35107237100601196}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -2.102205753326416, "loss_ft": -2.519197940826416, "loss_norm": 0.044013023376464844, "loss_ft_l2": 0.3729792833328247}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -2.690833806991577, "loss_ft": -3.1282663345336914, "loss_norm": 0.04300297796726227, "loss_ft_l2": 0.394429475069046}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -3.1485860347747803, "loss_ft": -3.5855374336242676, "loss_norm": 0.04313534498214722, "loss_ft_l2": 0.39381593465805054}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -4.338159561157227, "loss_ft": -4.778246879577637, "loss_norm": 0.04344407469034195, "loss_ft_l2": 0.39664337038993835}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -0.4242032766342163, "loss_ft": -0.8713514804840088, "loss_norm": 0.04408838599920273, "loss_ft_l2": 0.40305984020233154}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -5.582370281219482, "loss_ft": -5.940717697143555, "loss_norm": 0.04359510540962219, "loss_ft_l2": 0.3147522211074829}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": 0.16293571889400482, "loss_ft": -0.29136836528778076, "loss_norm": 0.04442380741238594, "loss_ft_l2": 0.40988028049468994}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -0.44699788093566895, "loss_ft": -0.8683865666389465, "loss_norm": 0.04421401768922806, "loss_ft_l2": 0.3771746754646301}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": 0.04436853528022766, "loss_ft": -0.41685211658477783, "loss_norm": 0.043780021369457245, "loss_ft_l2": 0.41744062304496765}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -1.2359343767166138, "loss_ft": -1.6566152572631836, "loss_norm": 0.04394998773932457, "loss_ft_l2": 0.37673094868659973}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -4.565028190612793, "loss_ft": -4.956912994384766, "loss_norm": 0.04325350373983383, "loss_ft_l2": 0.348631352186203}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -1.1196308135986328, "loss_ft": -1.5328359603881836, "loss_norm": 0.042341817170381546, "loss_ft_l2": 0.3708633482456207}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -4.8834428787231445, "loss_ft": -5.257493019104004, "loss_norm": 0.04279828444123268, "loss_ft_l2": 0.33125174045562744}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -4.794577121734619, "loss_ft": -5.213043689727783, "loss_norm": 0.04310869425535202, "loss_ft_l2": 0.37535804510116577}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -0.2762612998485565, "loss_ft": -0.7426652908325195, "loss_norm": 0.04405878484249115, "loss_ft_l2": 0.42234519124031067}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -2.7634594440460205, "loss_ft": -3.178438186645508, "loss_norm": 0.04399845376610756, "loss_ft_l2": 0.3709802031517029}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -1.7434459924697876, "loss_ft": -2.1610395908355713, "loss_norm": 0.044047653675079346, "loss_ft_l2": 0.3735460340976715}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -0.11575406789779663, "loss_ft": -0.5701334476470947, "loss_norm": 0.04360207915306091, "loss_ft_l2": 0.4107772707939148}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": 0.23738573491573334, "loss_ft": -0.21572411060333252, "loss_norm": 0.04348050057888031, "loss_ft_l2": 0.40962934494018555}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -0.3480677604675293, "loss_ft": -0.783378541469574, "loss_norm": 0.04357481375336647, "loss_ft_l2": 0.3917359709739685}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -2.37510085105896, "loss_ft": -2.783778667449951, "loss_norm": 0.043423060327768326, "loss_ft_l2": 0.36525458097457886}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -3.08976674079895, "loss_ft": -3.4869418144226074, "loss_norm": 0.04326816648244858, "loss_ft_l2": 0.3539068400859833}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -1.9090567827224731, "loss_ft": -2.336529493331909, "loss_norm": 0.043780617415905, "loss_ft_l2": 0.3836921751499176}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -2.1937344074249268, "loss_ft": -2.612309694290161, "loss_norm": 0.04360730201005936, "loss_ft_l2": 0.3749679625034332}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -0.522551417350769, "loss_ft": -0.9586647152900696, "loss_norm": 0.04421570152044296, "loss_ft_l2": 0.39189764857292175}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -5.069334030151367, "loss_ft": -5.485459327697754, "loss_norm": 0.044325754046440125, "loss_ft_l2": 0.3717992305755615}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -3.5339534282684326, "loss_ft": -3.970384359359741, "loss_norm": 0.04390585795044899, "loss_ft_l2": 0.3925248682498932}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -2.0886728763580322, "loss_ft": -2.476898193359375, "loss_norm": 0.04440874606370926, "loss_ft_l2": 0.3438166081905365}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -3.4143364429473877, "loss_ft": -3.7783284187316895, "loss_norm": 0.04467438906431198, "loss_ft_l2": 0.31931766867637634}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -3.150888681411743, "loss_ft": -3.5697743892669678, "loss_norm": 0.045163560658693314, "loss_ft_l2": 0.37372198700904846}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -4.608210563659668, "loss_ft": -5.0178914070129395, "loss_norm": 0.04496217519044876, "loss_ft_l2": 0.36471837759017944}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -1.548852562904358, "loss_ft": -1.937440276145935, "loss_norm": 0.04405888915061951, "loss_ft_l2": 0.34452879428863525}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": 0.36495891213417053, "loss_ft": -0.08118849992752075, "loss_norm": 0.04382748156785965, "loss_ft_l2": 0.40231993794441223}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -2.468998432159424, "loss_ft": -2.851365566253662, "loss_norm": 0.043978769332170486, "loss_ft_l2": 0.3383883237838745}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -2.831794023513794, "loss_ft": -3.2007102966308594, "loss_norm": 0.04410441964864731, "loss_ft_l2": 0.32481199502944946}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -0.6849580407142639, "loss_ft": -1.123760461807251, "loss_norm": 0.044260136783123016, "loss_ft_l2": 0.39454227685928345}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -2.297588586807251, "loss_ft": -2.7344858646392822, "loss_norm": 0.04450373724102974, "loss_ft_l2": 0.392393559217453}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -2.212341785430908, "loss_ft": -2.6472392082214355, "loss_norm": 0.045231811702251434, "loss_ft_l2": 0.3896656632423401}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -1.6533769369125366, "loss_ft": -2.0607924461364746, "loss_norm": 0.045413002371788025, "loss_ft_l2": 0.36200252175331116}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -3.725764036178589, "loss_ft": -4.134152889251709, "loss_norm": 0.04498513415455818, "loss_ft_l2": 0.36340364813804626}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -0.525955319404602, "loss_ft": -0.9896948337554932, "loss_norm": 0.044742826372385025, "loss_ft_l2": 0.418996661901474}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -2.5485734939575195, "loss_ft": -2.9624829292297363, "loss_norm": 0.04353896528482437, "loss_ft_l2": 0.3703705072402954}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -5.0208210945129395, "loss_ft": -5.373374938964844, "loss_norm": 0.044249165803194046, "loss_ft_l2": 0.30830466747283936}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -6.0768280029296875, "loss_ft": -6.504134178161621, "loss_norm": 0.04489557072520256, "loss_ft_l2": 0.38241061568260193}
INFO - 01/13/26 20:13:08 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -1.3155455589294434, "loss_ft": -1.6971421241760254, "loss_norm": 0.04605201631784439, "loss_ft_l2": 0.3355446457862854}
INFO - 01/13/26 20:13:09 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -2.1884093284606934, "loss_ft": -2.6101632118225098, "loss_norm": 0.045705411583185196, "loss_ft_l2": 0.3760485053062439}
INFO - 01/13/26 20:13:09 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -1.8184890747070312, "loss_ft": -2.211095094680786, "loss_norm": 0.04565197229385376, "loss_ft_l2": 0.3469541370868683}
INFO - 01/13/26 20:13:09 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -2.9753129482269287, "loss_ft": -3.3166160583496094, "loss_norm": 0.04496600851416588, "loss_ft_l2": 0.29633718729019165}
INFO - 01/13/26 20:13:09 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -2.4577488899230957, "loss_ft": -2.85180926322937, "loss_norm": 0.045571889728307724, "loss_ft_l2": 0.34848859906196594}
INFO - 01/13/26 20:13:09 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -4.401674747467041, "loss_ft": -4.76119327545166, "loss_norm": 0.04490010440349579, "loss_ft_l2": 0.31461846828460693}
INFO - 01/13/26 20:13:09 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -3.339484691619873, "loss_ft": -3.7660741806030273, "loss_norm": 0.04601796716451645, "loss_ft_l2": 0.380571573972702}
INFO - 01/13/26 20:13:09 - 0:00:10 - __log__:{"keyword": "iteration", "loss": -3.5506844520568848, "loss_ft": -4.006185054779053, "loss_norm": 0.04580377787351608, "loss_ft_l2": 0.4096967875957489}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -4.276220321655273, "loss_ft": -4.707296848297119, "loss_norm": 0.045629825443029404, "loss_ft_l2": 0.3854464888572693}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -2.546797752380371, "loss_ft": -2.981574296951294, "loss_norm": 0.045713089406490326, "loss_ft_l2": 0.3890634775161743}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -1.3852165937423706, "loss_ft": -1.8040831089019775, "loss_norm": 0.04530978947877884, "loss_ft_l2": 0.3735567331314087}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -1.6857430934906006, "loss_ft": -2.102598190307617, "loss_norm": 0.04474809020757675, "loss_ft_l2": 0.37210702896118164}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -5.247779369354248, "loss_ft": -5.618074417114258, "loss_norm": 0.04463019222021103, "loss_ft_l2": 0.3256652057170868}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -2.2239625453948975, "loss_ft": -2.6382617950439453, "loss_norm": 0.045460741966962814, "loss_ft_l2": 0.3688386380672455}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -1.195185899734497, "loss_ft": -1.6266120672225952, "loss_norm": 0.04610837996006012, "loss_ft_l2": 0.3853178322315216}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -1.483030915260315, "loss_ft": -1.8839343786239624, "loss_norm": 0.04563024640083313, "loss_ft_l2": 0.3552732765674591}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -2.152205228805542, "loss_ft": -2.519352674484253, "loss_norm": 0.04531969502568245, "loss_ft_l2": 0.32182762026786804}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -1.0362305641174316, "loss_ft": -1.4493896961212158, "loss_norm": 0.04435648024082184, "loss_ft_l2": 0.3688026964664459}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -3.035202980041504, "loss_ft": -3.4225263595581055, "loss_norm": 0.04454375430941582, "loss_ft_l2": 0.3427796959877014}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -2.6664297580718994, "loss_ft": -3.0409607887268066, "loss_norm": 0.04463513195514679, "loss_ft_l2": 0.3298960328102112}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -4.295400619506836, "loss_ft": -4.627620697021484, "loss_norm": 0.0454166904091835, "loss_ft_l2": 0.2868030369281769}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -2.0867197513580322, "loss_ft": -2.504746198654175, "loss_norm": 0.04548279196023941, "loss_ft_l2": 0.3725435435771942}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -5.007979869842529, "loss_ft": -5.379151344299316, "loss_norm": 0.045106250792741776, "loss_ft_l2": 0.32606491446495056}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -4.8875627517700195, "loss_ft": -5.287295818328857, "loss_norm": 0.045151323080062866, "loss_ft_l2": 0.35458189249038696}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -5.527613639831543, "loss_ft": -5.930544376373291, "loss_norm": 0.045773137360811234, "loss_ft_l2": 0.357157826423645}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -3.4268670082092285, "loss_ft": -3.8011114597320557, "loss_norm": 0.04612593352794647, "loss_ft_l2": 0.32811862230300903}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -1.819983959197998, "loss_ft": -2.212423324584961, "loss_norm": 0.045827947556972504, "loss_ft_l2": 0.34661149978637695}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -2.9756035804748535, "loss_ft": -3.3562111854553223, "loss_norm": 0.045468684285879135, "loss_ft_l2": 0.33513903617858887}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -5.06691312789917, "loss_ft": -5.433526992797852, "loss_norm": 0.046218059957027435, "loss_ft_l2": 0.3203958570957184}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -4.821929454803467, "loss_ft": -5.216667175292969, "loss_norm": 0.045734431594610214, "loss_ft_l2": 0.34900352358818054}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -6.313345432281494, "loss_ft": -6.709421634674072, "loss_norm": 0.04513167217373848, "loss_ft_l2": 0.35094472765922546}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -2.460409641265869, "loss_ft": -2.905925750732422, "loss_norm": 0.0465228296816349, "loss_ft_l2": 0.39899322390556335}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -3.026463508605957, "loss_ft": -3.4286465644836426, "loss_norm": 0.04561667889356613, "loss_ft_l2": 0.35656654834747314}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -2.023358106613159, "loss_ft": -2.4896814823150635, "loss_norm": 0.04534120485186577, "loss_ft_l2": 0.4209820330142975}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -0.8727412223815918, "loss_ft": -1.2888174057006836, "loss_norm": 0.045742832124233246, "loss_ft_l2": 0.37033331394195557}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -3.403040885925293, "loss_ft": -3.855468273162842, "loss_norm": 0.045876942574977875, "loss_ft_l2": 0.4065503478050232}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -1.4682170152664185, "loss_ft": -1.8826990127563477, "loss_norm": 0.046074483543634415, "loss_ft_l2": 0.3684075176715851}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -3.0809035301208496, "loss_ft": -3.4724786281585693, "loss_norm": 0.04544561728835106, "loss_ft_l2": 0.3461294174194336}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -2.9548583030700684, "loss_ft": -3.377394437789917, "loss_norm": 0.04592788591980934, "loss_ft_l2": 0.3766081929206848}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -3.442070960998535, "loss_ft": -3.8346476554870605, "loss_norm": 0.04568862169981003, "loss_ft_l2": 0.3468880355358124}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -4.981247425079346, "loss_ft": -5.3589887619018555, "loss_norm": 0.045582570135593414, "loss_ft_l2": 0.332158625125885}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -6.432725429534912, "loss_ft": -6.811794757843018, "loss_norm": 0.04565662890672684, "loss_ft_l2": 0.3334128260612488}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -2.6451056003570557, "loss_ft": -3.032179832458496, "loss_norm": 0.04647456482052803, "loss_ft_l2": 0.34059974551200867}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -3.5042834281921387, "loss_ft": -3.9155068397521973, "loss_norm": 0.046285491436719894, "loss_ft_l2": 0.3649381101131439}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -0.7163723707199097, "loss_ft": -1.1535139083862305, "loss_norm": 0.046173568814992905, "loss_ft_l2": 0.39096799492836}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -2.9601943492889404, "loss_ft": -3.357006311416626, "loss_norm": 0.04586314782500267, "loss_ft_l2": 0.3509487509727478}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -3.11710262298584, "loss_ft": -3.5336837768554688, "loss_norm": 0.04602644592523575, "loss_ft_l2": 0.3705545663833618}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -4.262748718261719, "loss_ft": -4.643613815307617, "loss_norm": 0.04508369415998459, "loss_ft_l2": 0.3357818126678467}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -0.7736404538154602, "loss_ft": -1.2205870151519775, "loss_norm": 0.046060800552368164, "loss_ft_l2": 0.40088576078414917}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -2.6440625190734863, "loss_ft": -3.0741615295410156, "loss_norm": 0.046052977442741394, "loss_ft_l2": 0.38404616713523865}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -2.272500991821289, "loss_ft": -2.627549409866333, "loss_norm": 0.044929929077625275, "loss_ft_l2": 0.3101184368133545}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -0.07930299639701843, "loss_ft": -0.5195140838623047, "loss_norm": 0.04618726670742035, "loss_ft_l2": 0.3940238058567047}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -0.9713668823242188, "loss_ft": -1.4145320653915405, "loss_norm": 0.04574394226074219, "loss_ft_l2": 0.397421270608902}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -0.649992048740387, "loss_ft": -1.0956443548202515, "loss_norm": 0.045731909573078156, "loss_ft_l2": 0.39992040395736694}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -2.330653429031372, "loss_ft": -2.7223455905914307, "loss_norm": 0.046075865626335144, "loss_ft_l2": 0.34561628103256226}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -1.7022768259048462, "loss_ft": -2.12166166305542, "loss_norm": 0.04587501659989357, "loss_ft_l2": 0.3735097348690033}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -3.5057568550109863, "loss_ft": -3.8988444805145264, "loss_norm": 0.045707881450653076, "loss_ft_l2": 0.3473796844482422}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -2.1820855140686035, "loss_ft": -2.5608057975769043, "loss_norm": 0.04455535113811493, "loss_ft_l2": 0.33416473865509033}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -4.652594566345215, "loss_ft": -5.031170845031738, "loss_norm": 0.0459064245223999, "loss_ft_l2": 0.3326699137687683}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -2.8171422481536865, "loss_ft": -3.242249011993408, "loss_norm": 0.044967275112867355, "loss_ft_l2": 0.38013967871665955}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -5.334252834320068, "loss_ft": -5.72429895401001, "loss_norm": 0.04623415321111679, "loss_ft_l2": 0.34381186962127686}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -2.7349936962127686, "loss_ft": -3.144913673400879, "loss_norm": 0.046253107488155365, "loss_ft_l2": 0.363666832447052}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -1.286526083946228, "loss_ft": -1.7166193723678589, "loss_norm": 0.04595524072647095, "loss_ft_l2": 0.3841380178928375}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -4.5880303382873535, "loss_ft": -4.970089912414551, "loss_norm": 0.04613629728555679, "loss_ft_l2": 0.33592313528060913}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -5.396801471710205, "loss_ft": -5.770155906677246, "loss_norm": 0.04575174301862717, "loss_ft_l2": 0.32760265469551086}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -3.5428922176361084, "loss_ft": -3.9896512031555176, "loss_norm": 0.04660249501466751, "loss_ft_l2": 0.40015658736228943}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -7.465190887451172, "loss_ft": -7.903373718261719, "loss_norm": 0.04695484787225723, "loss_ft_l2": 0.39122816920280457}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -0.05171513557434082, "loss_ft": -0.4876519441604614, "loss_norm": 0.045530132949352264, "loss_ft_l2": 0.39040666818618774}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -1.649462342262268, "loss_ft": -2.0713326930999756, "loss_norm": 0.04568583145737648, "loss_ft_l2": 0.3761846125125885}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -3.779249668121338, "loss_ft": -4.174294471740723, "loss_norm": 0.04611353576183319, "loss_ft_l2": 0.34893134236335754}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -4.206514358520508, "loss_ft": -4.637933731079102, "loss_norm": 0.046012744307518005, "loss_ft_l2": 0.38540640473365784}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -6.497552871704102, "loss_ft": -6.888759613037109, "loss_norm": 0.045443207025527954, "loss_ft_l2": 0.3457636833190918}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -4.510451316833496, "loss_ft": -4.899372100830078, "loss_norm": 0.04696056619286537, "loss_ft_l2": 0.341960608959198}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -5.617388725280762, "loss_ft": -6.06846284866333, "loss_norm": 0.04684833064675331, "loss_ft_l2": 0.4042259454727173}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -0.42593368887901306, "loss_ft": -0.8605605363845825, "loss_norm": 0.046875935047864914, "loss_ft_l2": 0.38775089383125305}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -4.517824649810791, "loss_ft": -4.993697166442871, "loss_norm": 0.04645321145653725, "loss_ft_l2": 0.42941930890083313}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -0.8907790184020996, "loss_ft": -1.3143093585968018, "loss_norm": 0.04680821672081947, "loss_ft_l2": 0.3767220973968506}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -2.3236582279205322, "loss_ft": -2.7199723720550537, "loss_norm": 0.04501352459192276, "loss_ft_l2": 0.35130077600479126}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -4.433413505554199, "loss_ft": -4.876222610473633, "loss_norm": 0.04647594690322876, "loss_ft_l2": 0.39633315801620483}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -6.4537553787231445, "loss_ft": -6.841870307922363, "loss_norm": 0.0467182919383049, "loss_ft_l2": 0.3413967788219452}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -5.042122840881348, "loss_ft": -5.442320823669434, "loss_norm": 0.04710801690816879, "loss_ft_l2": 0.3530896306037903}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -2.7313826084136963, "loss_ft": -3.1475844383239746, "loss_norm": 0.04750286787748337, "loss_ft_l2": 0.3686991035938263}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -0.9838889837265015, "loss_ft": -1.4290075302124023, "loss_norm": 0.047357622534036636, "loss_ft_l2": 0.39776086807250977}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -5.6950297355651855, "loss_ft": -6.090012073516846, "loss_norm": 0.04699919745326042, "loss_ft_l2": 0.3479832410812378}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -2.2538866996765137, "loss_ft": -2.6778581142425537, "loss_norm": 0.04708598926663399, "loss_ft_l2": 0.37688544392585754}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -2.5235400199890137, "loss_ft": -2.9380295276641846, "loss_norm": 0.04682479053735733, "loss_ft_l2": 0.3676649034023285}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -1.1633522510528564, "loss_ft": -1.611846685409546, "loss_norm": 0.04647170007228851, "loss_ft_l2": 0.4020227789878845}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -1.754734754562378, "loss_ft": -2.1328635215759277, "loss_norm": 0.04527905210852623, "loss_ft_l2": 0.3328497111797333}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -4.704263210296631, "loss_ft": -5.107276439666748, "loss_norm": 0.045929811894893646, "loss_ft_l2": 0.357083261013031}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -2.396973133087158, "loss_ft": -2.7946393489837646, "loss_norm": 0.045641377568244934, "loss_ft_l2": 0.3520246744155884}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -1.523374080657959, "loss_ft": -1.9838929176330566, "loss_norm": 0.0464455783367157, "loss_ft_l2": 0.4140731990337372}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -2.0938892364501953, "loss_ft": -2.513394355773926, "loss_norm": 0.046738192439079285, "loss_ft_l2": 0.37276703119277954}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -1.9563229084014893, "loss_ft": -2.3821706771850586, "loss_norm": 0.04711226373910904, "loss_ft_l2": 0.37873557209968567}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -3.9744296073913574, "loss_ft": -4.466638565063477, "loss_norm": 0.04697165638208389, "loss_ft_l2": 0.44523707032203674}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -3.138685464859009, "loss_ft": -3.547307014465332, "loss_norm": 0.04705594852566719, "loss_ft_l2": 0.36156558990478516}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -3.2805986404418945, "loss_ft": -3.687406539916992, "loss_norm": 0.046300217509269714, "loss_ft_l2": 0.3605077266693115}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -1.9327062368392944, "loss_ft": -2.349443197250366, "loss_norm": 0.046492889523506165, "loss_ft_l2": 0.3702441453933716}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -2.0242512226104736, "loss_ft": -2.4061639308929443, "loss_norm": 0.045241571962833405, "loss_ft_l2": 0.33667102456092834}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -6.772315502166748, "loss_ft": -7.1700639724731445, "loss_norm": 0.04580873250961304, "loss_ft_l2": 0.35193976759910583}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -1.1965539455413818, "loss_ft": -1.6319055557250977, "loss_norm": 0.04613891988992691, "loss_ft_l2": 0.3892127275466919}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -3.5411550998687744, "loss_ft": -3.898768901824951, "loss_norm": 0.0455436185002327, "loss_ft_l2": 0.3120700716972351}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -2.391627311706543, "loss_ft": -2.7917213439941406, "loss_norm": 0.045784223824739456, "loss_ft_l2": 0.35430991649627686}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -3.2295475006103516, "loss_ft": -3.613696813583374, "loss_norm": 0.04586194083094597, "loss_ft_l2": 0.338287353515625}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -3.8301351070404053, "loss_ft": -4.248615264892578, "loss_norm": 0.045349135994911194, "loss_ft_l2": 0.3731309473514557}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -6.2166266441345215, "loss_ft": -6.634792804718018, "loss_norm": 0.045290425419807434, "loss_ft_l2": 0.3728756010532379}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -0.4765578806400299, "loss_ft": -0.916620671749115, "loss_norm": 0.04596034064888954, "loss_ft_l2": 0.39410242438316345}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -0.5773842930793762, "loss_ft": -1.0397133827209473, "loss_norm": 0.04668675363063812, "loss_ft_l2": 0.41564232110977173}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -2.2921016216278076, "loss_ft": -2.7034552097320557, "loss_norm": 0.045401431620121, "loss_ft_l2": 0.3659522235393524}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -4.9668402671813965, "loss_ft": -5.358327865600586, "loss_norm": 0.04584050551056862, "loss_ft_l2": 0.3456469774246216}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -4.39214563369751, "loss_ft": -4.816620826721191, "loss_norm": 0.04675879701972008, "loss_ft_l2": 0.3777163326740265}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -2.9930124282836914, "loss_ft": -3.423569917678833, "loss_norm": 0.04714275896549225, "loss_ft_l2": 0.3834148049354553}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -0.7720655798912048, "loss_ft": -1.2320468425750732, "loss_norm": 0.0464119017124176, "loss_ft_l2": 0.4135693907737732}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -1.8427982330322266, "loss_ft": -2.259296417236328, "loss_norm": 0.04631275683641434, "loss_ft_l2": 0.37018531560897827}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -3.9496874809265137, "loss_ft": -4.291709899902344, "loss_norm": 0.046525947749614716, "loss_ft_l2": 0.29549652338027954}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -6.177505970001221, "loss_ft": -6.543992042541504, "loss_norm": 0.04645337909460068, "loss_ft_l2": 0.3200325071811676}
INFO - 01/13/26 20:13:09 - 0:00:11 - __log__:{"keyword": "iteration", "loss": -1.9059957265853882, "loss_ft": -2.32633376121521, "loss_norm": 0.046926893293857574, "loss_ft_l2": 0.37341105937957764}
INFO - 01/13/26 20:13:10 - 0:00:12 - __log__:{"keyword": "final", "psnr": 31.31849219777517, "ft_direction": 3.300861358642578, "ft_norm": 16.90309715270996, "rho": -1, "R": -582.856201171875}
INFO - 01/13/26 20:16:18 - 0:00:00 - ============ Initialized logger ============
INFO - 01/13/26 20:16:18 - 0:00:00 - angle: None
                                     carrier_id: 0
                                     carrier_path: carriers.pth
                                     command: python make_data_radioactive.py --carrier_id 0 --carrier_path 'carriers.pth' --data_augmentation random --epochs 200 --img_paths 'cifar10_images/0/29.png,cifar10_images/0/77.png' --lambda_ft_l2 '0.01' --lambda_l2_img '0.0005' --marking_network 'pretrained_resnet18.pth' --dump_path './cifar10_marked' --optimizer 'sgd,lr=1.0' --exp_id "cifar10_marked"
                                     crop_size: 224
                                     data_augmentation: random
                                     debug: False
                                     debug_slurm: False
                                     debug_train: False
                                     dump_path: ./cifar10_marked
                                     epochs: 200
                                     exp_id: cifar10_marked
                                     exp_name: bypass
                                     half_cone: True
                                     img_list: None
                                     img_paths: cifar10_images/0/29.png,cifar10_images/0/77.png
                                     img_size: 256
                                     lambda_ft_l2: 0.01
                                     lambda_l2_img: 0.0005
                                     marking_network: pretrained_resnet18.pth
                                     optimizer: sgd,lr=1.0
                                     radius: 10
INFO - 01/13/26 20:16:18 - 0:00:00 - The experiment will be stored in ./cifar10_marked
                                     
INFO - 01/13/26 20:16:18 - 0:00:00 - Running command: python make_data_radioactive.py --carrier_id 0 --carrier_path 'carriers.pth' --data_augmentation random --epochs 200 --img_paths 'cifar10_images/0/29.png,cifar10_images/0/77.png' --lambda_ft_l2 '0.01' --lambda_l2_img '0.0005' --marking_network 'pretrained_resnet18.pth' --dump_path './cifar10_marked' --optimizer 'sgd,lr=1.0'

INFO - 01/13/26 20:16:18 - 0:00:00 - Model: ResNet(
                                       (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
                                       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                       (relu): ReLU(inplace=True)
                                       (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
                                       (layer1): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer2): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer3): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer4): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
                                       (fc): Linear(in_features=512, out_features=10, bias=True)
                                     )
DEBUG - 01/13/26 20:16:18 - 0:00:00 - STREAM b'IHDR' 16 13
DEBUG - 01/13/26 20:16:18 - 0:00:00 - STREAM b'IDAT' 41 2006
DEBUG - 01/13/26 20:16:18 - 0:00:00 - STREAM b'IHDR' 16 13
DEBUG - 01/13/26 20:16:18 - 0:00:00 - STREAM b'IDAT' 41 2124
INFO - 01/13/26 20:16:18 - 0:00:00 - Schedule of sgd,lr=1.0: None
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": 0.48248612880706787, "loss_ft": 0.17231345176696777, "loss_norm": 0.0, "loss_ft_l2": 0.3101726770401001}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.247795820236206, "loss_ft": -1.557666540145874, "loss_norm": 0.008978158235549927, "loss_ft_l2": 0.30089253187179565}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.2245359420776367, "loss_ft": -1.5233372449874878, "loss_norm": 0.01657196879386902, "loss_ft_l2": 0.28222933411598206}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.6375281810760498, "loss_ft": -0.9865967631340027, "loss_norm": 0.020063335075974464, "loss_ft_l2": 0.32900527119636536}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.9577744007110596, "loss_ft": -1.316573143005371, "loss_norm": 0.022319193929433823, "loss_ft_l2": 0.336479514837265}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.2462432384490967, "loss_ft": -3.609002113342285, "loss_norm": 0.02365986257791519, "loss_ft_l2": 0.3390989303588867}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.8642932176589966, "loss_ft": -2.1698813438415527, "loss_norm": 0.025024855509400368, "loss_ft_l2": 0.28056320548057556}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.732246994972229, "loss_ft": -2.1141204833984375, "loss_norm": 0.02705739066004753, "loss_ft_l2": 0.35481610894203186}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.7809431552886963, "loss_ft": -4.10330867767334, "loss_norm": 0.02801906317472458, "loss_ft_l2": 0.29434657096862793}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.176359176635742, "loss_ft": -3.51815128326416, "loss_norm": 0.029104553163051605, "loss_ft_l2": 0.31268757581710815}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": 0.04151830077171326, "loss_ft": -0.3849688172340393, "loss_norm": 0.030346905812621117, "loss_ft_l2": 0.3961402177810669}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.080954074859619, "loss_ft": -4.405142784118652, "loss_norm": 0.030311118811368942, "loss_ft_l2": 0.2938775420188904}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.639475107192993, "loss_ft": -4.014274597167969, "loss_norm": 0.03209957852959633, "loss_ft_l2": 0.34269994497299194}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.6581859588623047, "loss_ft": -2.0483291149139404, "loss_norm": 0.03319467231631279, "loss_ft_l2": 0.3569483160972595}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.1575727462768555, "loss_ft": -1.557076096534729, "loss_norm": 0.03391076624393463, "loss_ft_l2": 0.3655925691127777}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.250603675842285, "loss_ft": -2.633585214614868, "loss_norm": 0.033580925315618515, "loss_ft_l2": 0.34940046072006226}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.5627245903015137, "loss_ft": -3.944826126098633, "loss_norm": 0.034719403833150864, "loss_ft_l2": 0.34738197922706604}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.925382673740387, "loss_ft": -1.3139233589172363, "loss_norm": 0.034701839089393616, "loss_ft_l2": 0.35383886098861694}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.851637363433838, "loss_ft": -3.2223057746887207, "loss_norm": 0.03588090464472771, "loss_ft_l2": 0.3347876965999603}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.5617945194244385, "loss_ft": -1.9675601720809937, "loss_norm": 0.03661404177546501, "loss_ft_l2": 0.3691515326499939}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.9306263327598572, "loss_ft": -1.3456631898880005, "loss_norm": 0.03699897602200508, "loss_ft_l2": 0.37803786993026733}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.0426509380340576, "loss_ft": -3.4032437801361084, "loss_norm": 0.03696022182703018, "loss_ft_l2": 0.32363277673721313}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.415469169616699, "loss_ft": -4.759909629821777, "loss_norm": 0.038141872733831406, "loss_ft_l2": 0.30629879236221313}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.1278890371322632, "loss_ft": -1.5445950031280518, "loss_norm": 0.038006268441677094, "loss_ft_l2": 0.3786996304988861}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -5.108644008636475, "loss_ft": -5.467546463012695, "loss_norm": 0.038040876388549805, "loss_ft_l2": 0.32086116075515747}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.9587122797966003, "loss_ft": -1.3857357501983643, "loss_norm": 0.039186760783195496, "loss_ft_l2": 0.387836754322052}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.776867389678955, "loss_ft": -5.134632110595703, "loss_norm": 0.03860313817858696, "loss_ft_l2": 0.3191615641117096}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.7252291440963745, "loss_ft": -2.154989004135132, "loss_norm": 0.03964564949274063, "loss_ft_l2": 0.3901142179965973}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -6.929532051086426, "loss_ft": -7.314927101135254, "loss_norm": 0.0395503044128418, "loss_ft_l2": 0.3458445370197296}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.580897808074951, "loss_ft": -3.995906352996826, "loss_norm": 0.0400615930557251, "loss_ft_l2": 0.37494713068008423}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.536677360534668, "loss_ft": -2.934709072113037, "loss_norm": 0.04052002727985382, "loss_ft_l2": 0.35751163959503174}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.444018602371216, "loss_ft": -2.849788188934326, "loss_norm": 0.03976636379957199, "loss_ft_l2": 0.3660033643245697}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.4260966777801514, "loss_ft": -1.8588457107543945, "loss_norm": 0.04019206017255783, "loss_ft_l2": 0.3925570547580719}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -5.549492359161377, "loss_ft": -5.907195091247559, "loss_norm": 0.0403415709733963, "loss_ft_l2": 0.3173612654209137}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": 0.28751635551452637, "loss_ft": -0.15974152088165283, "loss_norm": 0.041569486260414124, "loss_ft_l2": 0.40568840503692627}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.5037807822227478, "loss_ft": -0.9519239664077759, "loss_norm": 0.04150048643350601, "loss_ft_l2": 0.4066426753997803}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.397412300109863, "loss_ft": -4.804084777832031, "loss_norm": 0.04061882197856903, "loss_ft_l2": 0.3660537600517273}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.2788374423980713, "loss_ft": -3.68650484085083, "loss_norm": 0.04147719591856003, "loss_ft_l2": 0.3661902844905853}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.300942301750183, "loss_ft": -1.6839451789855957, "loss_norm": 0.04101874306797981, "loss_ft_l2": 0.3419841229915619}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.7609254717826843, "loss_ft": -1.1959187984466553, "loss_norm": 0.042674049735069275, "loss_ft_l2": 0.3923192620277405}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.4320223331451416, "loss_ft": -2.8924460411071777, "loss_norm": 0.04262576252222061, "loss_ft_l2": 0.41779807209968567}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.387892484664917, "loss_ft": -3.7536449432373047, "loss_norm": 0.04190905764698982, "loss_ft_l2": 0.323843389749527}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.686630964279175, "loss_ft": -4.113533973693848, "loss_norm": 0.042021431028842926, "loss_ft_l2": 0.3848816454410553}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.868063449859619, "loss_ft": -3.267282724380493, "loss_norm": 0.04192641004920006, "loss_ft_l2": 0.35729286074638367}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.2513080835342407, "loss_ft": -1.7134029865264893, "loss_norm": 0.042668431997299194, "loss_ft_l2": 0.41942641139030457}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.7622127532958984, "loss_ft": -4.120735168457031, "loss_norm": 0.04289916902780533, "loss_ft_l2": 0.31562340259552}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -6.300142288208008, "loss_ft": -6.68137264251709, "loss_norm": 0.042969971895217896, "loss_ft_l2": 0.3382599949836731}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -5.299892902374268, "loss_ft": -5.697694778442383, "loss_norm": 0.04340223968029022, "loss_ft_l2": 0.3543994724750519}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -7.189277172088623, "loss_ft": -7.597318649291992, "loss_norm": 0.04349474981427193, "loss_ft_l2": 0.3645465672016144}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.2636513710021973, "loss_ft": -2.6941051483154297, "loss_norm": 0.04365590214729309, "loss_ft_l2": 0.38679778575897217}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.648930311203003, "loss_ft": -3.0548923015594482, "loss_norm": 0.04340643435716629, "loss_ft_l2": 0.3625555634498596}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.05460524559021, "loss_ft": -2.3944687843322754, "loss_norm": 0.042320843786001205, "loss_ft_l2": 0.2975427806377411}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.238459587097168, "loss_ft": -4.619544506072998, "loss_norm": 0.042506515979766846, "loss_ft_l2": 0.33857834339141846}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.590662956237793, "loss_ft": -4.951735496520996, "loss_norm": 0.04289446771144867, "loss_ft_l2": 0.31817826628685}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.0173022747039795, "loss_ft": -3.4249961376190186, "loss_norm": 0.0431661531329155, "loss_ft_l2": 0.3645276427268982}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.3369228839874268, "loss_ft": -3.7421488761901855, "loss_norm": 0.04296354949474335, "loss_ft_l2": 0.362262487411499}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.7711840867996216, "loss_ft": -2.1801466941833496, "loss_norm": 0.04345864802598953, "loss_ft_l2": 0.3655039370059967}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.15243804454803467, "loss_ft": -0.6166480779647827, "loss_norm": 0.04378018528223038, "loss_ft_l2": 0.4204298257827759}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.573472499847412, "loss_ft": -1.9960134029388428, "loss_norm": 0.04387810453772545, "loss_ft_l2": 0.3786628246307373}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.6730995178222656, "loss_ft": -4.034382343292236, "loss_norm": 0.04322802275419235, "loss_ft_l2": 0.3180548846721649}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.709200620651245, "loss_ft": -4.1620283126831055, "loss_norm": 0.04437301307916641, "loss_ft_l2": 0.40845468640327454}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.165814399719238, "loss_ft": -4.555361270904541, "loss_norm": 0.043406739830970764, "loss_ft_l2": 0.346140056848526}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.1837732791900635, "loss_ft": -3.592585563659668, "loss_norm": 0.043402642011642456, "loss_ft_l2": 0.3654097020626068}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.0665713548660278, "loss_ft": -1.5167176723480225, "loss_norm": 0.04409250244498253, "loss_ft_l2": 0.4060538113117218}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.5694072246551514, "loss_ft": -2.9656097888946533, "loss_norm": 0.04386340081691742, "loss_ft_l2": 0.3523391783237457}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.2923829555511475, "loss_ft": -1.6922578811645508, "loss_norm": 0.044014208018779755, "loss_ft_l2": 0.3558606505393982}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.330026149749756, "loss_ft": -4.725312232971191, "loss_norm": 0.04453207552433014, "loss_ft_l2": 0.3507538139820099}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.4630577564239502, "loss_ft": -1.8433023691177368, "loss_norm": 0.04475398361682892, "loss_ft_l2": 0.33549055457115173}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.2905044555664062, "loss_ft": -3.7441601753234863, "loss_norm": 0.04450032860040665, "loss_ft_l2": 0.40915533900260925}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.1415555477142334, "loss_ft": -1.5516623258590698, "loss_norm": 0.043953459709882736, "loss_ft_l2": 0.36615338921546936}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.5367823243141174, "loss_ft": -0.9289636611938477, "loss_norm": 0.04500642046332359, "loss_ft_l2": 0.3471749424934387}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.3466851711273193, "loss_ft": -2.7311720848083496, "loss_norm": 0.04413966089487076, "loss_ft_l2": 0.3403473496437073}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -5.061315536499023, "loss_ft": -5.469723224639893, "loss_norm": 0.04371512308716774, "loss_ft_l2": 0.36469268798828125}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.505866050720215, "loss_ft": -2.914475440979004, "loss_norm": 0.04398484528064728, "loss_ft_l2": 0.36462461948394775}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.0193514823913574, "loss_ft": -1.4536762237548828, "loss_norm": 0.04403314366936684, "loss_ft_l2": 0.3902915120124817}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.30164048075675964, "loss_ft": -0.755238950252533, "loss_norm": 0.04369568079710007, "loss_ft_l2": 0.40990278124809265}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.2459638118743896, "loss_ft": -1.6621779203414917, "loss_norm": 0.04375700652599335, "loss_ft_l2": 0.3724571764469147}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.832444667816162, "loss_ft": -3.229233741760254, "loss_norm": 0.044121067970991135, "loss_ft_l2": 0.35266801714897156}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.5115106105804443, "loss_ft": -2.9256367683410645, "loss_norm": 0.044881824404001236, "loss_ft_l2": 0.3692443072795868}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.121152639389038, "loss_ft": -2.553713798522949, "loss_norm": 0.044520530849695206, "loss_ft_l2": 0.3880404531955719}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.033289432525635, "loss_ft": -4.39591121673584, "loss_norm": 0.04467102512717247, "loss_ft_l2": 0.3179507553577423}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.2377610206604004, "loss_ft": -1.677361011505127, "loss_norm": 0.044011712074279785, "loss_ft_l2": 0.3955882489681244}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.972980499267578, "loss_ft": -3.3397397994995117, "loss_norm": 0.04385741800069809, "loss_ft_l2": 0.3229019045829773}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.578772783279419, "loss_ft": -3.0025267601013184, "loss_norm": 0.04464458301663399, "loss_ft_l2": 0.37910929322242737}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.662079930305481, "loss_ft": -2.1105949878692627, "loss_norm": 0.04458210617303848, "loss_ft_l2": 0.4039328992366791}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.798114776611328, "loss_ft": -4.184404373168945, "loss_norm": 0.044932425022125244, "loss_ft_l2": 0.34135735034942627}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.100653886795044, "loss_ft": -3.5065088272094727, "loss_norm": 0.04402384161949158, "loss_ft_l2": 0.3618311882019043}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.9958871603012085, "loss_ft": -2.4335124492645264, "loss_norm": 0.04469504952430725, "loss_ft_l2": 0.39293015003204346}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.3721197247505188, "loss_ft": -0.7950578331947327, "loss_norm": 0.04405331611633301, "loss_ft_l2": 0.37888479232788086}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.9969637393951416, "loss_ft": -4.364939212799072, "loss_norm": 0.04462303966283798, "loss_ft_l2": 0.323352575302124}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.2595579624176025, "loss_ft": -2.670015335083008, "loss_norm": 0.04509560018777847, "loss_ft_l2": 0.365361750125885}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.131788969039917, "loss_ft": -1.5098249912261963, "loss_norm": 0.04400011897087097, "loss_ft_l2": 0.33403587341308594}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.31118631362915, "loss_ft": -4.707310199737549, "loss_norm": 0.044742390513420105, "loss_ft_l2": 0.35138145089149475}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.4046630859375, "loss_ft": -4.771697044372559, "loss_norm": 0.04395502060651779, "loss_ft_l2": 0.32307904958724976}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.5074408054351807, "loss_ft": -1.9298193454742432, "loss_norm": 0.04493897780776024, "loss_ft_l2": 0.37743955850601196}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.59006929397583, "loss_ft": -3.02726149559021, "loss_norm": 0.0444992259144783, "loss_ft_l2": 0.3926929533481598}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -5.002984523773193, "loss_ft": -5.395351409912109, "loss_norm": 0.044218916445970535, "loss_ft_l2": 0.3481479585170746}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.416831374168396, "loss_ft": -1.8672200441360474, "loss_norm": 0.045698441565036774, "loss_ft_l2": 0.4046902656555176}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.994774580001831, "loss_ft": -3.434657096862793, "loss_norm": 0.04580425098538399, "loss_ft_l2": 0.3940783143043518}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.487530708312988, "loss_ft": -4.864496231079102, "loss_norm": 0.04563923180103302, "loss_ft_l2": 0.33132636547088623}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.1449062824249268, "loss_ft": -3.5547194480895996, "loss_norm": 0.045036427676677704, "loss_ft_l2": 0.3647768795490265}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.715984344482422, "loss_ft": -4.120318412780762, "loss_norm": 0.0443960502743721, "loss_ft_l2": 0.35993826389312744}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -5.072602272033691, "loss_ft": -5.448508262634277, "loss_norm": 0.04497472941875458, "loss_ft_l2": 0.33093130588531494}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.472891330718994, "loss_ft": -3.913147449493408, "loss_norm": 0.04591680318117142, "loss_ft_l2": 0.39433932304382324}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.2602951526641846, "loss_ft": -2.637726068496704, "loss_norm": 0.04597608000040054, "loss_ft_l2": 0.3314547538757324}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.228710889816284, "loss_ft": -3.6610031127929688, "loss_norm": 0.04559425264596939, "loss_ft_l2": 0.386697918176651}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.386559009552002, "loss_ft": -3.808140277862549, "loss_norm": 0.04517509788274765, "loss_ft_l2": 0.37640631198883057}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -6.744104385375977, "loss_ft": -7.15483283996582, "loss_norm": 0.045238152146339417, "loss_ft_l2": 0.36549049615859985}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -6.0478925704956055, "loss_ft": -6.439383506774902, "loss_norm": 0.04540757089853287, "loss_ft_l2": 0.3460830748081207}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.7696726322174072, "loss_ft": -3.174757957458496, "loss_norm": 0.04702012240886688, "loss_ft_l2": 0.35806506872177124}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.3234267234802246, "loss_ft": -2.736588954925537, "loss_norm": 0.04624006524682045, "loss_ft_l2": 0.36692214012145996}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.685892343521118, "loss_ft": -4.088640213012695, "loss_norm": 0.046183690428733826, "loss_ft_l2": 0.3565642833709717}
INFO - 01/13/26 20:16:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.6468632221221924, "loss_ft": -4.036911964416504, "loss_norm": 0.04647279903292656, "loss_ft_l2": 0.34357595443725586}
INFO - 01/13/26 20:16:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.736559867858887, "loss_ft": -5.159333229064941, "loss_norm": 0.046428486704826355, "loss_ft_l2": 0.37634482979774475}
INFO - 01/13/26 20:16:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.718681335449219, "loss_ft": -5.093960285186768, "loss_norm": 0.04529266804456711, "loss_ft_l2": 0.3299858868122101}
INFO - 01/13/26 20:16:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.395565509796143, "loss_ft": -4.7853288650512695, "loss_norm": 0.04636441916227341, "loss_ft_l2": 0.3433990478515625}
INFO - 01/13/26 20:16:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.6263521909713745, "loss_ft": -2.04482364654541, "loss_norm": 0.046690210700035095, "loss_ft_l2": 0.37178125977516174}
INFO - 01/13/26 20:16:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.130502700805664, "loss_ft": -4.560040473937988, "loss_norm": 0.04631790518760681, "loss_ft_l2": 0.383219838142395}
INFO - 01/13/26 20:16:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -5.52869987487793, "loss_ft": -5.899413585662842, "loss_norm": 0.045557498931884766, "loss_ft_l2": 0.3251562714576721}
INFO - 01/13/26 20:16:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -3.5195798873901367, "loss_ft": -3.9390573501586914, "loss_norm": 0.04569367319345474, "loss_ft_l2": 0.37378379702568054}
INFO - 01/13/26 20:16:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -5.284663677215576, "loss_ft": -5.644343376159668, "loss_norm": 0.045524962246418, "loss_ft_l2": 0.3141544759273529}
INFO - 01/13/26 20:16:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -0.9384554624557495, "loss_ft": -1.3682126998901367, "loss_norm": 0.044981908053159714, "loss_ft_l2": 0.384775310754776}
INFO - 01/13/26 20:16:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.1814703941345215, "loss_ft": -4.573707103729248, "loss_norm": 0.044822581112384796, "loss_ft_l2": 0.3474138677120209}
INFO - 01/13/26 20:16:21 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.0316009521484375, "loss_ft": -4.417449951171875, "loss_norm": 0.04557608813047409, "loss_ft_l2": 0.3402731120586395}
INFO - 01/13/26 20:16:21 - 0:00:03 - __log__:{"keyword": "iteration", "loss": -3.153949022293091, "loss_ft": -3.557633399963379, "loss_norm": 0.04572219029068947, "loss_ft_l2": 0.3579621911048889}
INFO - 01/13/26 20:16:21 - 0:00:03 - __log__:{"keyword": "iteration", "loss": -6.879920482635498, "loss_ft": -7.299243450164795, "loss_norm": 0.045218612998723984, "loss_ft_l2": 0.3741046190261841}
INFO - 01/13/26 20:16:21 - 0:00:03 - __log__:{"keyword": "iteration", "loss": -2.4655277729034424, "loss_ft": -2.9051997661590576, "loss_norm": 0.046110849827528, "loss_ft_l2": 0.39356115460395813}
INFO - 01/13/26 20:16:21 - 0:00:03 - __log__:{"keyword": "iteration", "loss": -4.875776290893555, "loss_ft": -5.289334297180176, "loss_norm": 0.0467517152428627, "loss_ft_l2": 0.3668067455291748}
INFO - 01/13/26 20:16:21 - 0:00:03 - __log__:{"keyword": "iteration", "loss": -5.82310152053833, "loss_ft": -6.258740425109863, "loss_norm": 0.046694424003362656, "loss_ft_l2": 0.3889448046684265}
INFO - 01/13/26 20:16:21 - 0:00:03 - __log__:{"keyword": "iteration", "loss": -1.5381174087524414, "loss_ft": -1.92722487449646, "loss_norm": 0.04578418284654617, "loss_ft_l2": 0.343323290348053}
INFO - 01/13/26 20:16:21 - 0:00:03 - __log__:{"keyword": "iteration", "loss": -2.395641803741455, "loss_ft": -2.8019025325775146, "loss_norm": 0.0456508994102478, "loss_ft_l2": 0.36060988903045654}
INFO - 01/13/26 20:16:21 - 0:00:03 - __log__:{"keyword": "iteration", "loss": -5.97437047958374, "loss_ft": -6.361281871795654, "loss_norm": 0.04559837281703949, "loss_ft_l2": 0.34131285548210144}
INFO - 01/13/26 20:16:21 - 0:00:03 - __log__:{"keyword": "iteration", "loss": -2.602726459503174, "loss_ft": -3.0201854705810547, "loss_norm": 0.045580945909023285, "loss_ft_l2": 0.3718782365322113}
INFO - 01/13/26 20:16:21 - 0:00:03 - __log__:{"keyword": "iteration", "loss": -2.8550612926483154, "loss_ft": -3.287750244140625, "loss_norm": 0.04607082158327103, "loss_ft_l2": 0.3866181969642639}
INFO - 01/13/26 20:16:22 - 0:00:03 - __log__:{"keyword": "iteration", "loss": -0.7438130974769592, "loss_ft": -1.177621841430664, "loss_norm": 0.045316215604543686, "loss_ft_l2": 0.38849252462387085}
INFO - 01/13/26 20:16:22 - 0:00:03 - __log__:{"keyword": "iteration", "loss": -3.0178394317626953, "loss_ft": -3.405709743499756, "loss_norm": 0.044790688902139664, "loss_ft_l2": 0.34307944774627686}
INFO - 01/13/26 20:16:22 - 0:00:03 - __log__:{"keyword": "iteration", "loss": -3.4436802864074707, "loss_ft": -3.8521769046783447, "loss_norm": 0.0453517809510231, "loss_ft_l2": 0.36314481496810913}
INFO - 01/13/26 20:16:22 - 0:00:03 - __log__:{"keyword": "iteration", "loss": -6.462934970855713, "loss_ft": -6.84293270111084, "loss_norm": 0.045902203768491745, "loss_ft_l2": 0.3340955674648285}
INFO - 01/13/26 20:16:22 - 0:00:03 - __log__:{"keyword": "iteration", "loss": 0.47932446002960205, "loss_ft": 0.0024743080139160156, "loss_norm": 0.046496644616127014, "loss_ft_l2": 0.4303535223007202}
INFO - 01/13/26 20:16:22 - 0:00:03 - __log__:{"keyword": "iteration", "loss": -0.6481541395187378, "loss_ft": -1.1117846965789795, "loss_norm": 0.046161770820617676, "loss_ft_l2": 0.41746875643730164}
INFO - 01/13/26 20:16:22 - 0:00:03 - __log__:{"keyword": "iteration", "loss": -2.0615527629852295, "loss_ft": -2.47039532661438, "loss_norm": 0.04613611102104187, "loss_ft_l2": 0.3627064526081085}
INFO - 01/13/26 20:16:22 - 0:00:03 - __log__:{"keyword": "iteration", "loss": -5.656968116760254, "loss_ft": -6.031335830688477, "loss_norm": 0.046239420771598816, "loss_ft_l2": 0.32812827825546265}
INFO - 01/13/26 20:16:22 - 0:00:03 - __log__:{"keyword": "iteration", "loss": -3.7110393047332764, "loss_ft": -4.159138202667236, "loss_norm": 0.045925889164209366, "loss_ft_l2": 0.40217283368110657}
INFO - 01/13/26 20:16:22 - 0:00:03 - __log__:{"keyword": "iteration", "loss": -2.6724555492401123, "loss_ft": -3.070796251296997, "loss_norm": 0.04554435983300209, "loss_ft_l2": 0.35279640555381775}
INFO - 01/13/26 20:16:22 - 0:00:03 - __log__:{"keyword": "iteration", "loss": -5.324097633361816, "loss_ft": -5.730698585510254, "loss_norm": 0.04575745388865471, "loss_ft_l2": 0.3608434498310089}
INFO - 01/13/26 20:16:22 - 0:00:03 - __log__:{"keyword": "iteration", "loss": -6.874328136444092, "loss_ft": -7.282451152801514, "loss_norm": 0.0473177544772625, "loss_ft_l2": 0.36080503463745117}
INFO - 01/13/26 20:16:22 - 0:00:03 - __log__:{"keyword": "iteration", "loss": -5.221673488616943, "loss_ft": -5.64237117767334, "loss_norm": 0.04735288769006729, "loss_ft_l2": 0.3733450174331665}
INFO - 01/13/26 20:16:22 - 0:00:03 - __log__:{"keyword": "iteration", "loss": -1.583636999130249, "loss_ft": -2.022970676422119, "loss_norm": 0.0466073676943779, "loss_ft_l2": 0.39272627234458923}
INFO - 01/13/26 20:16:22 - 0:00:03 - __log__:{"keyword": "iteration", "loss": -4.6736674308776855, "loss_ft": -5.076897144317627, "loss_norm": 0.046414658427238464, "loss_ft_l2": 0.35681480169296265}
INFO - 01/13/26 20:16:22 - 0:00:03 - __log__:{"keyword": "iteration", "loss": -1.4652806520462036, "loss_ft": -1.8704719543457031, "loss_norm": 0.046376295387744904, "loss_ft_l2": 0.3588149845600128}
INFO - 01/13/26 20:16:22 - 0:00:03 - __log__:{"keyword": "iteration", "loss": -2.7751450538635254, "loss_ft": -3.1931214332580566, "loss_norm": 0.046161748468875885, "loss_ft_l2": 0.3718147277832031}
INFO - 01/13/26 20:16:22 - 0:00:03 - __log__:{"keyword": "iteration", "loss": -3.4754769802093506, "loss_ft": -3.8867156505584717, "loss_norm": 0.04524601995944977, "loss_ft_l2": 0.36599257588386536}
INFO - 01/13/26 20:16:22 - 0:00:03 - __log__:{"keyword": "iteration", "loss": -1.5023291110992432, "loss_ft": -1.9450740814208984, "loss_norm": 0.04547397047281265, "loss_ft_l2": 0.3972710967063904}
INFO - 01/13/26 20:16:22 - 0:00:03 - __log__:{"keyword": "iteration", "loss": -1.1963369846343994, "loss_ft": -1.6369158029556274, "loss_norm": 0.04563325643539429, "loss_ft_l2": 0.39494559168815613}
INFO - 01/13/26 20:16:22 - 0:00:03 - __log__:{"keyword": "iteration", "loss": -4.071468353271484, "loss_ft": -4.434635162353516, "loss_norm": 0.045515671372413635, "loss_ft_l2": 0.3176513910293579}
INFO - 01/13/26 20:16:22 - 0:00:03 - __log__:{"keyword": "iteration", "loss": -0.8523252606391907, "loss_ft": -1.2869598865509033, "loss_norm": 0.04602767154574394, "loss_ft_l2": 0.3886069655418396}
INFO - 01/13/26 20:16:22 - 0:00:03 - __log__:{"keyword": "iteration", "loss": -6.743640422821045, "loss_ft": -7.135006427764893, "loss_norm": 0.04535217955708504, "loss_ft_l2": 0.3460139334201813}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -0.5125744342803955, "loss_ft": -0.9570971131324768, "loss_norm": 0.04658765345811844, "loss_ft_l2": 0.39793503284454346}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -1.444634199142456, "loss_ft": -1.8793472051620483, "loss_norm": 0.045903731137514114, "loss_ft_l2": 0.3888092637062073}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "iteration", "loss": 0.3490743041038513, "loss_ft": -0.10643839836120605, "loss_norm": 0.04530138522386551, "loss_ft_l2": 0.41021132469177246}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -5.959708213806152, "loss_ft": -6.3748297691345215, "loss_norm": 0.04543249309062958, "loss_ft_l2": 0.3696889281272888}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -5.164095401763916, "loss_ft": -5.531410217285156, "loss_norm": 0.0457773357629776, "loss_ft_l2": 0.321537584066391}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -2.9683852195739746, "loss_ft": -3.3720550537109375, "loss_norm": 0.04694981127977371, "loss_ft_l2": 0.356719970703125}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -3.2133629322052, "loss_ft": -3.6491494178771973, "loss_norm": 0.0461951419711113, "loss_ft_l2": 0.3895915150642395}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -4.834589004516602, "loss_ft": -5.213741779327393, "loss_norm": 0.04617413133382797, "loss_ft_l2": 0.3329787254333496}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -5.610966682434082, "loss_ft": -6.02212381362915, "loss_norm": 0.04647964984178543, "loss_ft_l2": 0.3646776080131531}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -3.640010118484497, "loss_ft": -4.022261619567871, "loss_norm": 0.04649893194437027, "loss_ft_l2": 0.33575254678726196}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -3.2922346591949463, "loss_ft": -3.702646493911743, "loss_norm": 0.04610108211636543, "loss_ft_l2": 0.36431074142456055}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -1.5464532375335693, "loss_ft": -1.956573486328125, "loss_norm": 0.04628998041152954, "loss_ft_l2": 0.3638303577899933}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -2.041252613067627, "loss_ft": -2.4563567638397217, "loss_norm": 0.04623987525701523, "loss_ft_l2": 0.36886435747146606}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -3.252976655960083, "loss_ft": -3.6531310081481934, "loss_norm": 0.04668154567480087, "loss_ft_l2": 0.35347265005111694}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -3.243281364440918, "loss_ft": -3.6794557571411133, "loss_norm": 0.045390717685222626, "loss_ft_l2": 0.3907838463783264}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "iteration", "loss": 0.43348586559295654, "loss_ft": -0.04807639122009277, "loss_norm": 0.04578427970409393, "loss_ft_l2": 0.4357779622077942}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -1.1877355575561523, "loss_ft": -1.6232496500015259, "loss_norm": 0.045786745846271515, "loss_ft_l2": 0.3897273540496826}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -4.810678482055664, "loss_ft": -5.210873126983643, "loss_norm": 0.045873768627643585, "loss_ft_l2": 0.35432112216949463}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -1.931627869606018, "loss_ft": -2.3587093353271484, "loss_norm": 0.046222321689128876, "loss_ft_l2": 0.38085922598838806}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -3.7677392959594727, "loss_ft": -4.184308052062988, "loss_norm": 0.046137984842061996, "loss_ft_l2": 0.37043097615242004}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -0.9569268226623535, "loss_ft": -1.3692400455474854, "loss_norm": 0.04572062939405441, "loss_ft_l2": 0.3665926158428192}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -6.12379264831543, "loss_ft": -6.503291606903076, "loss_norm": 0.04558006674051285, "loss_ft_l2": 0.33391886949539185}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -0.9831205010414124, "loss_ft": -1.4167335033416748, "loss_norm": 0.04634399712085724, "loss_ft_l2": 0.38726896047592163}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -3.664107084274292, "loss_ft": -4.081661701202393, "loss_norm": 0.046346694231033325, "loss_ft_l2": 0.3712078630924225}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -4.10753059387207, "loss_ft": -4.504776954650879, "loss_norm": 0.04482228308916092, "loss_ft_l2": 0.35242408514022827}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -3.7700798511505127, "loss_ft": -4.137692451477051, "loss_norm": 0.04588443040847778, "loss_ft_l2": 0.32172802090644836}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -3.8287758827209473, "loss_ft": -4.240048885345459, "loss_norm": 0.04656563699245453, "loss_ft_l2": 0.36470744013786316}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -5.320716857910156, "loss_ft": -5.717462539672852, "loss_norm": 0.04620300233364105, "loss_ft_l2": 0.3505427837371826}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -3.9836745262145996, "loss_ft": -4.41420841217041, "loss_norm": 0.04691760241985321, "loss_ft_l2": 0.38361647725105286}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -2.650657892227173, "loss_ft": -3.06524920463562, "loss_norm": 0.045923274010419846, "loss_ft_l2": 0.3686680495738983}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -3.2466299533843994, "loss_ft": -3.6399035453796387, "loss_norm": 0.04534384608268738, "loss_ft_l2": 0.3479297459125519}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -4.312155246734619, "loss_ft": -4.6913957595825195, "loss_norm": 0.04617716372013092, "loss_ft_l2": 0.33306291699409485}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -5.242807388305664, "loss_ft": -5.5911102294921875, "loss_norm": 0.045395754277706146, "loss_ft_l2": 0.3029070496559143}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -5.384836196899414, "loss_ft": -5.760740280151367, "loss_norm": 0.04661796987056732, "loss_ft_l2": 0.3292863368988037}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -0.24054819345474243, "loss_ft": -0.707838773727417, "loss_norm": 0.04671884700655937, "loss_ft_l2": 0.4205717444419861}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -5.134051322937012, "loss_ft": -5.532327175140381, "loss_norm": 0.0465710386633873, "loss_ft_l2": 0.35170477628707886}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -3.2753684520721436, "loss_ft": -3.675981044769287, "loss_norm": 0.04715391993522644, "loss_ft_l2": 0.35345861315727234}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -4.118440628051758, "loss_ft": -4.522566795349121, "loss_norm": 0.047574594616889954, "loss_ft_l2": 0.35655179619789124}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -3.4856061935424805, "loss_ft": -3.9127821922302246, "loss_norm": 0.0465717539191246, "loss_ft_l2": 0.38060423731803894}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -4.174336910247803, "loss_ft": -4.562704086303711, "loss_norm": 0.047560859471559525, "loss_ft_l2": 0.34080666303634644}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -3.9022445678710938, "loss_ft": -4.278426647186279, "loss_norm": 0.04731166362762451, "loss_ft_l2": 0.3288702070713043}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -3.3425521850585938, "loss_ft": -3.759916305541992, "loss_norm": 0.047559842467308044, "loss_ft_l2": 0.36980438232421875}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -0.734586238861084, "loss_ft": -1.182464838027954, "loss_norm": 0.04766060411930084, "loss_ft_l2": 0.40021803975105286}
INFO - 01/13/26 20:16:22 - 0:00:04 - __log__:{"keyword": "final", "psnr": 31.261670493864344, "ft_direction": 3.4689278602600098, "ft_norm": 17.714902877807617, "cosine_mean": 0.19189073145389557, "rho": -1, "R": -640.6713256835938}
INFO - 01/13/26 20:16:54 - 0:00:00 - ============ Initialized logger ============
INFO - 01/13/26 20:16:54 - 0:00:00 - angle: None
                                     carrier_id: 0
                                     carrier_path: carriers.pth
                                     command: python make_data_radioactive.py --carrier_id 0 --carrier_path 'carriers.pth' --data_augmentation random --epochs 200 --img_paths 'cifar10_images/0/29.png,cifar10_images/0/77.png' --lambda_ft_l2 '0.01' --lambda_l2_img '0.0005' --marking_network 'pretrained_resnet18.pth' --dump_path './cifar10_marked' --optimizer 'sgd,lr=1.0' --exp_id "cifar10_marked"
                                     crop_size: 224
                                     data_augmentation: random
                                     debug: False
                                     debug_slurm: False
                                     debug_train: False
                                     dump_path: ./cifar10_marked
                                     epochs: 200
                                     exp_id: cifar10_marked
                                     exp_name: bypass
                                     half_cone: True
                                     img_list: None
                                     img_paths: cifar10_images/0/29.png,cifar10_images/0/77.png
                                     img_size: 256
                                     lambda_ft_l2: 0.01
                                     lambda_l2_img: 0.0005
                                     marking_network: pretrained_resnet18.pth
                                     optimizer: sgd,lr=1.0
                                     radius: 10
INFO - 01/13/26 20:16:54 - 0:00:00 - The experiment will be stored in ./cifar10_marked
                                     
INFO - 01/13/26 20:16:54 - 0:00:00 - Running command: python make_data_radioactive.py --carrier_id 0 --carrier_path 'carriers.pth' --data_augmentation random --epochs 200 --img_paths 'cifar10_images/0/29.png,cifar10_images/0/77.png' --lambda_ft_l2 '0.01' --lambda_l2_img '0.0005' --marking_network 'pretrained_resnet18.pth' --dump_path './cifar10_marked' --optimizer 'sgd,lr=1.0'

INFO - 01/13/26 20:16:54 - 0:00:00 - Model: ResNet(
                                       (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
                                       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                       (relu): ReLU(inplace=True)
                                       (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
                                       (layer1): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer2): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer3): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer4): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
                                       (fc): Linear(in_features=512, out_features=10, bias=True)
                                     )
DEBUG - 01/13/26 20:16:54 - 0:00:00 - STREAM b'IHDR' 16 13
DEBUG - 01/13/26 20:16:54 - 0:00:00 - STREAM b'IDAT' 41 2006
DEBUG - 01/13/26 20:16:54 - 0:00:00 - STREAM b'IHDR' 16 13
DEBUG - 01/13/26 20:16:54 - 0:00:00 - STREAM b'IDAT' 41 2124
INFO - 01/13/26 20:16:54 - 0:00:00 - Schedule of sgd,lr=1.0: None
INFO - 01/13/26 20:16:54 - 0:00:01 - __log__:{"keyword": "iteration", "loss": 0.24717602133750916, "loss_ft": -0.04776358604431152, "loss_norm": 0.0, "loss_ft_l2": 0.2949396073818207}
INFO - 01/13/26 20:16:54 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.2291537523269653, "loss_ft": -1.5254440307617188, "loss_norm": 0.007739580236375332, "loss_ft_l2": 0.2885507047176361}
INFO - 01/13/26 20:16:54 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.45081275701522827, "loss_ft": -0.8160620927810669, "loss_norm": 0.015396907925605774, "loss_ft_l2": 0.34985244274139404}
INFO - 01/13/26 20:16:54 - 0:00:01 - __log__:{"keyword": "iteration", "loss": 0.32682913541793823, "loss_ft": -0.07288765907287598, "loss_norm": 0.018215980380773544, "loss_ft_l2": 0.38150081038475037}
INFO - 01/13/26 20:16:54 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.109145164489746, "loss_ft": -2.3861806392669678, "loss_norm": 0.020171167328953743, "loss_ft_l2": 0.2568642497062683}
INFO - 01/13/26 20:16:54 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.503399133682251, "loss_ft": -1.9002374410629272, "loss_norm": 0.025313185527920723, "loss_ft_l2": 0.37152519822120667}
INFO - 01/13/26 20:16:54 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.709032654762268, "loss_ft": -2.078711748123169, "loss_norm": 0.027005452662706375, "loss_ft_l2": 0.3426736891269684}
INFO - 01/13/26 20:16:54 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.5621498227119446, "loss_ft": -0.9591453671455383, "loss_norm": 0.028147563338279724, "loss_ft_l2": 0.36884796619415283}
INFO - 01/13/26 20:16:54 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.1661081314086914, "loss_ft": -2.521603584289551, "loss_norm": 0.029251249507069588, "loss_ft_l2": 0.3262442350387573}
INFO - 01/13/26 20:16:54 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.7893881797790527, "loss_ft": -4.154092788696289, "loss_norm": 0.031011130660772324, "loss_ft_l2": 0.33369338512420654}
INFO - 01/13/26 20:16:54 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.9470274448394775, "loss_ft": -2.3264334201812744, "loss_norm": 0.03274810314178467, "loss_ft_l2": 0.34665805101394653}
INFO - 01/13/26 20:16:54 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.8835957646369934, "loss_ft": -1.317732334136963, "loss_norm": 0.032853834331035614, "loss_ft_l2": 0.40128272771835327}
INFO - 01/13/26 20:16:54 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.2480082511901855, "loss_ft": -2.6404261589050293, "loss_norm": 0.03311515599489212, "loss_ft_l2": 0.35930266976356506}
INFO - 01/13/26 20:16:54 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.7082388401031494, "loss_ft": -1.1160016059875488, "loss_norm": 0.03280705586075783, "loss_ft_l2": 0.3749556541442871}
INFO - 01/13/26 20:16:54 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.546231746673584, "loss_ft": -1.8744927644729614, "loss_norm": 0.03324098140001297, "loss_ft_l2": 0.2950199842453003}
INFO - 01/13/26 20:16:54 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.724950909614563, "loss_ft": -2.145813226699829, "loss_norm": 0.034249819815158844, "loss_ft_l2": 0.38661253452301025}
INFO - 01/13/26 20:16:54 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.29396915435791, "loss_ft": -3.66580867767334, "loss_norm": 0.0344868004322052, "loss_ft_l2": 0.3373526632785797}
INFO - 01/13/26 20:16:54 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.308930397033691, "loss_ft": -4.665196418762207, "loss_norm": 0.035235416144132614, "loss_ft_l2": 0.3210306167602539}
INFO - 01/13/26 20:16:54 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.065036773681641, "loss_ft": -4.428188323974609, "loss_norm": 0.03579822927713394, "loss_ft_l2": 0.3273533582687378}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.2717952728271484, "loss_ft": -3.6002869606018066, "loss_norm": 0.03570542484521866, "loss_ft_l2": 0.29278630018234253}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.35291779041290283, "loss_ft": -0.7955026626586914, "loss_norm": 0.03624259680509567, "loss_ft_l2": 0.4063422679901123}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.078038215637207, "loss_ft": -4.48163366317749, "loss_norm": 0.036446426063776016, "loss_ft_l2": 0.36714884638786316}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.948549747467041, "loss_ft": -3.353254556655884, "loss_norm": 0.03765002638101578, "loss_ft_l2": 0.36705467104911804}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.150696277618408, "loss_ft": -3.5601906776428223, "loss_norm": 0.03801083564758301, "loss_ft_l2": 0.37148359417915344}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.7540206909179688, "loss_ft": -3.1193156242370605, "loss_norm": 0.038777586072683334, "loss_ft_l2": 0.3265172243118286}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -5.494658470153809, "loss_ft": -5.8563737869262695, "loss_norm": 0.03807090222835541, "loss_ft_l2": 0.3236445486545563}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -6.877360820770264, "loss_ft": -7.252053260803223, "loss_norm": 0.039508432149887085, "loss_ft_l2": 0.33518415689468384}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.291689872741699, "loss_ft": -4.722379684448242, "loss_norm": 0.03960498794913292, "loss_ft_l2": 0.3910844326019287}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": 0.1526719331741333, "loss_ft": -0.3046344518661499, "loss_norm": 0.041219837963581085, "loss_ft_l2": 0.4160865545272827}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.5895276069641113, "loss_ft": -1.9374301433563232, "loss_norm": 0.04084568843245506, "loss_ft_l2": 0.3070569634437561}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.168076992034912, "loss_ft": -4.565574645996094, "loss_norm": 0.04256993532180786, "loss_ft_l2": 0.354927659034729}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.3235156536102295, "loss_ft": -2.698483467102051, "loss_norm": 0.04155908152461052, "loss_ft_l2": 0.3334088921546936}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.3102387487888336, "loss_ft": -0.7755182981491089, "loss_norm": 0.04216674715280533, "loss_ft_l2": 0.42311277985572815}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -5.473898887634277, "loss_ft": -5.828734874725342, "loss_norm": 0.041659802198410034, "loss_ft_l2": 0.31317609548568726}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.6134475469589233, "loss_ft": -2.064943552017212, "loss_norm": 0.04135986045002937, "loss_ft_l2": 0.4101361036300659}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.43572258949279785, "loss_ft": -0.8750053644180298, "loss_norm": 0.04183993116021156, "loss_ft_l2": 0.3974428176879883}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.6523334980010986, "loss_ft": -4.0067243576049805, "loss_norm": 0.04172086715698242, "loss_ft_l2": 0.31266993284225464}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.3293914794921875, "loss_ft": -3.713763952255249, "loss_norm": 0.04212227091193199, "loss_ft_l2": 0.34225013852119446}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.9460124969482422, "loss_ft": -1.324453592300415, "loss_norm": 0.04174652323126793, "loss_ft_l2": 0.336694598197937}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.536271572113037, "loss_ft": -3.9042534828186035, "loss_norm": 0.04162641614675522, "loss_ft_l2": 0.32635554671287537}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.0660293102264404, "loss_ft": -3.4687981605529785, "loss_norm": 0.04118094593286514, "loss_ft_l2": 0.36158791184425354}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.7593913078308105, "loss_ft": -4.1088151931762695, "loss_norm": 0.04176878556609154, "loss_ft_l2": 0.307655394077301}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.7304778099060059, "loss_ft": -2.1628577709198, "loss_norm": 0.04273238778114319, "loss_ft_l2": 0.3896474838256836}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.2726142406463623, "loss_ft": -1.7268736362457275, "loss_norm": 0.04248693957924843, "loss_ft_l2": 0.4117725193500519}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.4783103466033936, "loss_ft": -2.8886237144470215, "loss_norm": 0.0420449823141098, "loss_ft_l2": 0.3682684898376465}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.20443210005760193, "loss_ft": -0.6545434594154358, "loss_norm": 0.04339347034692764, "loss_ft_l2": 0.40671786665916443}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.884936571121216, "loss_ft": -3.3017594814300537, "loss_norm": 0.04338497668504715, "loss_ft_l2": 0.37343794107437134}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.524600028991699, "loss_ft": -2.947690963745117, "loss_norm": 0.04303331673145294, "loss_ft_l2": 0.3800576627254486}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.837846755981445, "loss_ft": -5.195144176483154, "loss_norm": 0.04351343959569931, "loss_ft_l2": 0.31378403306007385}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.2993732690811157, "loss_ft": -0.753262996673584, "loss_norm": 0.0434429794549942, "loss_ft_l2": 0.41044676303863525}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.6902239322662354, "loss_ft": -4.112442493438721, "loss_norm": 0.04371242970228195, "loss_ft_l2": 0.3785058856010437}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -5.133187294006348, "loss_ft": -5.524641990661621, "loss_norm": 0.04357704520225525, "loss_ft_l2": 0.347877562046051}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.348668575286865, "loss_ft": -4.7555108070373535, "loss_norm": 0.04325966164469719, "loss_ft_l2": 0.3635825216770172}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.032791614532471, "loss_ft": -4.4413604736328125, "loss_norm": 0.042791131883859634, "loss_ft_l2": 0.36577749252319336}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.822535276412964, "loss_ft": -4.2092976570129395, "loss_norm": 0.04333644360303879, "loss_ft_l2": 0.34342607855796814}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.751161813735962, "loss_ft": -3.1710290908813477, "loss_norm": 0.04310633987188339, "loss_ft_l2": 0.37676092982292175}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": 0.2895199656486511, "loss_ft": -0.193711519241333, "loss_norm": 0.0431305393576622, "loss_ft_l2": 0.44010093808174133}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.273918628692627, "loss_ft": -3.6432666778564453, "loss_norm": 0.04319608211517334, "loss_ft_l2": 0.32615184783935547}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.8197977542877197, "loss_ft": -4.152472972869873, "loss_norm": 0.043006349354982376, "loss_ft_l2": 0.2896687686443329}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.472925901412964, "loss_ft": -2.873856782913208, "loss_norm": 0.04374317452311516, "loss_ft_l2": 0.35718780755996704}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.8005852699279785, "loss_ft": -4.171260356903076, "loss_norm": 0.043949104845523834, "loss_ft_l2": 0.32672595977783203}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.9520204067230225, "loss_ft": -2.313499927520752, "loss_norm": 0.04234527796506882, "loss_ft_l2": 0.3191342353820801}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.2915434837341309, "loss_ft": -1.7224524021148682, "loss_norm": 0.04378678277134895, "loss_ft_l2": 0.38712215423583984}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -5.286470890045166, "loss_ft": -5.632439613342285, "loss_norm": 0.04306533560156822, "loss_ft_l2": 0.30290308594703674}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.248757839202881, "loss_ft": -2.6472249031066895, "loss_norm": 0.04414016008377075, "loss_ft_l2": 0.35432693362236023}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.555683135986328, "loss_ft": -4.934533596038818, "loss_norm": 0.04458696395158768, "loss_ft_l2": 0.3342633843421936}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.1276931762695312, "loss_ft": -3.5676934719085693, "loss_norm": 0.04503992944955826, "loss_ft_l2": 0.3949604034423828}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.0546441078186035, "loss_ft": -4.453904151916504, "loss_norm": 0.044378604739904404, "loss_ft_l2": 0.35488107800483704}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.784517765045166, "loss_ft": -3.1943798065185547, "loss_norm": 0.04465807229280472, "loss_ft_l2": 0.36520376801490784}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.386195570230484, "loss_ft": -0.8093950748443604, "loss_norm": 0.04496396332979202, "loss_ft_l2": 0.3782355487346649}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.110055923461914, "loss_ft": -2.443033456802368, "loss_norm": 0.04504610598087311, "loss_ft_l2": 0.28793150186538696}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.7536580562591553, "loss_ft": -3.169694185256958, "loss_norm": 0.04368016868829727, "loss_ft_l2": 0.37235593795776367}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.797347903251648, "loss_ft": -2.2150423526763916, "loss_norm": 0.043360523879528046, "loss_ft_l2": 0.3743339478969574}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.909897327423096, "loss_ft": -5.293002128601074, "loss_norm": 0.04436205327510834, "loss_ft_l2": 0.33874285221099854}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.7330434322357178, "loss_ft": -2.1382369995117188, "loss_norm": 0.04466835409402847, "loss_ft_l2": 0.36052507162094116}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.0716552734375, "loss_ft": -2.4736621379852295, "loss_norm": 0.044177405536174774, "loss_ft_l2": 0.35782963037490845}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.6654999256134033, "loss_ft": -3.0212459564208984, "loss_norm": 0.044814806431531906, "loss_ft_l2": 0.31093114614486694}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.120148181915283, "loss_ft": -4.472063064575195, "loss_norm": 0.045111194252967834, "loss_ft_l2": 0.3068036139011383}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -6.032896995544434, "loss_ft": -6.429152965545654, "loss_norm": 0.04587709903717041, "loss_ft_l2": 0.3503789007663727}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -6.799106121063232, "loss_ft": -7.2084245681762695, "loss_norm": 0.04590936750173569, "loss_ft_l2": 0.3634088933467865}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.211349010467529, "loss_ft": -4.59681510925293, "loss_norm": 0.0444379523396492, "loss_ft_l2": 0.3410281538963318}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.317596435546875, "loss_ft": -3.7221131324768066, "loss_norm": 0.04386548697948456, "loss_ft_l2": 0.3606513440608978}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.9853274822235107, "loss_ft": -2.398512125015259, "loss_norm": 0.044556908309459686, "loss_ft_l2": 0.36862775683403015}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.7658933401107788, "loss_ft": -2.1514594554901123, "loss_norm": 0.045039303600788116, "loss_ft_l2": 0.3405267298221588}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -6.059851169586182, "loss_ft": -6.474916458129883, "loss_norm": 0.04510143771767616, "loss_ft_l2": 0.3699638247489929}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.270183801651001, "loss_ft": -2.677232265472412, "loss_norm": 0.044968463480472565, "loss_ft_l2": 0.36208006739616394}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.269834041595459, "loss_ft": -4.693802833557129, "loss_norm": 0.04556192457675934, "loss_ft_l2": 0.37840715050697327}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.1593406200408936, "loss_ft": -3.5802865028381348, "loss_norm": 0.04592060297727585, "loss_ft_l2": 0.37502533197402954}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.5547404289245605, "loss_ft": -1.9942599534988403, "loss_norm": 0.046033598482608795, "loss_ft_l2": 0.3934858739376068}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.4113389253616333, "loss_ft": -1.7941272258758545, "loss_norm": 0.045345187187194824, "loss_ft_l2": 0.33744311332702637}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.289523124694824, "loss_ft": -4.683603286743164, "loss_norm": 0.04530257359147072, "loss_ft_l2": 0.3487776219844818}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.427865982055664, "loss_ft": -3.784987449645996, "loss_norm": 0.04478525370359421, "loss_ft_l2": 0.3123360872268677}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.106740474700928, "loss_ft": -4.4693169593811035, "loss_norm": 0.045583829283714294, "loss_ft_l2": 0.31699270009994507}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.338229775428772, "loss_ft": -1.708052158355713, "loss_norm": 0.045142143964767456, "loss_ft_l2": 0.3246801793575287}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.955743670463562, "loss_ft": -2.415214776992798, "loss_norm": 0.04502587020397186, "loss_ft_l2": 0.41444525122642517}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.2438926696777344, "loss_ft": -2.6558830738067627, "loss_norm": 0.04483428969979286, "loss_ft_l2": 0.367156058549881}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.7713443040847778, "loss_ft": -2.206491708755493, "loss_norm": 0.04459237679839134, "loss_ft_l2": 0.3905549943447113}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.1163487434387207, "loss_ft": -3.483963966369629, "loss_norm": 0.04459085315465927, "loss_ft_l2": 0.32302436232566833}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -5.7036542892456055, "loss_ft": -6.095281600952148, "loss_norm": 0.04445205628871918, "loss_ft_l2": 0.3471750319004059}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.697935104370117, "loss_ft": -5.068181037902832, "loss_norm": 0.04491734504699707, "loss_ft_l2": 0.3253288269042969}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -6.367883682250977, "loss_ft": -6.764739036560059, "loss_norm": 0.045132096856832504, "loss_ft_l2": 0.35172343254089355}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.871443748474121, "loss_ft": -3.2661736011505127, "loss_norm": 0.04459565877914429, "loss_ft_l2": 0.35013410449028015}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.653731346130371, "loss_ft": -4.086421012878418, "loss_norm": 0.04519716650247574, "loss_ft_l2": 0.38749274611473083}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.3474738597869873, "loss_ft": -2.773287773132324, "loss_norm": 0.04558435082435608, "loss_ft_l2": 0.3802294135093689}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.5255500078201294, "loss_ft": -0.9497870802879333, "loss_norm": 0.046012185513973236, "loss_ft_l2": 0.3782249391078949}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.7481679916381836, "loss_ft": -3.163423538208008, "loss_norm": 0.04626636207103729, "loss_ft_l2": 0.36898931860923767}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -5.403329372406006, "loss_ft": -5.809696197509766, "loss_norm": 0.04636581987142563, "loss_ft_l2": 0.36000099778175354}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.627106666564941, "loss_ft": -5.052535057067871, "loss_norm": 0.04558023810386658, "loss_ft_l2": 0.3798482120037079}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.449980229139328, "loss_ft": -0.893451988697052, "loss_norm": 0.044864680618047714, "loss_ft_l2": 0.3986071050167084}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.573446750640869, "loss_ft": -4.960572719573975, "loss_norm": 0.04497089982032776, "loss_ft_l2": 0.34215492010116577}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.136146068572998, "loss_ft": -4.498544216156006, "loss_norm": 0.04553646221756935, "loss_ft_l2": 0.3168615698814392}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.5733453035354614, "loss_ft": -1.0294429063796997, "loss_norm": 0.044261831790208817, "loss_ft_l2": 0.41183578968048096}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -5.242026329040527, "loss_ft": -5.635540962219238, "loss_norm": 0.04450047016143799, "loss_ft_l2": 0.3490140438079834}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.9265761375427246, "loss_ft": -4.316690921783447, "loss_norm": 0.04552599787712097, "loss_ft_l2": 0.3445886969566345}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.6140716075897217, "loss_ft": -1.0799204111099243, "loss_norm": 0.04597877338528633, "loss_ft_l2": 0.419869989156723}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.5513522624969482, "loss_ft": -3.927730083465576, "loss_norm": 0.045847415924072266, "loss_ft_l2": 0.3305303156375885}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.439784526824951, "loss_ft": -4.818480491638184, "loss_norm": 0.046851254999637604, "loss_ft_l2": 0.33184492588043213}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.2080060243606567, "loss_ft": -1.6556501388549805, "loss_norm": 0.0461256243288517, "loss_ft_l2": 0.40151846408843994}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -6.475928783416748, "loss_ft": -6.8712310791015625, "loss_norm": 0.04607274383306503, "loss_ft_l2": 0.3492291271686554}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.522794246673584, "loss_ft": -2.920733690261841, "loss_norm": 0.04693325608968735, "loss_ft_l2": 0.35100623965263367}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.2178878784179688, "loss_ft": -1.6597168445587158, "loss_norm": 0.04658187925815582, "loss_ft_l2": 0.39524704217910767}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.36952078342437744, "loss_ft": -0.8262547254562378, "loss_norm": 0.046086642891168594, "loss_ft_l2": 0.41064727306365967}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.136105537414551, "loss_ft": -4.518861293792725, "loss_norm": 0.04603266716003418, "loss_ft_l2": 0.33672332763671875}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -6.383697509765625, "loss_ft": -6.803858280181885, "loss_norm": 0.046313513070344925, "loss_ft_l2": 0.3738475739955902}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.3893909454345703, "loss_ft": -2.7964749336242676, "loss_norm": 0.045580312609672546, "loss_ft_l2": 0.3615037202835083}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.322373390197754, "loss_ft": -2.7129788398742676, "loss_norm": 0.04654931277036667, "loss_ft_l2": 0.3440561592578888}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.9442129135131836, "loss_ft": -4.3312811851501465, "loss_norm": 0.046328336000442505, "loss_ft_l2": 0.34073972702026367}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.04219740629196167, "loss_ft": -0.5060640573501587, "loss_norm": 0.045842964202165604, "loss_ft_l2": 0.4180236756801605}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.8355013132095337, "loss_ft": -2.2748231887817383, "loss_norm": 0.04584541916847229, "loss_ft_l2": 0.39347633719444275}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.900646686553955, "loss_ft": -2.3033394813537598, "loss_norm": 0.045536816120147705, "loss_ft_l2": 0.35715606808662415}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": 0.6773582696914673, "loss_ft": 0.21294105052947998, "loss_norm": 0.045574650168418884, "loss_ft_l2": 0.41884252429008484}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.19658088684082, "loss_ft": -4.569720268249512, "loss_norm": 0.04473315179347992, "loss_ft_l2": 0.32840633392333984}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.240024089813232, "loss_ft": -4.6595306396484375, "loss_norm": 0.044875599443912506, "loss_ft_l2": 0.37463077902793884}
INFO - 01/13/26 20:16:55 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.2420523166656494, "loss_ft": -3.6727209091186523, "loss_norm": 0.04466117173433304, "loss_ft_l2": 0.38600724935531616}
INFO - 01/13/26 20:16:55 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -6.2260870933532715, "loss_ft": -6.627994537353516, "loss_norm": 0.04519219696521759, "loss_ft_l2": 0.3567153811454773}
INFO - 01/13/26 20:16:55 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.152926445007324, "loss_ft": -2.583789825439453, "loss_norm": 0.04586189240217209, "loss_ft_l2": 0.3850013017654419}
INFO - 01/13/26 20:16:55 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -1.857175350189209, "loss_ft": -2.2736692428588867, "loss_norm": 0.0462968572974205, "loss_ft_l2": 0.37019702792167664}
INFO - 01/13/26 20:16:55 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.398130416870117, "loss_ft": -2.8127572536468506, "loss_norm": 0.04554319381713867, "loss_ft_l2": 0.36908358335494995}
INFO - 01/13/26 20:16:55 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.534377574920654, "loss_ft": -4.889590263366699, "loss_norm": 0.045668721199035645, "loss_ft_l2": 0.3095438778400421}
INFO - 01/13/26 20:16:55 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.448105812072754, "loss_ft": -4.833827018737793, "loss_norm": 0.046374641358852386, "loss_ft_l2": 0.33934637904167175}
INFO - 01/13/26 20:16:55 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.505992889404297, "loss_ft": -4.8694376945495605, "loss_norm": 0.04666683077812195, "loss_ft_l2": 0.31677842140197754}
INFO - 01/13/26 20:16:55 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -0.9529956579208374, "loss_ft": -1.3995311260223389, "loss_norm": 0.04579216241836548, "loss_ft_l2": 0.4007433354854584}
INFO - 01/13/26 20:16:55 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -1.9612797498703003, "loss_ft": -2.376222848892212, "loss_norm": 0.04546164721250534, "loss_ft_l2": 0.3694814145565033}
INFO - 01/13/26 20:16:55 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.697908401489258, "loss_ft": -3.1079111099243164, "loss_norm": 0.04479534551501274, "loss_ft_l2": 0.36520734429359436}
INFO - 01/13/26 20:16:55 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.4943037033081055, "loss_ft": -4.8589324951171875, "loss_norm": 0.045004211366176605, "loss_ft_l2": 0.31962448358535767}
INFO - 01/13/26 20:16:55 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -3.469632387161255, "loss_ft": -3.850627899169922, "loss_norm": 0.04555431008338928, "loss_ft_l2": 0.33544111251831055}
INFO - 01/13/26 20:16:55 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.694148540496826, "loss_ft": -3.1116199493408203, "loss_norm": 0.045539066195487976, "loss_ft_l2": 0.3719322085380554}
INFO - 01/13/26 20:16:55 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.152146816253662, "loss_ft": -2.560973644256592, "loss_norm": 0.04529953747987747, "loss_ft_l2": 0.36352741718292236}
INFO - 01/13/26 20:16:55 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.589515209197998, "loss_ft": -4.955101013183594, "loss_norm": 0.04492155462503433, "loss_ft_l2": 0.3206641972064972}
INFO - 01/13/26 20:16:55 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -1.6895039081573486, "loss_ft": -2.1276473999023438, "loss_norm": 0.045569125562906265, "loss_ft_l2": 0.39257436990737915}
INFO - 01/13/26 20:16:55 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.7688708305358887, "loss_ft": -3.1774654388427734, "loss_norm": 0.045238692313432693, "loss_ft_l2": 0.36335593461990356}
INFO - 01/13/26 20:16:55 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.5785412788391113, "loss_ft": -3.0306296348571777, "loss_norm": 0.04501122981309891, "loss_ft_l2": 0.4070771038532257}
INFO - 01/13/26 20:16:55 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.0233445167541504, "loss_ft": -2.4575281143188477, "loss_norm": 0.04474695026874542, "loss_ft_l2": 0.38943663239479065}
INFO - 01/13/26 20:16:55 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -3.024369716644287, "loss_ft": -3.455496311187744, "loss_norm": 0.04476650804281235, "loss_ft_l2": 0.386360228061676}
INFO - 01/13/26 20:16:55 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.571216583251953, "loss_ft": -2.992711067199707, "loss_norm": 0.0452524870634079, "loss_ft_l2": 0.3762418031692505}
INFO - 01/13/26 20:16:55 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.028818607330322, "loss_ft": -4.414957046508789, "loss_norm": 0.044645972549915314, "loss_ft_l2": 0.34149250388145447}
INFO - 01/13/26 20:16:55 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.82537317276001, "loss_ft": -5.1636552810668945, "loss_norm": 0.045160725712776184, "loss_ft_l2": 0.2931213974952698}
INFO - 01/13/26 20:16:55 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.992645263671875, "loss_ft": -5.413726806640625, "loss_norm": 0.04585590586066246, "loss_ft_l2": 0.3752255141735077}
INFO - 01/13/26 20:16:55 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -6.1869120597839355, "loss_ft": -6.590657711029053, "loss_norm": 0.04557882249355316, "loss_ft_l2": 0.35816648602485657}
INFO - 01/13/26 20:16:55 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.1408214569091797, "loss_ft": -2.5160250663757324, "loss_norm": 0.0453447625041008, "loss_ft_l2": 0.32985877990722656}
INFO - 01/13/26 20:16:55 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -5.44215202331543, "loss_ft": -5.85042667388916, "loss_norm": 0.04507710039615631, "loss_ft_l2": 0.36319735646247864}
INFO - 01/13/26 20:16:55 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.579312801361084, "loss_ft": -2.959322690963745, "loss_norm": 0.04493730887770653, "loss_ft_l2": 0.33507242798805237}
INFO - 01/13/26 20:16:55 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -1.4864325523376465, "loss_ft": -1.8678486347198486, "loss_norm": 0.04551031440496445, "loss_ft_l2": 0.3359057605266571}
INFO - 01/13/26 20:16:55 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -3.8295321464538574, "loss_ft": -4.237300872802734, "loss_norm": 0.04654975235462189, "loss_ft_l2": 0.3612189292907715}
INFO - 01/13/26 20:16:55 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.753749370574951, "loss_ft": -3.1786603927612305, "loss_norm": 0.046173229813575745, "loss_ft_l2": 0.3787376284599304}
INFO - 01/13/26 20:16:55 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -1.9109843969345093, "loss_ft": -2.3201866149902344, "loss_norm": 0.04638439044356346, "loss_ft_l2": 0.3628179132938385}
INFO - 01/13/26 20:16:55 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.428654193878174, "loss_ft": -4.864217758178711, "loss_norm": 0.04614038020372391, "loss_ft_l2": 0.38942351937294006}
INFO - 01/13/26 20:16:55 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -1.917069435119629, "loss_ft": -2.35830020904541, "loss_norm": 0.0462510772049427, "loss_ft_l2": 0.3949797749519348}
INFO - 01/13/26 20:16:55 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.162706136703491, "loss_ft": -2.561527729034424, "loss_norm": 0.04579570144414902, "loss_ft_l2": 0.35302597284317017}
INFO - 01/13/26 20:16:55 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.561699390411377, "loss_ft": -4.949850559234619, "loss_norm": 0.04693441465497017, "loss_ft_l2": 0.3412167429924011}
INFO - 01/13/26 20:16:56 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -1.4160411357879639, "loss_ft": -1.8641002178192139, "loss_norm": 0.04633012041449547, "loss_ft_l2": 0.40172895789146423}
INFO - 01/13/26 20:16:56 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -6.057423114776611, "loss_ft": -6.420352935791016, "loss_norm": 0.045814067125320435, "loss_ft_l2": 0.317115843296051}
INFO - 01/13/26 20:16:56 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -1.5680758953094482, "loss_ft": -2.00040602684021, "loss_norm": 0.04671397805213928, "loss_ft_l2": 0.38561615347862244}
INFO - 01/13/26 20:16:56 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.1838998794555664, "loss_ft": -2.605257749557495, "loss_norm": 0.046593353152275085, "loss_ft_l2": 0.37476444244384766}
INFO - 01/13/26 20:16:56 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -5.241552829742432, "loss_ft": -5.6310200691223145, "loss_norm": 0.0461508184671402, "loss_ft_l2": 0.3433166444301605}
INFO - 01/13/26 20:16:56 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -5.760692119598389, "loss_ft": -6.168461799621582, "loss_norm": 0.046227823942899704, "loss_ft_l2": 0.3615418076515198}
INFO - 01/13/26 20:16:56 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.8374531269073486, "loss_ft": -3.2921371459960938, "loss_norm": 0.046721894294023514, "loss_ft_l2": 0.4079621434211731}
INFO - 01/13/26 20:16:56 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.920479774475098, "loss_ft": -5.274731636047363, "loss_norm": 0.046445950865745544, "loss_ft_l2": 0.3078058063983917}
INFO - 01/13/26 20:16:56 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.035840034484863, "loss_ft": -4.42864990234375, "loss_norm": 0.046709395945072174, "loss_ft_l2": 0.34610044956207275}
INFO - 01/13/26 20:16:56 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.443886756896973, "loss_ft": -4.8592329025268555, "loss_norm": 0.04559486731886864, "loss_ft_l2": 0.3697512745857239}
INFO - 01/13/26 20:16:56 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -6.600437164306641, "loss_ft": -6.9705810546875, "loss_norm": 0.04542236030101776, "loss_ft_l2": 0.32472121715545654}
INFO - 01/13/26 20:16:56 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -5.085190773010254, "loss_ft": -5.444857120513916, "loss_norm": 0.045369379222393036, "loss_ft_l2": 0.3142973482608795}
INFO - 01/13/26 20:16:56 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -3.81630802154541, "loss_ft": -4.23018217086792, "loss_norm": 0.04535207152366638, "loss_ft_l2": 0.3685220777988434}
INFO - 01/13/26 20:16:56 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.212839126586914, "loss_ft": -4.600542068481445, "loss_norm": 0.04525439068675041, "loss_ft_l2": 0.34244853258132935}
INFO - 01/13/26 20:16:56 - 0:00:02 - __log__:{"keyword": "iteration", "loss": 0.1789611428976059, "loss_ft": -0.26632052659988403, "loss_norm": 0.045771852135658264, "loss_ft_l2": 0.39950981736183167}
INFO - 01/13/26 20:16:56 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.658277988433838, "loss_ft": -3.0569283962249756, "loss_norm": 0.046446070075035095, "loss_ft_l2": 0.3522043526172638}
INFO - 01/13/26 20:16:56 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -3.642902374267578, "loss_ft": -4.035738945007324, "loss_norm": 0.04663638770580292, "loss_ft_l2": 0.34620019793510437}
INFO - 01/13/26 20:16:56 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -0.10343295335769653, "loss_ft": -0.5694617033004761, "loss_norm": 0.04608858749270439, "loss_ft_l2": 0.41994017362594604}
INFO - 01/13/26 20:16:56 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -6.601694107055664, "loss_ft": -6.9985198974609375, "loss_norm": 0.04577285051345825, "loss_ft_l2": 0.35105299949645996}
INFO - 01/13/26 20:16:56 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -7.121220588684082, "loss_ft": -7.525733947753906, "loss_norm": 0.045973919332027435, "loss_ft_l2": 0.3585394620895386}
INFO - 01/13/26 20:16:56 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -1.3507320880889893, "loss_ft": -1.778158187866211, "loss_norm": 0.047494180500507355, "loss_ft_l2": 0.37993186712265015}
INFO - 01/13/26 20:16:56 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -3.09216570854187, "loss_ft": -3.5330936908721924, "loss_norm": 0.045965418219566345, "loss_ft_l2": 0.3949626386165619}
INFO - 01/13/26 20:16:56 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -3.9962105751037598, "loss_ft": -4.3708882331848145, "loss_norm": 0.04716440290212631, "loss_ft_l2": 0.327513188123703}
INFO - 01/13/26 20:16:56 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -1.732632040977478, "loss_ft": -2.178948402404785, "loss_norm": 0.047679055482149124, "loss_ft_l2": 0.3986373841762543}
INFO - 01/13/26 20:16:56 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -1.5152027606964111, "loss_ft": -1.9657660722732544, "loss_norm": 0.04757096990942955, "loss_ft_l2": 0.4029923975467682}
INFO - 01/13/26 20:16:56 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -3.6212613582611084, "loss_ft": -4.009915351867676, "loss_norm": 0.047509901225566864, "loss_ft_l2": 0.3411441445350647}
INFO - 01/13/26 20:16:56 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -1.4428809881210327, "loss_ft": -1.8937225341796875, "loss_norm": 0.04707672446966171, "loss_ft_l2": 0.40376487374305725}
INFO - 01/13/26 20:16:56 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -1.583902359008789, "loss_ft": -1.9970166683197021, "loss_norm": 0.04688332974910736, "loss_ft_l2": 0.36623090505599976}
INFO - 01/13/26 20:16:56 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -3.979158878326416, "loss_ft": -4.33714485168457, "loss_norm": 0.046609606593847275, "loss_ft_l2": 0.3113766312599182}
INFO - 01/13/26 20:16:56 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.4471497535705566, "loss_ft": -2.862698554992676, "loss_norm": 0.04673618823289871, "loss_ft_l2": 0.36881256103515625}
INFO - 01/13/26 20:16:56 - 0:00:02 - __log__:{"keyword": "final", "psnr": 31.338248753332422, "ft_direction": 2.2916502952575684, "ft_norm": 14.648427963256836, "cosine_mean": 0.16012035310268402, "rho": -1, "R": -440.55206298828125}
INFO - 01/13/26 20:17:19 - 0:00:00 - ============ Initialized logger ============
INFO - 01/13/26 20:17:19 - 0:00:00 - angle: None
                                     carrier_id: 0
                                     carrier_path: carriers.pth
                                     command: python make_data_radioactive.py --carrier_id 0 --carrier_path 'carriers.pth' --data_augmentation random --epochs 200 --img_paths 'cifar10_images/0/29.png,cifar10_images/0/77.png' --lambda_ft_l2 '0.01' --lambda_l2_img '0.0005' --marking_network 'pretrained_resnet18.pth' --dump_path './cifar10_marked' --optimizer 'sgd,lr=1.0' --exp_id "cifar10_marked"
                                     crop_size: 224
                                     data_augmentation: random
                                     debug: False
                                     debug_slurm: False
                                     debug_train: False
                                     dump_path: ./cifar10_marked
                                     epochs: 200
                                     exp_id: cifar10_marked
                                     exp_name: bypass
                                     half_cone: True
                                     img_list: None
                                     img_paths: cifar10_images/0/29.png,cifar10_images/0/77.png
                                     img_size: 256
                                     lambda_ft_l2: 0.01
                                     lambda_l2_img: 0.0005
                                     marking_network: pretrained_resnet18.pth
                                     optimizer: sgd,lr=1.0
                                     radius: 10
INFO - 01/13/26 20:17:19 - 0:00:00 - The experiment will be stored in ./cifar10_marked
                                     
INFO - 01/13/26 20:17:19 - 0:00:00 - Running command: python make_data_radioactive.py --carrier_id 0 --carrier_path 'carriers.pth' --data_augmentation random --epochs 200 --img_paths 'cifar10_images/0/29.png,cifar10_images/0/77.png' --lambda_ft_l2 '0.01' --lambda_l2_img '0.0005' --marking_network 'pretrained_resnet18.pth' --dump_path './cifar10_marked' --optimizer 'sgd,lr=1.0'

INFO - 01/13/26 20:17:19 - 0:00:00 - Model: ResNet(
                                       (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
                                       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                       (relu): ReLU(inplace=True)
                                       (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
                                       (layer1): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer2): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer3): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer4): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
                                       (fc): Linear(in_features=512, out_features=10, bias=True)
                                     )
DEBUG - 01/13/26 20:17:19 - 0:00:00 - STREAM b'IHDR' 16 13
DEBUG - 01/13/26 20:17:19 - 0:00:00 - STREAM b'IDAT' 41 2006
DEBUG - 01/13/26 20:17:19 - 0:00:00 - STREAM b'IHDR' 16 13
DEBUG - 01/13/26 20:17:19 - 0:00:00 - STREAM b'IDAT' 41 2124
INFO - 01/13/26 20:17:19 - 0:00:00 - Schedule of sgd,lr=1.0: None
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": 0.6428284049034119, "loss_ft": 0.280126690864563, "loss_norm": 0.0, "loss_ft_l2": 0.3627017140388489}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.677322268486023, "loss_ft": -0.9140122532844543, "loss_norm": 0.006876247003674507, "loss_ft_l2": 0.22981372475624084}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.503387451171875, "loss_ft": -0.7733790874481201, "loss_norm": 0.016157906502485275, "loss_ft_l2": 0.25383374094963074}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.6341451406478882, "loss_ft": -1.9656373262405396, "loss_norm": 0.020917795598506927, "loss_ft_l2": 0.3105744421482086}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.9765617847442627, "loss_ft": -2.338789463043213, "loss_norm": 0.023229219019412994, "loss_ft_l2": 0.33899858593940735}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.0148972272872925, "loss_ft": -1.4239585399627686, "loss_norm": 0.024840358644723892, "loss_ft_l2": 0.3842209577560425}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.3139917850494385, "loss_ft": -1.7096437215805054, "loss_norm": 0.026176419109106064, "loss_ft_l2": 0.36947551369667053}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.4975448846817017, "loss_ft": -1.8800618648529053, "loss_norm": 0.0277920663356781, "loss_ft_l2": 0.3547249138355255}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.356034755706787, "loss_ft": -2.71099591255188, "loss_norm": 0.028114330023527145, "loss_ft_l2": 0.3268469274044037}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.114388465881348, "loss_ft": -4.4548659324646, "loss_norm": 0.03002156689763069, "loss_ft_l2": 0.31045570969581604}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.3291898965835571, "loss_ft": -1.7116824388504028, "loss_norm": 0.03119911253452301, "loss_ft_l2": 0.3512934148311615}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.9628067016601562, "loss_ft": -4.283769607543945, "loss_norm": 0.032011084258556366, "loss_ft_l2": 0.2889517843723297}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.0732154846191406, "loss_ft": -2.4490809440612793, "loss_norm": 0.03279653191566467, "loss_ft_l2": 0.3430687189102173}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.9385251998901367, "loss_ft": -3.3362722396850586, "loss_norm": 0.034131184220314026, "loss_ft_l2": 0.36361566185951233}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.50472092628479, "loss_ft": -2.8851892948150635, "loss_norm": 0.03527995944023132, "loss_ft_l2": 0.34518834948539734}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.5926427841186523, "loss_ft": -3.9881017208099365, "loss_norm": 0.03671801835298538, "loss_ft_l2": 0.35874074697494507}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.016770362854004, "loss_ft": -3.4259986877441406, "loss_norm": 0.03715619444847107, "loss_ft_l2": 0.3720722794532776}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.091031074523926, "loss_ft": -3.4553110599517822, "loss_norm": 0.037324462085962296, "loss_ft_l2": 0.3269556760787964}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.689518451690674, "loss_ft": -3.086984634399414, "loss_norm": 0.036949947476387024, "loss_ft_l2": 0.3605162799358368}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.9553717374801636, "loss_ft": -1.3736928701400757, "loss_norm": 0.036504484713077545, "loss_ft_l2": 0.3818165957927704}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.5857105255126953, "loss_ft": -2.982551097869873, "loss_norm": 0.036347609013319016, "loss_ft_l2": 0.36049291491508484}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.467259407043457, "loss_ft": -4.88514518737793, "loss_norm": 0.03621599078178406, "loss_ft_l2": 0.381670206785202}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.3331339359283447, "loss_ft": -1.7060023546218872, "loss_norm": 0.036496274173259735, "loss_ft_l2": 0.33637216687202454}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.8207619190216064, "loss_ft": -2.210007429122925, "loss_norm": 0.03653711825609207, "loss_ft_l2": 0.3527083396911621}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.9346847534179688, "loss_ft": -3.313896656036377, "loss_norm": 0.03747375309467316, "loss_ft_l2": 0.34173816442489624}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.0467722415924072, "loss_ft": -3.426358461380005, "loss_norm": 0.038323625922203064, "loss_ft_l2": 0.34126266837120056}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -5.946369171142578, "loss_ft": -6.31220817565918, "loss_norm": 0.03884284198284149, "loss_ft_l2": 0.3269965350627899}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.8718583583831787, "loss_ft": -3.258746862411499, "loss_norm": 0.039398036897182465, "loss_ft_l2": 0.3474905788898468}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.8146591186523438, "loss_ft": -4.194983959197998, "loss_norm": 0.03962280973792076, "loss_ft_l2": 0.3407020568847656}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.901197075843811, "loss_ft": -2.3123929500579834, "loss_norm": 0.03979956731200218, "loss_ft_l2": 0.37139639258384705}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.2316112518310547, "loss_ft": -1.6482148170471191, "loss_norm": 0.03997164964675903, "loss_ft_l2": 0.3766320049762726}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.165982246398926, "loss_ft": -3.594832420349121, "loss_norm": 0.03872600197792053, "loss_ft_l2": 0.39012411236763}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": 0.23966661095619202, "loss_ft": -0.21066498756408691, "loss_norm": 0.03951529413461685, "loss_ft_l2": 0.4108163118362427}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.915128231048584, "loss_ft": -2.338894844055176, "loss_norm": 0.04010382294654846, "loss_ft_l2": 0.3836626410484314}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -5.085123538970947, "loss_ft": -5.469574928283691, "loss_norm": 0.03983794152736664, "loss_ft_l2": 0.3446137607097626}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.9081404209136963, "loss_ft": -3.292619228363037, "loss_norm": 0.040528569370508194, "loss_ft_l2": 0.34395018219947815}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.0307735204696655, "loss_ft": -1.4518933296203613, "loss_norm": 0.04106217250227928, "loss_ft_l2": 0.3800576627254486}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.1894755363464355, "loss_ft": -3.5939719676971436, "loss_norm": 0.041893430054187775, "loss_ft_l2": 0.3626028597354889}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.9731013774871826, "loss_ft": -4.370918273925781, "loss_norm": 0.04186651110649109, "loss_ft_l2": 0.35595065355300903}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.2208999395370483, "loss_ft": -1.6371018886566162, "loss_norm": 0.04073978215456009, "loss_ft_l2": 0.3754621744155884}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.1935300827026367, "loss_ft": -1.609033465385437, "loss_norm": 0.04036907106637955, "loss_ft_l2": 0.3751344084739685}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.9461183547973633, "loss_ft": -4.301513671875, "loss_norm": 0.039578065276145935, "loss_ft_l2": 0.3158174753189087}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.882105827331543, "loss_ft": -5.2216668128967285, "loss_norm": 0.04059651494026184, "loss_ft_l2": 0.298964262008667}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.1495656967163086, "loss_ft": -2.5859248638153076, "loss_norm": 0.04128342494368553, "loss_ft_l2": 0.3950759172439575}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.878162384033203, "loss_ft": -4.253086090087891, "loss_norm": 0.04059688374400139, "loss_ft_l2": 0.3343268632888794}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.3627877235412598, "loss_ft": -2.7203924655914307, "loss_norm": 0.04056869074702263, "loss_ft_l2": 0.31703615188598633}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.421086311340332, "loss_ft": -2.794342279434204, "loss_norm": 0.04093547910451889, "loss_ft_l2": 0.33232033252716064}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.290664404630661, "loss_ft": -0.7574294805526733, "loss_norm": 0.04170970991253853, "loss_ft_l2": 0.4250553548336029}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.771541118621826, "loss_ft": -5.122870445251465, "loss_norm": 0.04191567376255989, "loss_ft_l2": 0.30941322445869446}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.625227689743042, "loss_ft": -1.0578794479370117, "loss_norm": 0.041828595101833344, "loss_ft_l2": 0.3908231258392334}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.312948226928711, "loss_ft": -4.6972527503967285, "loss_norm": 0.041410088539123535, "loss_ft_l2": 0.34289470314979553}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.8228259086608887, "loss_ft": -2.263479232788086, "loss_norm": 0.04160168021917343, "loss_ft_l2": 0.3990516662597656}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.4844117760658264, "loss_ft": -0.9503651857376099, "loss_norm": 0.041418056935071945, "loss_ft_l2": 0.42453533411026}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.2248504161834717, "loss_ft": -3.6059300899505615, "loss_norm": 0.041325751692056656, "loss_ft_l2": 0.33975380659103394}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.6347832679748535, "loss_ft": -4.025388717651367, "loss_norm": 0.041582588106393814, "loss_ft_l2": 0.34902292490005493}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.4579458236694336, "loss_ft": -2.9087371826171875, "loss_norm": 0.04214668273925781, "loss_ft_l2": 0.4086446166038513}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.874131202697754, "loss_ft": -3.2971649169921875, "loss_norm": 0.04210536926984787, "loss_ft_l2": 0.3809281587600708}
INFO - 01/13/26 20:17:19 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.1240296363830566, "loss_ft": -2.532276153564453, "loss_norm": 0.042546674609184265, "loss_ft_l2": 0.365699827671051}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -6.0298333168029785, "loss_ft": -6.405138969421387, "loss_norm": 0.042054399847984314, "loss_ft_l2": 0.33325159549713135}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.1804654598236084, "loss_ft": -2.5961480140686035, "loss_norm": 0.04211486130952835, "loss_ft_l2": 0.37356749176979065}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.3912245035171509, "loss_ft": -0.8434504270553589, "loss_norm": 0.04209228605031967, "loss_ft_l2": 0.4101336598396301}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -5.387718200683594, "loss_ft": -5.78287935256958, "loss_norm": 0.04170060530304909, "loss_ft_l2": 0.35346052050590515}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.4662933349609375, "loss_ft": -1.9067668914794922, "loss_norm": 0.04228650778532028, "loss_ft_l2": 0.3981870710849762}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.4135453701019287, "loss_ft": -1.8389798402786255, "loss_norm": 0.04232996329665184, "loss_ft_l2": 0.3831046223640442}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.654414176940918, "loss_ft": -2.0685548782348633, "loss_norm": 0.042570557445287704, "loss_ft_l2": 0.3715701103210449}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -5.265684127807617, "loss_ft": -5.602785110473633, "loss_norm": 0.042015235871076584, "loss_ft_l2": 0.2950860857963562}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.4007856845855713, "loss_ft": -1.8096253871917725, "loss_norm": 0.04275260865688324, "loss_ft_l2": 0.3660871088504791}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.7146449089050293, "loss_ft": -3.108935832977295, "loss_norm": 0.04329723119735718, "loss_ft_l2": 0.35099369287490845}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -5.410090446472168, "loss_ft": -5.793020248413086, "loss_norm": 0.043444275856018066, "loss_ft_l2": 0.33948585391044617}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -6.193734169006348, "loss_ft": -6.58747673034668, "loss_norm": 0.04303274303674698, "loss_ft_l2": 0.35070982575416565}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -6.475476264953613, "loss_ft": -6.8532233238220215, "loss_norm": 0.043583694845438004, "loss_ft_l2": 0.3341631591320038}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.13364315032959, "loss_ft": -4.484388828277588, "loss_norm": 0.043054379522800446, "loss_ft_l2": 0.3076913058757782}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -5.545303821563721, "loss_ft": -5.931487083435059, "loss_norm": 0.04372226446866989, "loss_ft_l2": 0.34246131777763367}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.206716060638428, "loss_ft": -4.568238258361816, "loss_norm": 0.04369458556175232, "loss_ft_l2": 0.31782791018486023}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.8678011894226074, "loss_ft": -3.2709152698516846, "loss_norm": 0.043886762112379074, "loss_ft_l2": 0.3592275083065033}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.2248106002807617, "loss_ft": -2.6625328063964844, "loss_norm": 0.04325011372566223, "loss_ft_l2": 0.39447224140167236}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.976809501647949, "loss_ft": -5.305443286895752, "loss_norm": 0.043570078909397125, "loss_ft_l2": 0.28506386280059814}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.795224666595459, "loss_ft": -3.228067398071289, "loss_norm": 0.04455100744962692, "loss_ft_l2": 0.38829174637794495}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -5.046355247497559, "loss_ft": -5.422318458557129, "loss_norm": 0.04438306391239166, "loss_ft_l2": 0.3315802812576294}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.9424045085906982, "loss_ft": -3.376455307006836, "loss_norm": 0.04457420855760574, "loss_ft_l2": 0.3894764482975006}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.4620556831359863, "loss_ft": -2.8840479850769043, "loss_norm": 0.04395493119955063, "loss_ft_l2": 0.3780374825000763}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.4140238761901855, "loss_ft": -3.79575514793396, "loss_norm": 0.043030187487602234, "loss_ft_l2": 0.3387010991573334}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.3755695819854736, "loss_ft": -2.7952423095703125, "loss_norm": 0.04366994649171829, "loss_ft_l2": 0.37600287795066833}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -5.012701511383057, "loss_ft": -5.408965110778809, "loss_norm": 0.043262068182229996, "loss_ft_l2": 0.35300174355506897}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.7272186279296875, "loss_ft": -4.151114463806152, "loss_norm": 0.04304277151823044, "loss_ft_l2": 0.38085323572158813}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.881900310516357, "loss_ft": -5.236492156982422, "loss_norm": 0.043629541993141174, "loss_ft_l2": 0.3109620213508606}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.9286789894104004, "loss_ft": -1.3734253644943237, "loss_norm": 0.0446159802377224, "loss_ft_l2": 0.40013039112091064}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -6.543374061584473, "loss_ft": -6.929238796234131, "loss_norm": 0.04505322873592377, "loss_ft_l2": 0.34081175923347473}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.8988659381866455, "loss_ft": -2.3119266033172607, "loss_norm": 0.044726915657520294, "loss_ft_l2": 0.3683338165283203}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -5.1235175132751465, "loss_ft": -5.521925449371338, "loss_norm": 0.044124022126197815, "loss_ft_l2": 0.3542839288711548}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.2615344524383545, "loss_ft": -2.68183970451355, "loss_norm": 0.044644031673669815, "loss_ft_l2": 0.375661164522171}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.9541783332824707, "loss_ft": -3.3480210304260254, "loss_norm": 0.04383864253759384, "loss_ft_l2": 0.35000407695770264}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.880602836608887, "loss_ft": -5.288694381713867, "loss_norm": 0.04481897130608559, "loss_ft_l2": 0.36327245831489563}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.244876861572266, "loss_ft": -4.614054203033447, "loss_norm": 0.04428451135754585, "loss_ft_l2": 0.32489311695098877}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -6.31209135055542, "loss_ft": -6.704537391662598, "loss_norm": 0.04517943412065506, "loss_ft_l2": 0.3472665250301361}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.733201026916504, "loss_ft": -3.145791530609131, "loss_norm": 0.04603033512830734, "loss_ft_l2": 0.3665601909160614}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.6099520921707153, "loss_ft": -1.0424652099609375, "loss_norm": 0.04576974734663963, "loss_ft_l2": 0.3867433965206146}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.6815366744995117, "loss_ft": -4.092004776000977, "loss_norm": 0.04547952115535736, "loss_ft_l2": 0.364988774061203}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.9819968938827515, "loss_ft": -2.3826992511749268, "loss_norm": 0.04542148858308792, "loss_ft_l2": 0.3552807569503784}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.0621769428253174, "loss_ft": -2.481374740600586, "loss_norm": 0.04613472893834114, "loss_ft_l2": 0.37306302785873413}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.778883457183838, "loss_ft": -5.1641035079956055, "loss_norm": 0.04521387815475464, "loss_ft_l2": 0.34000644087791443}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.8430328369140625, "loss_ft": -5.188358306884766, "loss_norm": 0.04388374462723732, "loss_ft_l2": 0.30144158005714417}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -7.681671619415283, "loss_ft": -8.081645965576172, "loss_norm": 0.045340754091739655, "loss_ft_l2": 0.3546335995197296}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.2230875492095947, "loss_ft": -3.6165060997009277, "loss_norm": 0.045622311532497406, "loss_ft_l2": 0.3477962017059326}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.5837085247039795, "loss_ft": -2.9862399101257324, "loss_norm": 0.045715488493442535, "loss_ft_l2": 0.35681572556495667}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.1314549446105957, "loss_ft": -2.528968334197998, "loss_norm": 0.04567088186740875, "loss_ft_l2": 0.3518425226211548}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.6708085536956787, "loss_ft": -3.050687313079834, "loss_norm": 0.04573146253824234, "loss_ft_l2": 0.334147185087204}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -6.358938694000244, "loss_ft": -6.732640266418457, "loss_norm": 0.04571583494544029, "loss_ft_l2": 0.32798564434051514}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.323938369750977, "loss_ft": -4.727949142456055, "loss_norm": 0.04669469594955444, "loss_ft_l2": 0.3573160767555237}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.6069765090942383, "loss_ft": -3.021700859069824, "loss_norm": 0.045708850026130676, "loss_ft_l2": 0.36901554465293884}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.7205371856689453, "loss_ft": -2.126753807067871, "loss_norm": 0.045584894716739655, "loss_ft_l2": 0.36063170433044434}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.8762173652648926, "loss_ft": -3.3023014068603516, "loss_norm": 0.04441099986433983, "loss_ft_l2": 0.3816731870174408}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.4518198072910309, "loss_ft": -0.9006327390670776, "loss_norm": 0.045154355466365814, "loss_ft_l2": 0.40365859866142273}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.9417097568511963, "loss_ft": -4.3269734382629395, "loss_norm": 0.04557090625166893, "loss_ft_l2": 0.3396928012371063}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": 0.295421302318573, "loss_ft": -0.18360185623168945, "loss_norm": 0.04505985975265503, "loss_ft_l2": 0.4339632987976074}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.332995414733887, "loss_ft": -4.710885524749756, "loss_norm": 0.044905439019203186, "loss_ft_l2": 0.33298444747924805}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.597909688949585, "loss_ft": -3.0057685375213623, "loss_norm": 0.04595837742090225, "loss_ft_l2": 0.36190065741539}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -5.232238292694092, "loss_ft": -5.596035003662109, "loss_norm": 0.04523555189371109, "loss_ft_l2": 0.3185611665248871}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.473268985748291, "loss_ft": -2.896843910217285, "loss_norm": 0.04642312601208687, "loss_ft_l2": 0.3771516680717468}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.6105754375457764, "loss_ft": -3.9859237670898438, "loss_norm": 0.0462399423122406, "loss_ft_l2": 0.32910841703414917}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.175065279006958, "loss_ft": -2.605426788330078, "loss_norm": 0.046520017087459564, "loss_ft_l2": 0.3838415741920471}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.07596743106842041, "loss_ft": -0.5393449068069458, "loss_norm": 0.04575939103960991, "loss_ft_l2": 0.4176180958747864}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.508378267288208, "loss_ft": -2.900996446609497, "loss_norm": 0.04609734192490578, "loss_ft_l2": 0.34652096033096313}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -0.615152895450592, "loss_ft": -1.0500268936157227, "loss_norm": 0.046716608107089996, "loss_ft_l2": 0.3881574273109436}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.1281189918518066, "loss_ft": -3.52475905418396, "loss_norm": 0.045848116278648376, "loss_ft_l2": 0.3507918119430542}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.0549793243408203, "loss_ft": -3.396693229675293, "loss_norm": 0.04620587080717087, "loss_ft_l2": 0.2955082356929779}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -4.754369258880615, "loss_ft": -5.1145501136779785, "loss_norm": 0.046405866742134094, "loss_ft_l2": 0.31377512216567993}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.339749336242676, "loss_ft": -3.736527442932129, "loss_norm": 0.045394450426101685, "loss_ft_l2": 0.35138359665870667}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.817122459411621, "loss_ft": -4.225198745727539, "loss_norm": 0.04638413339853287, "loss_ft_l2": 0.3616919219493866}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.2149049043655396, "loss_ft": -1.6001311540603638, "loss_norm": 0.04640830308198929, "loss_ft_l2": 0.3388179838657379}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.872314214706421, "loss_ft": -2.291231393814087, "loss_norm": 0.04644864797592163, "loss_ft_l2": 0.3724684715270996}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -5.647472381591797, "loss_ft": -6.0150837898254395, "loss_norm": 0.04566352814435959, "loss_ft_l2": 0.3219478130340576}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -5.028985023498535, "loss_ft": -5.408447265625, "loss_norm": 0.045552365481853485, "loss_ft_l2": 0.3339097797870636}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.2900147438049316, "loss_ft": -2.7073750495910645, "loss_norm": 0.04569613188505173, "loss_ft_l2": 0.3716641962528229}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -1.2517169713974, "loss_ft": -1.6633479595184326, "loss_norm": 0.04581214115023613, "loss_ft_l2": 0.3658188283443451}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -5.658309459686279, "loss_ft": -6.044674873352051, "loss_norm": 0.04603155702352524, "loss_ft_l2": 0.3403337895870209}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -3.838693141937256, "loss_ft": -4.207261085510254, "loss_norm": 0.04604452848434448, "loss_ft_l2": 0.3225235044956207}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.0864334106445312, "loss_ft": -2.515118360519409, "loss_norm": 0.04594520851969719, "loss_ft_l2": 0.3827396631240845}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -5.278255462646484, "loss_ft": -5.6394124031066895, "loss_norm": 0.045831769704818726, "loss_ft_l2": 0.3153251111507416}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.481510639190674, "loss_ft": -2.8795294761657715, "loss_norm": 0.04726420342922211, "loss_ft_l2": 0.35075461864471436}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -5.272433280944824, "loss_ft": -5.6043596267700195, "loss_norm": 0.04530305415391922, "loss_ft_l2": 0.2866232395172119}
INFO - 01/13/26 20:17:20 - 0:00:01 - __log__:{"keyword": "iteration", "loss": -2.894213914871216, "loss_ft": -3.3024966716766357, "loss_norm": 0.04534076154232025, "loss_ft_l2": 0.36294203996658325}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.7744593620300293, "loss_ft": -3.2008774280548096, "loss_norm": 0.04523996263742447, "loss_ft_l2": 0.38117802143096924}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.579128265380859, "loss_ft": -4.966836452484131, "loss_norm": 0.04546689987182617, "loss_ft_l2": 0.34224146604537964}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -3.3449318408966064, "loss_ft": -3.7240447998046875, "loss_norm": 0.045825932174921036, "loss_ft_l2": 0.3332870304584503}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.281352996826172, "loss_ft": -4.667501926422119, "loss_norm": 0.04609491676092148, "loss_ft_l2": 0.34005412459373474}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -1.1527154445648193, "loss_ft": -1.6057525873184204, "loss_norm": 0.04632219672203064, "loss_ft_l2": 0.40671485662460327}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.400882720947266, "loss_ft": -4.760236740112305, "loss_norm": 0.04685605317354202, "loss_ft_l2": 0.3124982416629791}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.917530536651611, "loss_ft": -5.361893653869629, "loss_norm": 0.046256307512521744, "loss_ft_l2": 0.3981066346168518}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -6.868140697479248, "loss_ft": -7.259491920471191, "loss_norm": 0.045821722596883774, "loss_ft_l2": 0.34552934765815735}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -1.9299609661102295, "loss_ft": -2.3472254276275635, "loss_norm": 0.046466149389743805, "loss_ft_l2": 0.37079840898513794}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.193903923034668, "loss_ft": -4.552901268005371, "loss_norm": 0.04535679146647453, "loss_ft_l2": 0.3136407136917114}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.8864285945892334, "loss_ft": -3.321467161178589, "loss_norm": 0.04568534344434738, "loss_ft_l2": 0.38935333490371704}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -1.880042552947998, "loss_ft": -2.2436940670013428, "loss_norm": 0.04640214145183563, "loss_ft_l2": 0.3172493577003479}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.639819383621216, "loss_ft": -3.0223608016967773, "loss_norm": 0.046233583241701126, "loss_ft_l2": 0.33630770444869995}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": 0.16776496171951294, "loss_ft": -0.2852296829223633, "loss_norm": 0.045782025903463364, "loss_ft_l2": 0.40721261501312256}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -3.815544843673706, "loss_ft": -4.148426055908203, "loss_norm": 0.04583427682518959, "loss_ft_l2": 0.28704723715782166}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.446550369262695, "loss_ft": -4.853160858154297, "loss_norm": 0.04591897130012512, "loss_ft_l2": 0.36069175601005554}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -3.9577057361602783, "loss_ft": -4.35861873626709, "loss_norm": 0.046239081770181656, "loss_ft_l2": 0.3546741306781769}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -1.9756795167922974, "loss_ft": -2.4021902084350586, "loss_norm": 0.04590063542127609, "loss_ft_l2": 0.3806101083755493}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -3.2771310806274414, "loss_ft": -3.7154808044433594, "loss_norm": 0.04558584839105606, "loss_ft_l2": 0.39276382327079773}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.963627815246582, "loss_ft": -5.315810203552246, "loss_norm": 0.04568932577967644, "loss_ft_l2": 0.30649328231811523}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -3.5961999893188477, "loss_ft": -3.9973373413085938, "loss_norm": 0.04581906646490097, "loss_ft_l2": 0.35531824827194214}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.0905206203460693, "loss_ft": -2.518733501434326, "loss_norm": 0.045930493623018265, "loss_ft_l2": 0.38228240609169006}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -5.730939865112305, "loss_ft": -6.1044206619262695, "loss_norm": 0.04610547423362732, "loss_ft_l2": 0.32737526297569275}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.0248589515686035, "loss_ft": -4.39991569519043, "loss_norm": 0.04678524285554886, "loss_ft_l2": 0.3282715976238251}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -5.356096267700195, "loss_ft": -5.779633522033691, "loss_norm": 0.04808792099356651, "loss_ft_l2": 0.37544897198677063}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -7.018446922302246, "loss_ft": -7.411220550537109, "loss_norm": 0.04754505679011345, "loss_ft_l2": 0.34522849321365356}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -3.208577871322632, "loss_ft": -3.6469802856445312, "loss_norm": 0.047198258340358734, "loss_ft_l2": 0.3912040889263153}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -5.280513286590576, "loss_ft": -5.66419792175293, "loss_norm": 0.04685835540294647, "loss_ft_l2": 0.33682647347450256}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -6.164289951324463, "loss_ft": -6.574943542480469, "loss_norm": 0.046803489327430725, "loss_ft_l2": 0.36385002732276917}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -1.8211405277252197, "loss_ft": -2.2841482162475586, "loss_norm": 0.04685679078102112, "loss_ft_l2": 0.4161508083343506}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -1.755160927772522, "loss_ft": -2.159149646759033, "loss_norm": 0.04785436764359474, "loss_ft_l2": 0.3561343252658844}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -3.1323158740997314, "loss_ft": -3.531768321990967, "loss_norm": 0.047898538410663605, "loss_ft_l2": 0.35155391693115234}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -5.375275135040283, "loss_ft": -5.773654937744141, "loss_norm": 0.04739460349082947, "loss_ft_l2": 0.35098496079444885}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.057723045349121, "loss_ft": -4.485448837280273, "loss_norm": 0.046150900423526764, "loss_ft_l2": 0.381575345993042}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -1.3661843538284302, "loss_ft": -1.811897873878479, "loss_norm": 0.046118076890707016, "loss_ft_l2": 0.3995954692363739}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.651747226715088, "loss_ft": -3.0396342277526855, "loss_norm": 0.046281129121780396, "loss_ft_l2": 0.3416060209274292}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -3.421607255935669, "loss_ft": -3.8383727073669434, "loss_norm": 0.047306887805461884, "loss_ft_l2": 0.3694586753845215}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -3.0277295112609863, "loss_ft": -3.429455041885376, "loss_norm": 0.046961311250925064, "loss_ft_l2": 0.35476428270339966}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -0.8908576965332031, "loss_ft": -1.3070085048675537, "loss_norm": 0.047048307955265045, "loss_ft_l2": 0.36910247802734375}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.976747989654541, "loss_ft": -5.380232334136963, "loss_norm": 0.04581083729863167, "loss_ft_l2": 0.3576735556125641}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.623532295227051, "loss_ft": -4.998542785644531, "loss_norm": 0.046384379267692566, "loss_ft_l2": 0.32862594723701477}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.8621881008148193, "loss_ft": -3.262073040008545, "loss_norm": 0.046283699572086334, "loss_ft_l2": 0.35360124707221985}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -3.622992753982544, "loss_ft": -4.038013458251953, "loss_norm": 0.046631429344415665, "loss_ft_l2": 0.3683893084526062}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.637331962585449, "loss_ft": -5.012160301208496, "loss_norm": 0.04695626720786095, "loss_ft_l2": 0.3278721868991852}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -3.280409336090088, "loss_ft": -3.685051441192627, "loss_norm": 0.04690747708082199, "loss_ft_l2": 0.3577346205711365}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -3.139902353286743, "loss_ft": -3.5684735774993896, "loss_norm": 0.04722587764263153, "loss_ft_l2": 0.381345272064209}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.2574591636657715, "loss_ft": -2.64013671875, "loss_norm": 0.0481753908097744, "loss_ft_l2": 0.33450227975845337}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -7.1411919593811035, "loss_ft": -7.505701541900635, "loss_norm": 0.047829531133174896, "loss_ft_l2": 0.31667983531951904}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -0.19517600536346436, "loss_ft": -0.637799859046936, "loss_norm": 0.048997171223163605, "loss_ft_l2": 0.39362668991088867}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -5.289999485015869, "loss_ft": -5.704916000366211, "loss_norm": 0.047510676085948944, "loss_ft_l2": 0.3674059212207794}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -5.010483741760254, "loss_ft": -5.395047187805176, "loss_norm": 0.047771673649549484, "loss_ft_l2": 0.3367922008037567}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.209199905395508, "loss_ft": -2.6207194328308105, "loss_norm": 0.04764775186777115, "loss_ft_l2": 0.3638717532157898}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -3.12605881690979, "loss_ft": -3.538797616958618, "loss_norm": 0.046794287860393524, "loss_ft_l2": 0.36594459414482117}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.3597216606140137, "loss_ft": -2.7730765342712402, "loss_norm": 0.04711953178048134, "loss_ft_l2": 0.3662351667881012}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.616272926330566, "loss_ft": -5.007055759429932, "loss_norm": 0.047373320907354355, "loss_ft_l2": 0.34340956807136536}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.3337953090667725, "loss_ft": -2.767001152038574, "loss_norm": 0.04695994406938553, "loss_ft_l2": 0.38624587655067444}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -1.942800760269165, "loss_ft": -2.3831069469451904, "loss_norm": 0.04667337238788605, "loss_ft_l2": 0.3936328887939453}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -1.7452988624572754, "loss_ft": -2.0866541862487793, "loss_norm": 0.04671231657266617, "loss_ft_l2": 0.29464298486709595}
INFO - 01/13/26 20:17:20 - 0:00:02 - __log__:{"keyword": "final", "psnr": 31.215652727865503, "ft_direction": 3.2434253692626953, "ft_norm": 16.394914627075195, "cosine_mean": 0.1981412172317505, "rho": -1, "R": -546.9458618164062}
INFO - 01/13/26 20:19:51 - 0:00:00 - ============ Initialized logger ============
INFO - 01/13/26 20:19:51 - 0:00:00 - angle: None
                                     carrier_id: 0
                                     carrier_path: carriers.pth
                                     command: python make_data_radioactive.py --carrier_id 0 --carrier_path 'carriers.pth' --data_augmentation random --epochs 200 --img_paths 'cifar10_images/0/29.png,cifar10_images/0/77.png' --lambda_ft_l2 '0.01' --lambda_l2_img '0.0005' --marking_network 'pretrained_resnet18.pth' --dump_path './cifar10_marked' --optimizer 'sgd,lr=1.0' --exp_id "cifar10_marked"
                                     crop_size: 224
                                     data_augmentation: random
                                     debug: False
                                     debug_slurm: False
                                     debug_train: False
                                     dump_path: ./cifar10_marked
                                     epochs: 200
                                     exp_id: cifar10_marked
                                     exp_name: bypass
                                     half_cone: True
                                     img_list: None
                                     img_paths: cifar10_images/0/29.png,cifar10_images/0/77.png
                                     img_size: 256
                                     lambda_ft_l2: 0.01
                                     lambda_l2_img: 0.0005
                                     marking_network: pretrained_resnet18.pth
                                     optimizer: sgd,lr=1.0
                                     radius: 10
INFO - 01/13/26 20:19:51 - 0:00:00 - The experiment will be stored in ./cifar10_marked
                                     
INFO - 01/13/26 20:19:51 - 0:00:00 - Running command: python make_data_radioactive.py --carrier_id 0 --carrier_path 'carriers.pth' --data_augmentation random --epochs 200 --img_paths 'cifar10_images/0/29.png,cifar10_images/0/77.png' --lambda_ft_l2 '0.01' --lambda_l2_img '0.0005' --marking_network 'pretrained_resnet18.pth' --dump_path './cifar10_marked' --optimizer 'sgd,lr=1.0'

INFO - 01/13/26 20:19:51 - 0:00:00 - Model: ResNet(
                                       (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
                                       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                       (relu): ReLU(inplace=True)
                                       (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
                                       (layer1): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer2): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer3): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (layer4): Sequential(
                                         (0): BasicBlock(
                                           (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (downsample): Sequential(
                                             (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                                             (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           )
                                         )
                                         (1): BasicBlock(
                                           (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                           (relu): ReLU(inplace=True)
                                           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                                           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                                         )
                                       )
                                       (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
                                       (fc): Linear(in_features=512, out_features=10, bias=True)
                                     )
DEBUG - 01/13/26 20:19:51 - 0:00:00 - STREAM b'IHDR' 16 13
DEBUG - 01/13/26 20:19:51 - 0:00:00 - STREAM b'IDAT' 41 2006
DEBUG - 01/13/26 20:19:51 - 0:00:00 - STREAM b'IHDR' 16 13
DEBUG - 01/13/26 20:19:51 - 0:00:00 - STREAM b'IDAT' 41 2124
INFO - 01/13/26 20:19:51 - 0:00:00 - Schedule of sgd,lr=1.0: None
INFO - 01/13/26 20:19:52 - 0:00:01 - __log__:{"keyword": "iteration", "loss": 0.22605553269386292, "loss_ft": -0.03177076578140259, "loss_norm": 0.0, "loss_ft_l2": 0.2578262984752655, "alpha_mean": 0.03177076578140259, "cosine_mean": -0.0005396679043769836}
INFO - 01/13/26 20:19:52 - 0:00:01 - __log__:{"keyword": "iteration", "loss": 0.09088176488876343, "loss_ft": -0.26544904708862305, "loss_norm": 0.008124406449496746, "loss_ft_l2": 0.34820640087127686, "alpha_mean": 0.26544904708862305, "cosine_mean": 0.004415865987539291}
INFO - 01/13/26 20:19:52 - 0:00:01 - __log__:{"keyword": "iteration", "loss": 0.045516014099121094, "loss_ft": -0.32837963104248047, "loss_norm": 0.01348106749355793, "loss_ft_l2": 0.3604145646095276, "alpha_mean": 0.32837963104248047, "cosine_mean": 0.014904621988534927}
INFO - 01/13/26 20:19:52 - 0:00:01 - __log__:{"keyword": "iteration", "loss": 1.044450044631958, "loss_ft": 0.6416879296302795, "loss_norm": 0.01744634285569191, "loss_ft_l2": 0.38531583547592163, "alpha_mean": -0.6416879296302795, "cosine_mean": -0.018501635640859604}
INFO - 01/13/26 20:19:52 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -1.0567638874053955, "loss_ft": -1.380948781967163, "loss_norm": 0.01920224353671074, "loss_ft_l2": 0.3049827218055725, "alpha_mean": 1.380948781967163, "cosine_mean": 0.04705926403403282}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -1.8635022640228271, "loss_ft": -2.2377166748046875, "loss_norm": 0.023641562089323997, "loss_ft_l2": 0.350572794675827, "alpha_mean": 2.2377166748046875, "cosine_mean": 0.057889025658369064}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -1.8291209936141968, "loss_ft": -2.143397092819214, "loss_norm": 0.02618037909269333, "loss_ft_l2": 0.2880958616733551, "alpha_mean": 2.143397092819214, "cosine_mean": 0.061942100524902344}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -1.2940870523452759, "loss_ft": -1.6834399700164795, "loss_norm": 0.02796047180891037, "loss_ft_l2": 0.3613924980163574, "alpha_mean": 1.6834399700164795, "cosine_mean": 0.054192256182432175}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -0.4431711733341217, "loss_ft": -0.8530474305152893, "loss_norm": 0.02900993637740612, "loss_ft_l2": 0.38086631894111633, "alpha_mean": 0.8530474305152893, "cosine_mean": 0.020356692373752594}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -0.865728497505188, "loss_ft": -1.2688243389129639, "loss_norm": 0.029972851276397705, "loss_ft_l2": 0.37312307953834534, "alpha_mean": 1.2688243389129639, "cosine_mean": 0.032946761697530746}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -0.4375287592411041, "loss_ft": -0.8388022184371948, "loss_norm": 0.030185412615537643, "loss_ft_l2": 0.37108805775642395, "alpha_mean": 0.8388022184371948, "cosine_mean": 0.018114814534783363}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -1.3339595794677734, "loss_ft": -1.7383339405059814, "loss_norm": 0.030116740614175797, "loss_ft_l2": 0.37425756454467773, "alpha_mean": 1.7383339405059814, "cosine_mean": 0.03861772269010544}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -1.2124302387237549, "loss_ft": -1.6230820417404175, "loss_norm": 0.031177671626210213, "loss_ft_l2": 0.37947410345077515, "alpha_mean": 1.6230820417404175, "cosine_mean": 0.050056226551532745}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -1.5283228158950806, "loss_ft": -1.9547922611236572, "loss_norm": 0.03173089772462845, "loss_ft_l2": 0.3947385251522064, "alpha_mean": 1.9547922611236572, "cosine_mean": 0.05255072936415672}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.331860542297363, "loss_ft": -4.70108699798584, "loss_norm": 0.03252819925546646, "loss_ft_l2": 0.33669814467430115, "alpha_mean": 4.70108699798584, "cosine_mean": 0.12894311547279358}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -1.9314824342727661, "loss_ft": -2.333244800567627, "loss_norm": 0.033509694039821625, "loss_ft_l2": 0.36825263500213623, "alpha_mean": 2.333244800567627, "cosine_mean": 0.05950601026415825}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -1.4940943717956543, "loss_ft": -1.8911949396133423, "loss_norm": 0.03388005495071411, "loss_ft_l2": 0.3632204234600067, "alpha_mean": 1.8911949396133423, "cosine_mean": 0.04843331128358841}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.170921802520752, "loss_ft": -2.5383899211883545, "loss_norm": 0.03528796136379242, "loss_ft_l2": 0.33218032121658325, "alpha_mean": 2.5383899211883545, "cosine_mean": 0.07625745981931686}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -1.3274509906768799, "loss_ft": -1.7455790042877197, "loss_norm": 0.03565822169184685, "loss_ft_l2": 0.38246971368789673, "alpha_mean": 1.7455790042877197, "cosine_mean": 0.050470929592847824}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": 0.373109370470047, "loss_ft": -0.1029973030090332, "loss_norm": 0.03586402162909508, "loss_ft_l2": 0.4402426481246948, "alpha_mean": 0.1029973030090332, "cosine_mean": 0.004282716661691666}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -0.45997241139411926, "loss_ft": -0.8984607458114624, "loss_norm": 0.0357511043548584, "loss_ft_l2": 0.40273723006248474, "alpha_mean": 0.8984607458114624, "cosine_mean": 0.016504552215337753}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.859772205352783, "loss_ft": -3.2022528648376465, "loss_norm": 0.035643570125103, "loss_ft_l2": 0.3068370223045349, "alpha_mean": 3.2022528648376465, "cosine_mean": 0.10133242607116699}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.11672306060791, "loss_ft": -2.533026695251465, "loss_norm": 0.03645169362425804, "loss_ft_l2": 0.37985193729400635, "alpha_mean": 2.533026695251465, "cosine_mean": 0.07363422214984894}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -3.0552926063537598, "loss_ft": -3.4961440563201904, "loss_norm": 0.03641435503959656, "loss_ft_l2": 0.4044370949268341, "alpha_mean": 3.4961440563201904, "cosine_mean": 0.08630259335041046}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.599595069885254, "loss_ft": -4.976035118103027, "loss_norm": 0.037482257932424545, "loss_ft_l2": 0.33895766735076904, "alpha_mean": 4.976035118103027, "cosine_mean": 0.1450148969888687}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -0.09782612323760986, "loss_ft": -0.5567667484283447, "loss_norm": 0.03836511820554733, "loss_ft_l2": 0.42057549953460693, "alpha_mean": 0.5567667484283447, "cosine_mean": 0.013843292370438576}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -0.5338901281356812, "loss_ft": -0.894996166229248, "loss_norm": 0.038225919008255005, "loss_ft_l2": 0.3228801190853119, "alpha_mean": 0.894996166229248, "cosine_mean": 0.045928556472063065}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.7701256275177, "loss_ft": -3.209343910217285, "loss_norm": 0.03852080926299095, "loss_ft_l2": 0.40069738030433655, "alpha_mean": 3.209343910217285, "cosine_mean": 0.08139333128929138}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -1.0411714315414429, "loss_ft": -1.4351890087127686, "loss_norm": 0.038477573543787, "loss_ft_l2": 0.355540007352829, "alpha_mean": 1.4351890087127686, "cosine_mean": 0.04824148118495941}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -3.506826162338257, "loss_ft": -3.857764720916748, "loss_norm": 0.03819302096962929, "loss_ft_l2": 0.3127455711364746, "alpha_mean": 3.857764720916748, "cosine_mean": 0.119429811835289}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -1.9475152492523193, "loss_ft": -2.3615076541900635, "loss_norm": 0.039300791919231415, "loss_ft_l2": 0.3746917247772217, "alpha_mean": 2.3615076541900635, "cosine_mean": 0.0645868331193924}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.496969699859619, "loss_ft": -4.909920692443848, "loss_norm": 0.03857339918613434, "loss_ft_l2": 0.3743775188922882, "alpha_mean": 4.909920692443848, "cosine_mean": 0.12896384298801422}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": 0.43356943130493164, "loss_ft": 0.0016788244247436523, "loss_norm": 0.03951491042971611, "loss_ft_l2": 0.3923757076263428, "alpha_mean": -0.0016788244247436523, "cosine_mean": -0.0011765863746404648}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.663923263549805, "loss_ft": -5.026616096496582, "loss_norm": 0.03947529196739197, "loss_ft_l2": 0.323217511177063, "alpha_mean": 5.026616096496582, "cosine_mean": 0.15688642859458923}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.348059177398682, "loss_ft": -4.75370454788208, "loss_norm": 0.039699964225292206, "loss_ft_l2": 0.3659452795982361, "alpha_mean": 4.75370454788208, "cosine_mean": 0.12250006198883057}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.5937283039093018, "loss_ft": -2.98547101020813, "loss_norm": 0.040152110159397125, "loss_ft_l2": 0.3515906035900116, "alpha_mean": 2.98547101020813, "cosine_mean": 0.09269357472658157}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -5.181515693664551, "loss_ft": -5.56764030456543, "loss_norm": 0.0408550500869751, "loss_ft_l2": 0.3452695906162262, "alpha_mean": 5.56764030456543, "cosine_mean": 0.1634640246629715}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -3.278144359588623, "loss_ft": -3.6723310947418213, "loss_norm": 0.04088372737169266, "loss_ft_l2": 0.3533029854297638, "alpha_mean": 3.6723310947418213, "cosine_mean": 0.10120820999145508}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.658946990966797, "loss_ft": -3.026960849761963, "loss_norm": 0.041285477578639984, "loss_ft_l2": 0.32672828435897827, "alpha_mean": 3.026960849761963, "cosine_mean": 0.10780344903469086}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -6.731247425079346, "loss_ft": -7.13053035736084, "loss_norm": 0.042645856738090515, "loss_ft_l2": 0.35663720965385437, "alpha_mean": 7.13053035736084, "cosine_mean": 0.1965494304895401}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.6252665519714355, "loss_ft": -5.012779712677002, "loss_norm": 0.04296273738145828, "loss_ft_l2": 0.3445507884025574, "alpha_mean": 5.012779712677002, "cosine_mean": 0.14127615094184875}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -5.513308525085449, "loss_ft": -5.936971664428711, "loss_norm": 0.0431755930185318, "loss_ft_l2": 0.3804875612258911, "alpha_mean": 5.936971664428711, "cosine_mean": 0.15200117230415344}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -6.179751873016357, "loss_ft": -6.566182613372803, "loss_norm": 0.04338584095239639, "loss_ft_l2": 0.34304457902908325, "alpha_mean": 6.566182613372803, "cosine_mean": 0.18653979897499084}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.073136568069458, "loss_ft": -2.480133295059204, "loss_norm": 0.04385822266340256, "loss_ft_l2": 0.363138347864151, "alpha_mean": 2.480133295059204, "cosine_mean": 0.06433752179145813}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -3.7848639488220215, "loss_ft": -4.168220520019531, "loss_norm": 0.04401031881570816, "loss_ft_l2": 0.3393465280532837, "alpha_mean": 4.168220520019531, "cosine_mean": 0.12105496227741241}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -0.8257588148117065, "loss_ft": -1.2768352031707764, "loss_norm": 0.04336555302143097, "loss_ft_l2": 0.4077107608318329, "alpha_mean": 1.2768352031707764, "cosine_mean": 0.030185407027602196}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.004054546356201, "loss_ft": -4.444385051727295, "loss_norm": 0.04380427673459053, "loss_ft_l2": 0.39652612805366516, "alpha_mean": 4.444385051727295, "cosine_mean": 0.11919417977333069}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -3.777338743209839, "loss_ft": -4.196177959442139, "loss_norm": 0.04333019629120827, "loss_ft_l2": 0.37550902366638184, "alpha_mean": 4.196177959442139, "cosine_mean": 0.10745970904827118}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.2567293643951416, "loss_ft": -2.6721489429473877, "loss_norm": 0.044455815106630325, "loss_ft_l2": 0.3709639012813568, "alpha_mean": 2.6721489429473877, "cosine_mean": 0.07181554287672043}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.3711116313934326, "loss_ft": -2.774282455444336, "loss_norm": 0.044010505080223083, "loss_ft_l2": 0.3591603636741638, "alpha_mean": 2.774282455444336, "cosine_mean": 0.08275558799505234}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -1.2596638202667236, "loss_ft": -1.7006231546401978, "loss_norm": 0.044256389141082764, "loss_ft_l2": 0.3967030346393585, "alpha_mean": 1.7006231546401978, "cosine_mean": 0.0498412661254406}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.42347526550293, "loss_ft": -4.800166606903076, "loss_norm": 0.04322778433561325, "loss_ft_l2": 0.3334638178348541, "alpha_mean": 4.800166606903076, "cosine_mean": 0.14821316301822662}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -3.9319446086883545, "loss_ft": -4.342875957489014, "loss_norm": 0.04337228089570999, "loss_ft_l2": 0.36755919456481934, "alpha_mean": 4.342875957489014, "cosine_mean": 0.11884908378124237}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.6609721183776855, "loss_ft": -3.0291085243225098, "loss_norm": 0.042913325130939484, "loss_ft_l2": 0.32522299885749817, "alpha_mean": 3.0291085243225098, "cosine_mean": 0.09503068029880524}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.282524347305298, "loss_ft": -2.703672170639038, "loss_norm": 0.043577127158641815, "loss_ft_l2": 0.37757062911987305, "alpha_mean": 2.703672170639038, "cosine_mean": 0.0774591863155365}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -5.983823776245117, "loss_ft": -6.382203578948975, "loss_norm": 0.04345197230577469, "loss_ft_l2": 0.354928195476532, "alpha_mean": 6.382203578948975, "cosine_mean": 0.1792706847190857}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -3.2199316024780273, "loss_ft": -3.6358838081359863, "loss_norm": 0.04320099949836731, "loss_ft_l2": 0.3727511465549469, "alpha_mean": 3.6358838081359863, "cosine_mean": 0.09800121933221817}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -1.8834952116012573, "loss_ft": -2.2440242767333984, "loss_norm": 0.0434560626745224, "loss_ft_l2": 0.3170729875564575, "alpha_mean": 2.2440242767333984, "cosine_mean": 0.09668156504631042}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.2467727661132812, "loss_ft": -2.6612370014190674, "loss_norm": 0.04388126730918884, "loss_ft_l2": 0.37058302760124207, "alpha_mean": 2.6612370014190674, "cosine_mean": 0.07984255999326706}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -5.741163730621338, "loss_ft": -6.1390275955200195, "loss_norm": 0.0441524013876915, "loss_ft_l2": 0.3537116050720215, "alpha_mean": 6.1390275955200195, "cosine_mean": 0.17356032133102417}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.5185623168945312, "loss_ft": -2.9092705249786377, "loss_norm": 0.04413825646042824, "loss_ft_l2": 0.3465699553489685, "alpha_mean": 2.9092705249786377, "cosine_mean": 0.09031963348388672}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.32823371887207, "loss_ft": -4.726642608642578, "loss_norm": 0.04362273961305618, "loss_ft_l2": 0.35478585958480835, "alpha_mean": 4.726642608642578, "cosine_mean": 0.13032442331314087}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -0.8601921796798706, "loss_ft": -1.2449136972427368, "loss_norm": 0.04462425783276558, "loss_ft_l2": 0.3400972783565521, "alpha_mean": 1.2449136972427368, "cosine_mean": 0.06708406656980515}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -6.624892234802246, "loss_ft": -7.035032272338867, "loss_norm": 0.04503261297941208, "loss_ft_l2": 0.3651076555252075, "alpha_mean": 7.035032272338867, "cosine_mean": 0.18122997879981995}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.665741443634033, "loss_ft": -3.045947551727295, "loss_norm": 0.04524881765246391, "loss_ft_l2": 0.3349572420120239, "alpha_mean": 3.045947551727295, "cosine_mean": 0.09431108832359314}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.1062777042388916, "loss_ft": -2.541656970977783, "loss_norm": 0.04463557153940201, "loss_ft_l2": 0.3907436728477478, "alpha_mean": 2.541656970977783, "cosine_mean": 0.08151042461395264}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -5.097887992858887, "loss_ft": -5.475090026855469, "loss_norm": 0.044743385165929794, "loss_ft_l2": 0.3324585556983948, "alpha_mean": 5.475090026855469, "cosine_mean": 0.16354966163635254}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -0.32616978883743286, "loss_ft": -0.7746192216873169, "loss_norm": 0.04537370428442955, "loss_ft_l2": 0.4030757546424866, "alpha_mean": 0.7746192216873169, "cosine_mean": 0.02341567352414131}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -3.4167962074279785, "loss_ft": -3.845196485519409, "loss_norm": 0.04525095224380493, "loss_ft_l2": 0.38314926624298096, "alpha_mean": 3.845196485519409, "cosine_mean": 0.10284401476383209}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -5.111528396606445, "loss_ft": -5.527673721313477, "loss_norm": 0.044587209820747375, "loss_ft_l2": 0.37155839800834656, "alpha_mean": 5.527673721313477, "cosine_mean": 0.15022867918014526}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -5.788008689880371, "loss_ft": -6.191184043884277, "loss_norm": 0.044794484972953796, "loss_ft_l2": 0.35838088393211365, "alpha_mean": 6.191184043884277, "cosine_mean": 0.1726401448249817}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -0.5374847054481506, "loss_ft": -0.9609589576721191, "loss_norm": 0.04474403336644173, "loss_ft_l2": 0.37873023748397827, "alpha_mean": 0.9609589576721191, "cosine_mean": 0.0247641708701849}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -3.6576220989227295, "loss_ft": -4.061331272125244, "loss_norm": 0.04429434612393379, "loss_ft_l2": 0.35941481590270996, "alpha_mean": 4.061331272125244, "cosine_mean": 0.11344839632511139}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.000470161437988, "loss_ft": -4.467019081115723, "loss_norm": 0.04448342323303223, "loss_ft_l2": 0.422065794467926, "alpha_mean": 4.467019081115723, "cosine_mean": 0.10754264891147614}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -5.198844909667969, "loss_ft": -5.619053840637207, "loss_norm": 0.04404178261756897, "loss_ft_l2": 0.3761672079563141, "alpha_mean": 5.619053840637207, "cosine_mean": 0.1493816375732422}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.281626224517822, "loss_ft": -4.647090911865234, "loss_norm": 0.044596023857593536, "loss_ft_l2": 0.32086843252182007, "alpha_mean": 4.647090911865234, "cosine_mean": 0.15521079301834106}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.278571128845215, "loss_ft": -2.6971304416656494, "loss_norm": 0.04507320001721382, "loss_ft_l2": 0.37348616123199463, "alpha_mean": 2.6971304416656494, "cosine_mean": 0.07067900896072388}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.591475009918213, "loss_ft": -2.9887778759002686, "loss_norm": 0.04510083794593811, "loss_ft_l2": 0.3522018492221832, "alpha_mean": 2.9887778759002686, "cosine_mean": 0.09001767635345459}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.186338424682617, "loss_ft": -4.572422981262207, "loss_norm": 0.04516947641968727, "loss_ft_l2": 0.3409152626991272, "alpha_mean": 4.572422981262207, "cosine_mean": 0.12195929884910583}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -1.905423879623413, "loss_ft": -2.3255388736724854, "loss_norm": 0.045300886034965515, "loss_ft_l2": 0.37481409311294556, "alpha_mean": 2.3255388736724854, "cosine_mean": 0.05646250396966934}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.668980360031128, "loss_ft": -3.10459303855896, "loss_norm": 0.04465530812740326, "loss_ft_l2": 0.3909573256969452, "alpha_mean": 3.10459303855896, "cosine_mean": 0.08768019825220108}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.5700738430023193, "loss_ft": -3.0086748600006104, "loss_norm": 0.04421410337090492, "loss_ft_l2": 0.3943869173526764, "alpha_mean": 3.0086748600006104, "cosine_mean": 0.07220526784658432}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -0.5008412599563599, "loss_ft": -0.9261263012886047, "loss_norm": 0.043543897569179535, "loss_ft_l2": 0.38174113631248474, "alpha_mean": 0.9261263012886047, "cosine_mean": 0.02263738214969635}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -3.0453972816467285, "loss_ft": -3.438646078109741, "loss_norm": 0.0432153083384037, "loss_ft_l2": 0.3500335216522217, "alpha_mean": 3.438646078109741, "cosine_mean": 0.1099337488412857}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -0.8368594646453857, "loss_ft": -1.2527738809585571, "loss_norm": 0.04446382820606232, "loss_ft_l2": 0.3714505732059479, "alpha_mean": 1.2527738809585571, "cosine_mean": 0.03680139780044556}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.673510789871216, "loss_ft": -3.108510971069336, "loss_norm": 0.04361144080758095, "loss_ft_l2": 0.39138856530189514, "alpha_mean": 3.108510971069336, "cosine_mean": 0.07973924279212952}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.6955387592315674, "loss_ft": -3.1152899265289307, "loss_norm": 0.04364408552646637, "loss_ft_l2": 0.37610694766044617, "alpha_mean": 3.1152899265289307, "cosine_mean": 0.10649891197681427}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -3.281069278717041, "loss_ft": -3.701653003692627, "loss_norm": 0.04363811016082764, "loss_ft_l2": 0.37694552540779114, "alpha_mean": 3.701653003692627, "cosine_mean": 0.10228733718395233}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -5.477766513824463, "loss_ft": -5.857542991638184, "loss_norm": 0.0439569354057312, "loss_ft_l2": 0.335819810628891, "alpha_mean": 5.857542991638184, "cosine_mean": 0.16367539763450623}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.374947547912598, "loss_ft": -4.792247772216797, "loss_norm": 0.04460233449935913, "loss_ft_l2": 0.3726978898048401, "alpha_mean": 4.792247772216797, "cosine_mean": 0.12534655630588531}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.678373336791992, "loss_ft": -5.078922271728516, "loss_norm": 0.04551967978477478, "loss_ft_l2": 0.35502889752388, "alpha_mean": 5.078922271728516, "cosine_mean": 0.14006729423999786}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -4.682316303253174, "loss_ft": -5.08195686340332, "loss_norm": 0.0448877289891243, "loss_ft_l2": 0.3547531068325043, "alpha_mean": 5.08195686340332, "cosine_mean": 0.14500436186790466}
INFO - 01/13/26 20:19:53 - 0:00:02 - __log__:{"keyword": "iteration", "loss": -2.5081210136413574, "loss_ft": -2.9089012145996094, "loss_norm": 0.04527958855032921, "loss_ft_l2": 0.3555006980895996, "alpha_mean": 2.9089012145996094, "cosine_mean": 0.0783064067363739}
INFO - 01/13/26 20:19:54 - 0:00:03 - __log__:{"keyword": "iteration", "loss": -3.0080277919769287, "loss_ft": -3.399141788482666, "loss_norm": 0.044930458068847656, "loss_ft_l2": 0.34618350863456726, "alpha_mean": 3.399141788482666, "cosine_mean": 0.09770266711711884}
INFO - 01/13/26 20:19:54 - 0:00:03 - __log__:{"keyword": "iteration", "loss": -1.222809910774231, "loss_ft": -1.6486318111419678, "loss_norm": 0.04477976635098457, "loss_ft_l2": 0.38104209303855896, "alpha_mean": 1.6486318111419678, "cosine_mean": 0.045871980488300323}
INFO - 01/13/26 20:19:54 - 0:00:03 - __log__:{"keyword": "iteration", "loss": -2.238882064819336, "loss_ft": -2.660083293914795, "loss_norm": 0.04445965588092804, "loss_ft_l2": 0.3767416179180145, "alpha_mean": 2.660083293914795, "cosine_mean": 0.07148727029561996}
INFO - 01/13/26 20:19:54 - 0:00:03 - __log__:{"keyword": "iteration", "loss": -2.478174924850464, "loss_ft": -2.869610548019409, "loss_norm": 0.044699955731630325, "loss_ft_l2": 0.3467356860637665, "alpha_mean": 2.869610548019409, "cosine_mean": 0.08365610241889954}
INFO - 01/13/26 20:19:54 - 0:00:03 - __log__:{"keyword": "iteration", "loss": -4.6714677810668945, "loss_ft": -5.094404220581055, "loss_norm": 0.04558021202683449, "loss_ft_l2": 0.37735599279403687, "alpha_mean": 5.094404220581055, "cosine_mean": 0.13207679986953735}
INFO - 01/13/26 20:19:54 - 0:00:03 - __log__:{"keyword": "iteration", "loss": 0.18857140839099884, "loss_ft": -0.2827276587486267, "loss_norm": 0.04516474902629852, "loss_ft_l2": 0.426134318113327, "alpha_mean": 0.2827276587486267, "cosine_mean": 0.006784528493881226}
INFO - 01/13/26 20:19:55 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -4.967652320861816, "loss_ft": -5.342801094055176, "loss_norm": 0.044931560754776, "loss_ft_l2": 0.33021730184555054, "alpha_mean": 5.342801094055176, "cosine_mean": 0.164617657661438}
INFO - 01/13/26 20:19:55 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -3.217076301574707, "loss_ft": -3.6722970008850098, "loss_norm": 0.04554101824760437, "loss_ft_l2": 0.4096797704696655, "alpha_mean": 3.6722970008850098, "cosine_mean": 0.09095567464828491}
INFO - 01/13/26 20:19:55 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -3.051436185836792, "loss_ft": -3.451106548309326, "loss_norm": 0.04537751525640488, "loss_ft_l2": 0.3542928099632263, "alpha_mean": 3.451106548309326, "cosine_mean": 0.10047309100627899}
INFO - 01/13/26 20:19:55 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -2.2322568893432617, "loss_ft": -2.653186082839966, "loss_norm": 0.04520503059029579, "loss_ft_l2": 0.37572410702705383, "alpha_mean": 2.653186082839966, "cosine_mean": 0.0672377198934555}
INFO - 01/13/26 20:19:55 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -1.7902311086654663, "loss_ft": -2.238152027130127, "loss_norm": 0.04618065804243088, "loss_ft_l2": 0.4017401933670044, "alpha_mean": 2.238152027130127, "cosine_mean": 0.055433835834264755}
INFO - 01/13/26 20:19:55 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -3.029539108276367, "loss_ft": -3.391125440597534, "loss_norm": 0.046157754957675934, "loss_ft_l2": 0.3154284954071045, "alpha_mean": 3.391125440597534, "cosine_mean": 0.10819172114133835}
INFO - 01/13/26 20:19:55 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -2.6968202590942383, "loss_ft": -3.1423559188842773, "loss_norm": 0.04597342014312744, "loss_ft_l2": 0.39956244826316833, "alpha_mean": 3.1423559188842773, "cosine_mean": 0.08048105239868164}
INFO - 01/13/26 20:19:55 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -1.7642842531204224, "loss_ft": -2.1662516593933105, "loss_norm": 0.045638445764780045, "loss_ft_l2": 0.3563288152217865, "alpha_mean": 2.1662516593933105, "cosine_mean": 0.06929206848144531}
INFO - 01/13/26 20:19:55 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -1.2999824285507202, "loss_ft": -1.7358930110931396, "loss_norm": 0.04545686021447182, "loss_ft_l2": 0.3904537260532379, "alpha_mean": 1.7358930110931396, "cosine_mean": 0.044681597501039505}
INFO - 01/13/26 20:19:55 - 0:00:04 - __log__:{"keyword": "iteration", "loss": 0.04270261526107788, "loss_ft": -0.4053748846054077, "loss_norm": 0.04512882977724075, "loss_ft_l2": 0.40294867753982544, "alpha_mean": 0.4053748846054077, "cosine_mean": 0.010766502469778061}
INFO - 01/13/26 20:19:55 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -4.238908767700195, "loss_ft": -4.618222236633301, "loss_norm": 0.045161157846450806, "loss_ft_l2": 0.33415207266807556, "alpha_mean": 4.618222236633301, "cosine_mean": 0.13859951496124268}
INFO - 01/13/26 20:19:55 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -2.722675085067749, "loss_ft": -3.1041016578674316, "loss_norm": 0.04482743516564369, "loss_ft_l2": 0.33659908175468445, "alpha_mean": 3.1041016578674316, "cosine_mean": 0.09846436977386475}
INFO - 01/13/26 20:19:55 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -2.3400282859802246, "loss_ft": -2.7704880237579346, "loss_norm": 0.04387688636779785, "loss_ft_l2": 0.38658276200294495, "alpha_mean": 2.7704880237579346, "cosine_mean": 0.07635259628295898}
INFO - 01/13/26 20:19:55 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -2.7967798709869385, "loss_ft": -3.187751054763794, "loss_norm": 0.043989397585392, "loss_ft_l2": 0.3469817340373993, "alpha_mean": 3.187751054763794, "cosine_mean": 0.11107631027698517}
INFO - 01/13/26 20:19:55 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -5.348038196563721, "loss_ft": -5.766198635101318, "loss_norm": 0.04503501206636429, "loss_ft_l2": 0.37312576174736023, "alpha_mean": 5.766198635101318, "cosine_mean": 0.1482599675655365}
INFO - 01/13/26 20:19:55 - 0:00:04 - __log__:{"keyword": "iteration", "loss": 0.542546272277832, "loss_ft": 0.07597339153289795, "loss_norm": 0.045962296426296234, "loss_ft_l2": 0.42061057686805725, "alpha_mean": -0.07597339153289795, "cosine_mean": -0.0037740692496299744}
INFO - 01/13/26 20:19:55 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -0.7276874780654907, "loss_ft": -1.1184154748916626, "loss_norm": 0.04593678191304207, "loss_ft_l2": 0.3447911739349365, "alpha_mean": 1.1184154748916626, "cosine_mean": 0.027405139058828354}
INFO - 01/13/26 20:19:55 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -5.104798316955566, "loss_ft": -5.462037086486816, "loss_norm": 0.04523025080561638, "loss_ft_l2": 0.31200817227363586, "alpha_mean": 5.462037086486816, "cosine_mean": 0.17511972784996033}
INFO - 01/13/26 20:19:55 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -2.090153217315674, "loss_ft": -2.5123486518859863, "loss_norm": 0.046297334134578705, "loss_ft_l2": 0.37589824199676514, "alpha_mean": 2.5123486518859863, "cosine_mean": 0.06951161473989487}
INFO - 01/13/26 20:19:55 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -0.5487409830093384, "loss_ft": -1.0069122314453125, "loss_norm": 0.046092547476291656, "loss_ft_l2": 0.41207870841026306, "alpha_mean": 1.0069122314453125, "cosine_mean": 0.023052258417010307}
INFO - 01/13/26 20:19:55 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -6.473437786102295, "loss_ft": -6.879403114318848, "loss_norm": 0.0461881048977375, "loss_ft_l2": 0.35977739095687866, "alpha_mean": 6.879403114318848, "cosine_mean": 0.18716742098331451}
INFO - 01/13/26 20:19:55 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -2.9353535175323486, "loss_ft": -3.3021726608276367, "loss_norm": 0.04704149439930916, "loss_ft_l2": 0.3197777569293976, "alpha_mean": 3.3021726608276367, "cosine_mean": 0.10491026192903519}
INFO - 01/13/26 20:19:55 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -3.999835252761841, "loss_ft": -4.424561500549316, "loss_norm": 0.0458376407623291, "loss_ft_l2": 0.3788887560367584, "alpha_mean": 4.424561500549316, "cosine_mean": 0.1169474646449089}
INFO - 01/13/26 20:19:55 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -1.0384600162506104, "loss_ft": -1.5150551795959473, "loss_norm": 0.046679481863975525, "loss_ft_l2": 0.4299156963825226, "alpha_mean": 1.5150551795959473, "cosine_mean": 0.034566730260849}
INFO - 01/13/26 20:19:55 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -2.869762897491455, "loss_ft": -3.2794809341430664, "loss_norm": 0.04653041064739227, "loss_ft_l2": 0.3631875514984131, "alpha_mean": 3.2794809341430664, "cosine_mean": 0.09095018357038498}
INFO - 01/13/26 20:19:55 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -2.566013813018799, "loss_ft": -2.9418795108795166, "loss_norm": 0.046550072729587555, "loss_ft_l2": 0.32931557297706604, "alpha_mean": 2.9418795108795166, "cosine_mean": 0.096882164478302}
INFO - 01/13/26 20:19:55 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -2.243826389312744, "loss_ft": -2.6641106605529785, "loss_norm": 0.04668163135647774, "loss_ft_l2": 0.37360259890556335, "alpha_mean": 2.6641106605529785, "cosine_mean": 0.06853832304477692}
INFO - 01/13/26 20:19:55 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -2.0037107467651367, "loss_ft": -2.4297940731048584, "loss_norm": 0.04660259932279587, "loss_ft_l2": 0.37948089838027954, "alpha_mean": 2.4297940731048584, "cosine_mean": 0.07246987521648407}
INFO - 01/13/26 20:19:55 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -4.386799335479736, "loss_ft": -4.795325756072998, "loss_norm": 0.04640628397464752, "loss_ft_l2": 0.36212021112442017, "alpha_mean": 4.795325756072998, "cosine_mean": 0.13246259093284607}
INFO - 01/13/26 20:19:55 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -3.6492345333099365, "loss_ft": -4.067277908325195, "loss_norm": 0.046121202409267426, "loss_ft_l2": 0.37192222476005554, "alpha_mean": 4.067277908325195, "cosine_mean": 0.11168213188648224}
INFO - 01/13/26 20:19:55 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -4.263779640197754, "loss_ft": -4.623262405395508, "loss_norm": 0.04638345539569855, "loss_ft_l2": 0.3130994737148285, "alpha_mean": 4.623262405395508, "cosine_mean": 0.14581507444381714}
INFO - 01/13/26 20:19:55 - 0:00:04 - __log__:{"keyword": "iteration", "loss": -4.132317543029785, "loss_ft": -4.563076019287109, "loss_norm": 0.0469105988740921, "loss_ft_l2": 0.3838476538658142, "alpha_mean": 4.563076019287109, "cosine_mean": 0.11905406415462494}
INFO - 01/13/26 20:19:55 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -3.1728262901306152, "loss_ft": -3.5695300102233887, "loss_norm": 0.04667384922504425, "loss_ft_l2": 0.35002997517585754, "alpha_mean": 3.5695300102233887, "cosine_mean": 0.10255325585603714}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -1.697343111038208, "loss_ft": -2.140429973602295, "loss_norm": 0.046215757727622986, "loss_ft_l2": 0.39687103033065796, "alpha_mean": 2.140429973602295, "cosine_mean": 0.058139290660619736}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -4.913637161254883, "loss_ft": -5.351404190063477, "loss_norm": 0.04587649554014206, "loss_ft_l2": 0.3918904662132263, "alpha_mean": 5.351404190063477, "cosine_mean": 0.13625124096870422}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -3.032712459564209, "loss_ft": -3.4585514068603516, "loss_norm": 0.0466780811548233, "loss_ft_l2": 0.3791607618331909, "alpha_mean": 3.4585514068603516, "cosine_mean": 0.09149959683418274}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -1.9793434143066406, "loss_ft": -2.388441324234009, "loss_norm": 0.04672001302242279, "loss_ft_l2": 0.3623778522014618, "alpha_mean": 2.388441324234009, "cosine_mean": 0.07310860604047775}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -4.087892055511475, "loss_ft": -4.514172077178955, "loss_norm": 0.04609810560941696, "loss_ft_l2": 0.3801819384098053, "alpha_mean": 4.514172077178955, "cosine_mean": 0.12205704301595688}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -4.414306163787842, "loss_ft": -4.835444450378418, "loss_norm": 0.04592413082718849, "loss_ft_l2": 0.3752139210700989, "alpha_mean": 4.835444450378418, "cosine_mean": 0.12782520055770874}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -4.490975379943848, "loss_ft": -4.914834022521973, "loss_norm": 0.04680684208869934, "loss_ft_l2": 0.3770519196987152, "alpha_mean": 4.914834022521973, "cosine_mean": 0.12785471975803375}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -1.9521368741989136, "loss_ft": -2.4057400226593018, "loss_norm": 0.046520620584487915, "loss_ft_l2": 0.4070824384689331, "alpha_mean": 2.4057400226593018, "cosine_mean": 0.058052536100149155}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -6.260672569274902, "loss_ft": -6.681944847106934, "loss_norm": 0.046133846044540405, "loss_ft_l2": 0.37513846158981323, "alpha_mean": 6.681944847106934, "cosine_mean": 0.17878104746341705}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": 0.042324334383010864, "loss_ft": -0.44403010606765747, "loss_norm": 0.045763395726680756, "loss_ft_l2": 0.440591037273407, "alpha_mean": 0.44403010606765747, "cosine_mean": 0.010284874588251114}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -4.326608657836914, "loss_ft": -4.750783920288086, "loss_norm": 0.045808449387550354, "loss_ft_l2": 0.3783669173717499, "alpha_mean": 4.750783920288086, "cosine_mean": 0.1251472532749176}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -1.3157768249511719, "loss_ft": -1.755589246749878, "loss_norm": 0.04552681744098663, "loss_ft_l2": 0.39428550004959106, "alpha_mean": 1.755589246749878, "cosine_mean": 0.04436992481350899}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -1.729720115661621, "loss_ft": -2.150125503540039, "loss_norm": 0.045847076922655106, "loss_ft_l2": 0.3745581805706024, "alpha_mean": 2.150125503540039, "cosine_mean": 0.07077977061271667}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -5.704575538635254, "loss_ft": -6.120150566101074, "loss_norm": 0.04628722742199898, "loss_ft_l2": 0.3692881762981415, "alpha_mean": 6.120150566101074, "cosine_mean": 0.16349419951438904}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -0.18641430139541626, "loss_ft": -0.6625730991363525, "loss_norm": 0.045991428196430206, "loss_ft_l2": 0.43016737699508667, "alpha_mean": 0.6625730991363525, "cosine_mean": 0.01555568352341652}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -3.836226224899292, "loss_ft": -4.270506858825684, "loss_norm": 0.04604239761829376, "loss_ft_l2": 0.38823816180229187, "alpha_mean": 4.270506858825684, "cosine_mean": 0.10989731550216675}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -2.2708468437194824, "loss_ft": -2.6626200675964355, "loss_norm": 0.04571914300322533, "loss_ft_l2": 0.3460541367530823, "alpha_mean": 2.6626200675964355, "cosine_mean": 0.08873365074396133}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -2.284425735473633, "loss_ft": -2.711406946182251, "loss_norm": 0.045541912317276, "loss_ft_l2": 0.3814392387866974, "alpha_mean": 2.711406946182251, "cosine_mean": 0.07059374451637268}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -3.1354286670684814, "loss_ft": -3.577826976776123, "loss_norm": 0.045257098972797394, "loss_ft_l2": 0.3971411883831024, "alpha_mean": 3.577826976776123, "cosine_mean": 0.09164056181907654}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -4.7669854164123535, "loss_ft": -5.22816276550293, "loss_norm": 0.04510944336652756, "loss_ft_l2": 0.4160679876804352, "alpha_mean": 5.22816276550293, "cosine_mean": 0.12509214878082275}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -2.9495434761047363, "loss_ft": -3.3639585971832275, "loss_norm": 0.04581880569458008, "loss_ft_l2": 0.3685964047908783, "alpha_mean": 3.3639585971832275, "cosine_mean": 0.0908103883266449}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -1.8985975980758667, "loss_ft": -2.3329739570617676, "loss_norm": 0.046242665499448776, "loss_ft_l2": 0.3881336748600006, "alpha_mean": 2.3329739570617676, "cosine_mean": 0.05932103097438812}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -4.081965446472168, "loss_ft": -4.492478847503662, "loss_norm": 0.045809969305992126, "loss_ft_l2": 0.364703893661499, "alpha_mean": 4.492478847503662, "cosine_mean": 0.12329265475273132}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -2.484306573867798, "loss_ft": -2.93673038482666, "loss_norm": 0.046317387372255325, "loss_ft_l2": 0.406106561422348, "alpha_mean": 2.93673038482666, "cosine_mean": 0.08245764672756195}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -1.7841017246246338, "loss_ft": -2.199334144592285, "loss_norm": 0.04617653787136078, "loss_ft_l2": 0.36905592679977417, "alpha_mean": 2.199334144592285, "cosine_mean": 0.05838578939437866}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -1.287210464477539, "loss_ft": -1.7112675905227661, "loss_norm": 0.04595761373639107, "loss_ft_l2": 0.37809959053993225, "alpha_mean": 1.7112675905227661, "cosine_mean": 0.04152670130133629}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -2.9550580978393555, "loss_ft": -3.370561122894287, "loss_norm": 0.04572228714823723, "loss_ft_l2": 0.36978065967559814, "alpha_mean": 3.370561122894287, "cosine_mean": 0.08864215761423111}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -2.058415412902832, "loss_ft": -2.458562135696411, "loss_norm": 0.04538143426179886, "loss_ft_l2": 0.35476523637771606, "alpha_mean": 2.458562135696411, "cosine_mean": 0.0717279464006424}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -1.6660295724868774, "loss_ft": -2.101191997528076, "loss_norm": 0.04542951658368111, "loss_ft_l2": 0.3897329568862915, "alpha_mean": 2.101191997528076, "cosine_mean": 0.053635239601135254}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -4.169507026672363, "loss_ft": -4.511566162109375, "loss_norm": 0.04499544948339462, "loss_ft_l2": 0.2970636785030365, "alpha_mean": 4.511566162109375, "cosine_mean": 0.15363800525665283}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -2.5131077766418457, "loss_ft": -2.931652069091797, "loss_norm": 0.04474524408578873, "loss_ft_l2": 0.373799204826355, "alpha_mean": 2.931652069091797, "cosine_mean": 0.08183204382658005}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -4.5106072425842285, "loss_ft": -4.908592224121094, "loss_norm": 0.045288458466529846, "loss_ft_l2": 0.35269659757614136, "alpha_mean": 4.908592224121094, "cosine_mean": 0.13639312982559204}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -5.373199462890625, "loss_ft": -5.801217079162598, "loss_norm": 0.04563891887664795, "loss_ft_l2": 0.38237836956977844, "alpha_mean": 5.801217079162598, "cosine_mean": 0.14201366901397705}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -4.075357913970947, "loss_ft": -4.493507385253906, "loss_norm": 0.046701908111572266, "loss_ft_l2": 0.3714475631713867, "alpha_mean": 4.493507385253906, "cosine_mean": 0.12146668136119843}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -4.876651287078857, "loss_ft": -5.299221992492676, "loss_norm": 0.046537939459085464, "loss_ft_l2": 0.37603285908699036, "alpha_mean": 5.299221992492676, "cosine_mean": 0.1381068229675293}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -5.094906806945801, "loss_ft": -5.49099588394165, "loss_norm": 0.04702074080705643, "loss_ft_l2": 0.34906795620918274, "alpha_mean": 5.49099588394165, "cosine_mean": 0.15724454820156097}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -4.893702983856201, "loss_ft": -5.291038513183594, "loss_norm": 0.04719429463148117, "loss_ft_l2": 0.35014113783836365, "alpha_mean": 5.291038513183594, "cosine_mean": 0.15149328112602234}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -0.11794701218605042, "loss_ft": -0.5685240030288696, "loss_norm": 0.047044605016708374, "loss_ft_l2": 0.40353235602378845, "alpha_mean": 0.5685240030288696, "cosine_mean": 0.012060292065143585}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -0.5510450601577759, "loss_ft": -1.0115313529968262, "loss_norm": 0.04725468158721924, "loss_ft_l2": 0.41323161125183105, "alpha_mean": 1.0115313529968262, "cosine_mean": 0.021672777831554413}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -4.550796031951904, "loss_ft": -4.924891471862793, "loss_norm": 0.04637504369020462, "loss_ft_l2": 0.32771995663642883, "alpha_mean": 4.924891471862793, "cosine_mean": 0.15010300278663635}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -2.639418601989746, "loss_ft": -3.070087432861328, "loss_norm": 0.04683656245470047, "loss_ft_l2": 0.38383224606513977, "alpha_mean": 3.070087432861328, "cosine_mean": 0.07903740555047989}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -0.18763425946235657, "loss_ft": -0.6434173583984375, "loss_norm": 0.04696321487426758, "loss_ft_l2": 0.40881988406181335, "alpha_mean": 0.6434173583984375, "cosine_mean": 0.01349097304046154}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -3.3357393741607666, "loss_ft": -3.7569057941436768, "loss_norm": 0.04715918004512787, "loss_ft_l2": 0.3740072250366211, "alpha_mean": 3.7569057941436768, "cosine_mean": 0.10686606168746948}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -2.21301531791687, "loss_ft": -2.6399242877960205, "loss_norm": 0.046695344150066376, "loss_ft_l2": 0.38021376729011536, "alpha_mean": 2.6399242877960205, "cosine_mean": 0.07372815907001495}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -1.5173606872558594, "loss_ft": -1.9669208526611328, "loss_norm": 0.046423591673374176, "loss_ft_l2": 0.403136670589447, "alpha_mean": 1.9669208526611328, "cosine_mean": 0.048774272203445435}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -4.023009300231934, "loss_ft": -4.42958927154541, "loss_norm": 0.04599873721599579, "loss_ft_l2": 0.3605814278125763, "alpha_mean": 4.42958927154541, "cosine_mean": 0.11593368649482727}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -1.3672747611999512, "loss_ft": -1.7908869981765747, "loss_norm": 0.04657036066055298, "loss_ft_l2": 0.37704184651374817, "alpha_mean": 1.7908869981765747, "cosine_mean": 0.046884723007678986}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -1.9570618867874146, "loss_ft": -2.344536304473877, "loss_norm": 0.04594873636960983, "loss_ft_l2": 0.341525673866272, "alpha_mean": 2.344536304473877, "cosine_mean": 0.08168813586235046}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -4.847028732299805, "loss_ft": -5.276618957519531, "loss_norm": 0.046678539365530014, "loss_ft_l2": 0.3829118609428406, "alpha_mean": 5.276618957519531, "cosine_mean": 0.13883286714553833}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -0.8221401572227478, "loss_ft": -1.270288109779358, "loss_norm": 0.04598316550254822, "loss_ft_l2": 0.4021647572517395, "alpha_mean": 1.270288109779358, "cosine_mean": 0.02962424047291279}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -2.0347275733947754, "loss_ft": -2.4464542865753174, "loss_norm": 0.04569833725690842, "loss_ft_l2": 0.36602821946144104, "alpha_mean": 2.4464542865753174, "cosine_mean": 0.06423312425613403}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -5.902302265167236, "loss_ft": -6.291382789611816, "loss_norm": 0.04536018893122673, "loss_ft_l2": 0.3437206447124481, "alpha_mean": 6.291382789611816, "cosine_mean": 0.1839449405670166}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -2.009528398513794, "loss_ft": -2.4509754180908203, "loss_norm": 0.04595889151096344, "loss_ft_l2": 0.39548805356025696, "alpha_mean": 2.4509754180908203, "cosine_mean": 0.05823744833469391}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -2.8146564960479736, "loss_ft": -3.267634391784668, "loss_norm": 0.04600600153207779, "loss_ft_l2": 0.40697193145751953, "alpha_mean": 3.267634391784668, "cosine_mean": 0.08246184140443802}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -5.372281551361084, "loss_ft": -5.757061004638672, "loss_norm": 0.04604492336511612, "loss_ft_l2": 0.33873450756073, "alpha_mean": 5.757061004638672, "cosine_mean": 0.16678230464458466}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -3.2515041828155518, "loss_ft": -3.6775033473968506, "loss_norm": 0.045523736625909805, "loss_ft_l2": 0.3804755210876465, "alpha_mean": 3.6775033473968506, "cosine_mean": 0.0917862132191658}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -3.736053466796875, "loss_ft": -4.17103910446167, "loss_norm": 0.04563776031136513, "loss_ft_l2": 0.3893480598926544, "alpha_mean": 4.17103910446167, "cosine_mean": 0.1039462685585022}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -4.277179718017578, "loss_ft": -4.69060754776001, "loss_norm": 0.046360477805137634, "loss_ft_l2": 0.3670673966407776, "alpha_mean": 4.69060754776001, "cosine_mean": 0.12621217966079712}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -3.203876256942749, "loss_ft": -3.635354518890381, "loss_norm": 0.04574296623468399, "loss_ft_l2": 0.38573524355888367, "alpha_mean": 3.635354518890381, "cosine_mean": 0.10053752362728119}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -2.7162373065948486, "loss_ft": -3.1338753700256348, "loss_norm": 0.04526331275701523, "loss_ft_l2": 0.37237483263015747, "alpha_mean": 3.1338753700256348, "cosine_mean": 0.08495030552148819}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -3.6888978481292725, "loss_ft": -4.058159351348877, "loss_norm": 0.045630112290382385, "loss_ft_l2": 0.3236314654350281, "alpha_mean": 4.058159351348877, "cosine_mean": 0.12806817889213562}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -2.155216693878174, "loss_ft": -2.583265542984009, "loss_norm": 0.04538145661354065, "loss_ft_l2": 0.3826674222946167, "alpha_mean": 2.583265542984009, "cosine_mean": 0.0680682510137558}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -4.591508865356445, "loss_ft": -4.997967720031738, "loss_norm": 0.04590107500553131, "loss_ft_l2": 0.3605577349662781, "alpha_mean": 4.997967720031738, "cosine_mean": 0.13756591081619263}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -1.6734015941619873, "loss_ft": -2.0690622329711914, "loss_norm": 0.04578932374715805, "loss_ft_l2": 0.349871426820755, "alpha_mean": 2.0690622329711914, "cosine_mean": 0.060815222561359406}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -1.4530855417251587, "loss_ft": -1.855783224105835, "loss_norm": 0.045836079865694046, "loss_ft_l2": 0.35686156153678894, "alpha_mean": 1.855783224105835, "cosine_mean": 0.06575217843055725}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -0.3760792911052704, "loss_ft": -0.8299291133880615, "loss_norm": 0.046104200184345245, "loss_ft_l2": 0.4077456295490265, "alpha_mean": 0.8299291133880615, "cosine_mean": 0.01872849464416504}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -0.5053220987319946, "loss_ft": -0.9613595008850098, "loss_norm": 0.04618752375245094, "loss_ft_l2": 0.4098498523235321, "alpha_mean": 0.9613595008850098, "cosine_mean": 0.02474926970899105}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "iteration", "loss": -2.0918238162994385, "loss_ft": -2.5112123489379883, "loss_norm": 0.04611677676439285, "loss_ft_l2": 0.37327173352241516, "alpha_mean": 2.5112123489379883, "cosine_mean": 0.07078748196363449}
INFO - 01/13/26 20:19:56 - 0:00:05 - __log__:{"keyword": "final", "psnr": 31.368529104971216, "ft_direction": 2.000087261199951, "ft_norm": 14.658042907714844, "cosine_mean": 0.13853713870048523, "rho": -1, "R": -433.36334228515625}
